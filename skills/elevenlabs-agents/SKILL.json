{
  "description": "|",
  "metadata": {
    "license": "MIT"
  },
  "references": {
    "files": [
      "references/api-reference.md",
      "references/cli-commands.md",
      "references/compliance-guide.md",
      "references/cost-optimization.md",
      "references/system-prompt-guide.md",
      "references/testing-guide.md",
      "references/tool-examples.md",
      "references/workflow-examples.md"
    ]
  },
  "content": "### Path A: React SDK (Embedded Voice Chat)\r\n\r\nFor building voice chat interfaces in React applications.\r\n\r\n**Installation**:\r\n```bash\r\nnpm install @elevenlabs/react zod\r\n```\r\n\r\n**Basic Example**:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\nimport { z } from 'zod';\r\n\r\nexport default function VoiceChat() {\r\n  const { startConversation, stopConversation, status } = useConversation({\r\n    // Public agent (no API key needed)\r\n    agentId: 'your-agent-id',\r\n\r\n    // OR private agent (requires API key)\r\n    apiKey: process.env.NEXT_PUBLIC_ELEVENLABS_API_KEY,\r\n\r\n    // OR signed URL (server-generated, most secure)\r\n    signedUrl: '/api/elevenlabs/auth',\r\n\r\n    // Client-side tools (browser functions)\r\n    clientTools: {\r\n      updateCart: {\r\n        description: \"Update the shopping cart\",\r\n        parameters: z.object({\r\n          item: z.string(),\r\n          quantity: z.number()\r\n        }),\r\n        handler: async ({ item, quantity }) => {\r\n          console.log('Updating cart:', item, quantity);\r\n          return { success: true };\r\n        }\r\n      }\r\n    },\r\n\r\n    // Event handlers\r\n    onConnect: () => console.log('Connected'),\r\n    onDisconnect: () => console.log('Disconnected'),\r\n    onEvent: (event) => {\r\n      switch (event.type) {\r\n        case 'transcript':\r\n          console.log('User said:', event.data.text);\r\n          break;\r\n        case 'agent_response':\r\n          console.log('Agent replied:', event.data.text);\r\n          break;\r\n      }\r\n    },\r\n\r\n    // Regional compliance (GDPR, data residency)\r\n    serverLocation: 'us' // 'us' | 'global' | 'eu-residency' | 'in-residency'\r\n  });\r\n\r\n  return (\r\n    <div>\r\n      <button onClick={startConversation}>Start Conversation</button>\r\n      <button onClick={stopConversation}>Stop</button>\r\n      <p>Status: {status}</p>\r\n    </div>\r\n  );\r\n}\r\n```\r\n\r\n### Path B: CLI (\"Agents as Code\")\r\n\r\nFor managing agents via code with version control and CI/CD.\r\n\r\n**Installation**:\r\n```bash\r\nnpm install -g @elevenlabs/agents-cli\r\npnpm install -g @elevenlabs/agents-cli\r\n```\r\n\r\n**Workflow**:\r\n```bash\r\nelevenlabs auth login\r\n\r\nelevenlabs agents init\r\n\r\nelevenlabs agents add \"Support Agent\" --template customer-service\r\n\r\n\r\nelevenlabs agents push --env dev\r\n\r\nelevenlabs agents test \"Support Agent\"\r\n\r\n\r\n### Scenario Testing (LLM-Based Evaluation)\r\n\r\nSimulate full conversations and evaluate against success criteria.\r\n\r\n**Configuration via CLI**:\r\n```bash\r\nelevenlabs tests add \"Refund Request Test\" --template basic-llm\r\n```\r\n\r\n**test_configs/refund-request-test.json**:\r\n```json\r\n{\r\n  \"name\": \"Refund Request Test\",\r\n  \"scenario\": \"Customer requests refund for defective product\",\r\n  \"user_input\": \"I want a refund for order #12345. The product was broken when it arrived.\",\r\n  \"success_criteria\": [\r\n    \"Agent acknowledges the request empathetically\",\r\n    \"Agent asks for order number (which was already provided)\",\r\n    \"Agent verifies order details\",\r\n    \"Agent provides refund timeline or next steps\"\r\n  ],\r\n  \"evaluation_type\": \"llm\"\r\n}\r\n```\r\n\r\n**Run Test**:\r\n```bash\r\nelevenlabs agents test \"Support Agent\"\r\n```\r\n\r\n### Tool Call Testing\r\n\r\nVerify that agents correctly use tools with the right parameters.\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"name\": \"Account Balance Test\",\r\n  \"scenario\": \"Customer requests account balance\",\r\n  \"expected_tool_call\": {\r\n    \"tool_name\": \"get_account_balance\",\r\n    \"parameters\": {\r\n      \"account_id\": \"ACC-12345\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Load Testing\r\n\r\nTest agent capacity under high concurrency.\r\n\r\n**Configuration**:\r\n```bash\r\n\r\n### Installation & Authentication\r\n\r\n```bash\r\nnpm install -g @elevenlabs/cli\r\n\r\nelevenlabs auth login\r\n\r\nelevenlabs auth residency eu-residency  # or 'in-residency' | 'global'\r\n\r\nelevenlabs auth whoami\r\n```\r\n\r\n**Environment Variables** (For CI/CD):\r\n```bash\r\nexport ELEVENLABS_API_KEY=your-api-key\r\n```\r\n\r\n### Project Structure\r\n\r\n**Initialize Project**:\r\n```bash\r\nelevenlabs agents init\r\n```\r\n\r\n**Directory Structure Created**:\r\n```\r\nyour_project/\r\n├── agents.json              # Agent registry\r\n├── tools.json               # Tool configurations\r\n├── tests.json               # Test configurations\r\n├── agent_configs/           # Individual agent files (.json)\r\n├── tool_configs/            # Tool configuration files\r\n└── test_configs/            # Test configuration files\r\n```\r\n\r\n### Agent Management Commands\r\n\r\n```bash\r\nelevenlabs agents add \"Support Agent\" --template customer-service\r\n\r\nelevenlabs agents push\r\nelevenlabs agents push --agent \"Support Agent\"\r\nelevenlabs agents push --env prod\r\nelevenlabs agents push --dry-run  # Preview changes\r\n\r\nelevenlabs agents pull\r\n\r\nelevenlabs agents list\r\n\r\nelevenlabs agents status\r\n\r\nelevenlabs agents delete <agent_id>\r\n```\r\n\r\n### Tool Management Commands\r\n\r\n```bash\r\nelevenlabs tools add-webhook \"Get Weather\" --config-path tool_configs/get-weather.json\r\n\r\nelevenlabs tools add-client \"Update Cart\" --config-path tool_configs/update-cart.json\r\n\r\nelevenlabs tools push\r\n\r\nelevenlabs tools pull\r\n\r\nelevenlabs tools delete <tool_id>\r\nelevenlabs tools delete --all\r\n```\r\n\r\n### Testing Commands\r\n\r\n```bash\r\nelevenlabs tests add \"Refund Test\" --template basic-llm\r\n\r\nelevenlabs tests push\r\n\r\nelevenlabs tests pull\r\n\r\nelevenlabs agents test \"Support Agent\"\r\n```\r\n\r\n### Multi-Environment Deployment\r\n\r\n**Pattern**:\r\n```bash\r\nelevenlabs agents push --env dev\r\n\r\nelevenlabs agents push --env staging\r\n\r\nelevenlabs agents push --env prod --dry-run\r\nelevenlabs agents push --env prod\r\n```\r\n\r\n**Environment-Specific Configs**:\r\n```\r\nagent_configs/\r\n├── support-bot.json          # Base config\r\n├── support-bot.dev.json      # Dev overrides\r\n├── support-bot.staging.json  # Staging overrides\r\n└── support-bot.prod.json     # Prod overrides\r\n```\r\n\r\n### CI/CD Integration\r\n\r\n**GitHub Actions Example**:\r\n```yaml\r\nname: Deploy Agent\r\non:\r\n  push:\r\n    branches: [main]\r\n    paths:\r\n      - 'agent_configs/**'\r\n      - 'tool_configs/**'\r\n\r\njobs:\r\n  deploy:\r\n    runs-on: ubuntu-latest\r\n    steps:\r\n      - uses: actions/checkout@v3\r\n\r\n      - name: Install CLI\r\n        run: npm install -g @elevenlabs/cli\r\n\r\n      - name: Test Configs\r\n        run: elevenlabs agents push --dry-run --env prod\r\n        env:\r\n          ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY_PROD }}\r\n\r\n      - name: Deploy\r\n        run: elevenlabs agents push --env prod\r\n        env:\r\n          ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY_PROD }}\r\n```\r\n\r\n### Version Control Best Practices\r\n\r\n**Commit**:\r\n- `agent_configs/*.json`\r\n- `tool_configs/*.json`\r\n- `test_configs/*.json`\r\n- `agents.json`, `tools.json`, `tests.json`\r\n\r\n**Ignore**:\r\n```\r\n\r\n### Error 1: Missing Required Dynamic Variables\r\n\r\n**Symptom**: \"Missing required dynamic variables\" error, no transcript generated\r\n\r\n**Cause**: Dynamic variables referenced in prompts/messages but not provided at conversation start\r\n\r\n**Solution**:\r\n```typescript\r\nconst conversation = await client.conversations.create({\r\n  agent_id: \"agent_123\",\r\n  dynamic_variables: {\r\n    user_name: \"John\",\r\n    account_tier: \"premium\",\r\n    // Provide ALL variables referenced in prompts\r\n  }\r\n});\r\n```\r\n\r\n### Error 2: Case-Sensitive Tool Names\r\n\r\n**Symptom**: Tool not executing, agent says \"tool not found\"\r\n\r\n**Cause**: Tool name in config doesn't match registered name (case-sensitive)\r\n\r\n**Solution**:\r\n```json\r\n// agent_configs/bot.json\r\n{\r\n  \"agent\": {\r\n    \"prompt\": {\r\n      \"tool_ids\": [\"orderLookup\"]  // Must match exactly\r\n    }\r\n  }\r\n}\r\n\r\n// tool_configs/order-lookup.json\r\n{\r\n  \"name\": \"orderLookup\"  // Match case exactly\r\n}\r\n```\r\n\r\n### Error 3: Webhook Authentication Failures\r\n\r\n**Symptom**: Webhook auto-disabled after failures\r\n\r\n**Cause**:\r\n- Incorrect HMAC signature verification\r\n- Not returning 200 status code\r\n- 10+ consecutive failures\r\n\r\n**Solution**:\r\n```typescript\r\n// Always verify HMAC signature\r\nimport crypto from 'crypto';\r\n\r\nconst signature = req.headers['elevenlabs-signature'];\r\nconst payload = JSON.stringify(req.body);\r\n\r\nconst hmac = crypto\r\n  .createHmac('sha256', process.env.WEBHOOK_SECRET)\r\n  .update(payload)\r\n  .digest('hex');\r\n\r\nif (signature !== hmac) {\r\n  return res.status(401).json({ error: 'Invalid signature' });\r\n}\r\n\r\n// Process webhook\r\n// ...\r\n\r\n// MUST return 200\r\nres.status(200).json({ success: true });\r\n```\r\n\r\n### Error 4: Voice Consistency Issues\r\n\r\n**Symptom**: Generated audio varies in volume/tone\r\n\r\n**Cause**:\r\n- Background noise in voice clone training data\r\n- Inconsistent microphone distance\r\n- Whispering or shouting in samples\r\n\r\n**Solution**:\r\n- Use clean audio samples (no music, noise, pops)\r\n- Maintain consistent microphone distance\r\n- Avoid extreme volumes\r\n- Test voice settings before deployment\r\n\r\n### Error 5: Wrong Language Voice\r\n\r\n**Symptom**: Unpredictable pronunciation, accent issues\r\n\r\n**Cause**: Using English-trained voice for non-English language\r\n\r\n**Solution**:\r\n```json\r\n{\r\n  \"language_presets\": [\r\n    {\r\n      \"language\": \"es\",\r\n      \"voice_id\": \"spanish_trained_voice_id\"  // Must be Spanish-trained\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n### Error 6: Restricted API Keys Not Supported (CLI)\r\n\r\n**Symptom**: CLI authentication fails\r\n\r\n**Cause**: Using restricted API key (not currently supported)\r\n\r\n**Solution**: Use unrestricted API key for CLI operations\r\n\r\n### Error 7: Agent Configuration Push Conflicts\r\n\r\n**Symptom**: Changes not reflected after push\r\n\r\n**Cause**: Hash-based change detection missed modification\r\n\r\n**Solution**:\r\n```bash\r\nelevenlabs agents init --override\r\nelevenlabs agents pull  # Re-import from platform\r\nelevenlabs agents push\r\n```\r\n\r\n### Error 8: Tool Parameter Schema Mismatch\r\n\r\n**Symptom**: Tool called but parameters empty or incorrect\r\n\r\n**Cause**: Schema definition doesn't match actual usage\r\n\r\n**Solution**:\r\n```json\r\n// tool_configs/order-lookup.json\r\n{\r\n  \"parameters\": {\r\n    \"type\": \"object\",\r\n    \"properties\": {\r\n      \"order_id\": {\r\n        \"type\": \"string\",\r\n        \"description\": \"The order ID to look up (format: ORD-12345)\"  // Clear description\r\n      }\r\n    },\r\n    \"required\": [\"order_id\"]\r\n  }\r\n}\r\n```\r\n\r\n### Error 9: RAG Index Not Ready\r\n\r\n**Symptom**: Agent doesn't use knowledge base\r\n\r\n**Cause**: RAG index still computing (can take minutes for large documents)\r\n\r\n**Solution**:\r\n```typescript\r\n// Check index status before using\r\nconst index = await client.knowledgeBase.getRagIndex({\r\n  document_id: 'doc_123'\r\n});\r\n\r\nif (index.status !== 'ready') {\r\n  console.log('Index still computing...');\r\n}\r\n```\r\n\r\n### Error 10: WebSocket Protocol Error (1002)\r\n\r\n**Symptom**: Intermittent \"protocol error\" when using WebSocket connections\r\n\r\n**Cause**: Network instability or incompatible browser\r\n\r\n**Solution**:\r\n- Use WebRTC instead of WebSocket (more resilient)\r\n- Implement reconnection logic\r\n- Check browser compatibility\r\n\r\n### Error 11: 401 Unauthorized in Production\r\n\r\n**Symptom**: Works locally but fails in production\r\n\r\n**Cause**: Agent visibility settings or API key configuration\r\n\r\n**Solution**:\r\n- Check agent visibility (public vs private)\r\n- Verify API key is set in production environment\r\n- Check allowlist configuration if enabled\r\n\r\n### Error 12: Allowlist Connection Errors\r\n\r\n**Symptom**: \"Host elevenlabs.io is not allowed to connect to this agent\"\r\n\r\n**Cause**: Agent has allowlist enabled but using shared link\r\n\r\n**Solution**:\r\n- Configure agent allowlist with correct domains\r\n- Or disable allowlist for testing\r\n\r\n### Error 13: Workflow Infinite Loops\r\n\r\n**Symptom**: Agent gets stuck in workflow, never completes\r\n\r\n**Cause**: Edge conditions creating loops\r\n\r\n**Solution**:\r\n- Add max iteration limits\r\n- Test all edge paths\r\n- Add explicit exit conditions\r\n\r\n### Error 14: Burst Pricing Not Enabled\r\n\r\n**Symptom**: Calls rejected during traffic spikes\r\n\r\n**Cause**: Burst pricing not enabled in agent settings\r\n\r\n**Solution**:\r\n```json\r\n{\r\n  \"call_limits\": {\r\n    \"burst_pricing_enabled\": true\r\n  }\r\n}\r\n```\r\n\r\n### Error 15: MCP Server Timeout\r\n\r\n**Symptom**: MCP tools not responding\r\n\r\n**Cause**: MCP server slow or unreachable\r\n\r\n**Solution**:\r\n- Check MCP server URL is accessible\r\n- Verify transport type (SSE vs HTTP)\r\n- Check authentication token\r\n- Monitor MCP server logs\r\n\r\n### Error 16: First Message Cutoff on Android\r\n\r\n**Symptom**: First message from agent gets cut off on Android devices (works fine on iOS/web)\r\n\r\n**Cause**: Android devices need time to switch to correct audio mode after connection\r\n\r\n**Solution**:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\n\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-agent-id',\r\n\r\n  // Add connection delay for Android\r\n  connectionDelay: {\r\n    android: 3_000,  // 3 seconds (default)\r\n    ios: 0,          // No delay needed\r\n    default: 0       // Other platforms\r\n  },\r\n\r\n  // Rest of config...\r\n});\r\n```\r\n\r\n**Explanation**:\r\n- Android needs 3 seconds to switch audio routing mode\r\n- Without delay, first audio chunk is lost\r\n- iOS and web don't have this issue\r\n- Adjust delay if 3 seconds isn't sufficient\r\n\r\n**Testing**:\r\n```bash\r\nnpm run android\r\n\r\n```\r\n\r\n### Error 17: CSP (Content Security Policy) Violations\r\n\r\n**Symptom**: \"Refused to load the script because it violates the following Content Security Policy directive\" errors in browser console\r\n\r\n**Cause**: Applications with strict Content Security Policy don't allow `data:` or `blob:` URLs in `script-src` directive. ElevenLabs SDK uses Audio Worklets that are loaded as blobs by default.\r\n\r\n**Solution - Self-Host Worklet Files**:\r\n\r\n**Step 1**: Copy worklet files to your public directory:\r\n```bash\r\ncp node_modules/@elevenlabs/client/dist/worklets/*.js public/elevenlabs/\r\n```\r\n\r\n**Step 2**: Configure SDK to use self-hosted worklets:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\n\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-agent-id',\r\n\r\n  // Point to self-hosted worklet files\r\n  workletPaths: {\r\n    'rawAudioProcessor': '/elevenlabs/rawAudioProcessor.worklet.js',\r\n    'audioConcatProcessor': '/elevenlabs/audioConcatProcessor.worklet.js',\r\n  },\r\n\r\n  // Rest of config...\r\n});\r\n```\r\n\r\n**Step 3**: Update CSP headers to allow self-hosted scripts:\r\n```nginx",
  "name": "elevenlabs-agents",
  "id": "elevenlabs-agents",
  "sections": {
    "2. Agent Configuration": "### System Prompt Architecture (6 Components)\r\n\r\nElevenLabs recommends structuring agent prompts using 6 components:\r\n\r\n#### 1. Personality\r\nDefine the agent's identity, role, and character traits.\r\n\r\n**Example**:\r\n```\r\nYou are Alex, a friendly and knowledgeable customer support specialist at TechCorp.\r\nYou have 5 years of experience helping customers solve technical issues.\r\nYou're patient, empathetic, and always maintain a positive attitude.\r\n```\r\n\r\n#### 2. Environment\r\nDescribe the communication context (phone, web chat, video call).\r\n\r\n**Example**:\r\n```\r\nYou're speaking with customers over the phone. Communication is voice-only.\r\nCustomers may have background noise or poor connection quality.\r\nSpeak clearly and occasionally use thoughtful pauses for emphasis.\r\n```\r\n\r\n#### 3. Tone\r\nSpecify formality, speech patterns, humor, and verbosity.\r\n\r\n**Example**:\r\n```\r\nTone: Professional yet warm. Use contractions (\"I'm\" instead of \"I am\") to sound natural.\r\nAvoid jargon unless the customer uses it first. Keep responses concise (2-3 sentences max).\r\nUse encouraging phrases like \"I'll be happy to help with that\" and \"Let's get this sorted for you.\"\r\n```\r\n\r\n#### 4. Goal\r\nDefine objectives and success criteria.\r\n\r\n**Example**:\r\n```\r\nPrimary Goal: Resolve customer technical issues on the first call.\r\nSecondary Goals:\r\n- Verify customer identity securely\r\n- Document issue details accurately\r\n- Offer proactive solutions\r\n- End calls with confirmation that the issue is resolved\r\n\r\nSuccess Criteria: Customer verbally confirms their issue is resolved.\r\n```\r\n\r\n#### 5. Guardrails\r\nSet boundaries, prohibited topics, and ethical constraints.\r\n\r\n**Example**:\r\n```\r\nGuardrails:\r\n- Never provide medical, legal, or financial advice\r\n- Do not share confidential company information\r\n- If asked about competitors, politely redirect to TechCorp's offerings\r\n- Escalate to a human supervisor if customer becomes abusive\r\n- Never make promises about refunds or credits without verification\r\n```\r\n\r\n#### 6. Tools\r\nDescribe available external capabilities and when to use them.\r\n\r\n**Example**:\r\n```\r\nAvailable Tools:\r\n1. lookup_order(order_id) - Fetch order details from database. Use when customer mentions an order number.\r\n2. transfer_to_supervisor() - Escalate to human agent. Use when issue requires manager approval.\r\n3. send_password_reset(email) - Trigger password reset email. Use when customer can't access account.\r\n\r\nAlways explain to the customer what you're doing before calling a tool.\r\n```\r\n\r\n**Complete Template**:\r\n```json\r\n{\r\n  \"agent\": {\r\n    \"prompt\": {\r\n      \"prompt\": \"Personality:\\nYou are Alex, a friendly customer support specialist.\\n\\nEnvironment:\\nYou're speaking with customers over the phone.\\n\\nTone:\\nProfessional yet warm. Keep responses concise.\\n\\nGoal:\\nResolve technical issues on the first call.\\n\\nGuardrails:\\n- Never provide medical/legal/financial advice\\n- Escalate abusive customers\\n\\nTools:\\n- lookup_order(order_id) - Fetch order details\\n- transfer_to_supervisor() - Escalate to human\",\r\n      \"llm\": \"gpt-4o\",\r\n      \"temperature\": 0.7,\r\n      \"max_tokens\": 500\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Turn-Taking Modes\r\n\r\nControls when the agent interrupts or waits for the user to finish speaking.\r\n\r\n**3 Modes**:\r\n\r\n| Mode | Behavior | Best For |\r\n|------|----------|----------|\r\n| **Eager** | Responds quickly, jumps in at earliest opportunity | Fast-paced support, quick orders |\r\n| **Normal** | Balanced, waits for natural conversation breaks | General customer service (default) |\r\n| **Patient** | Waits longer, allows detailed user responses | Information collection, therapy, tutoring |\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"conversation_config\": {\r\n    \"turn\": {\r\n      \"mode\": \"patient\" // \"eager\" | \"normal\" | \"patient\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- **Eager**: Fast food ordering, quick FAQs, urgent notifications\r\n- **Normal**: General support, product inquiries, appointment booking\r\n- **Patient**: Detailed form filling, emotional support, educational tutoring\r\n\r\n**Gotchas**:\r\n- Eager mode can feel interruptive to some users\r\n- Patient mode may feel slow in fast-paced contexts\r\n- Can be dynamically adjusted in workflows for context-aware behavior\r\n\r\n### Workflows (Visual Builder)\r\n\r\nCreate branching conversation flows with subagent nodes and conditional routing.\r\n\r\n**Node Types**:\r\n1. **Subagent Nodes** - Override base agent config (change prompt, voice, turn-taking)\r\n2. **Tool Nodes** - Guarantee tool execution (unlike tools in subagents)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"workflow\": {\r\n    \"nodes\": [\r\n      {\r\n        \"id\": \"node_1\",\r\n        \"type\": \"subagent\",\r\n        \"config\": {\r\n          \"system_prompt\": \"You are now a technical support specialist. Ask detailed diagnostic questions.\",\r\n          \"turn_eagerness\": \"patient\",\r\n          \"voice_id\": \"tech_support_voice_id\"\r\n        }\r\n      },\r\n      {\r\n        \"id\": \"node_2\",\r\n        \"type\": \"tool\",\r\n        \"tool_name\": \"transfer_to_human\"\r\n      }\r\n    ],\r\n    \"edges\": [\r\n      {\r\n        \"from\": \"node_1\",\r\n        \"to\": \"node_2\",\r\n        \"condition\": \"user_requests_escalation\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Multi-department routing (sales → support → billing)\r\n- Decision trees (\"press 1 for sales, 2 for support\")\r\n- Role-playing scenarios (customer vs agent voices)\r\n- Escalation paths (bot → human transfer)\r\n\r\n**Gotchas**:\r\n- Workflows add ~100-200ms latency per node transition\r\n- Tool nodes guarantee execution (subagents may skip tools)\r\n- Edges can create infinite loops if not tested properly\r\n\r\n### Dynamic Variables & Personalization\r\n\r\nInject runtime data into prompts, first messages, and tool parameters using `{{var_name}}` syntax.\r\n\r\n**System Variables (Auto-Available)**:\r\n```typescript\r\n{{system__agent_id}}         // Current agent ID\r\n{{system__conversation_id}}  // Conversation ID\r\n{{system__caller_id}}        // Phone number (telephony only)\r\n{{system__called_number}}    // Called number (telephony only)\r\n{{system__call_duration_secs}} // Call duration\r\n{{system__time_utc}}         // Current UTC time\r\n{{system__call_sid}}         // Twilio call SID (Twilio only)\r\n```\r\n\r\n**Custom Variables**:\r\n```typescript\r\n// Provide when starting conversation\r\nconst conversation = await client.conversations.create({\r\n  agent_id: \"agent_123\",\r\n  dynamic_variables: {\r\n    user_name: \"John\",\r\n    account_tier: \"premium\",\r\n    order_id: \"ORD-12345\"\r\n  }\r\n});\r\n```\r\n\r\n**Secret Variables** (For API Keys):\r\n```\r\n{{secret__stripe_api_key}}\r\n{{secret__database_password}}\r\n```\r\n\r\n**Important**: Secret variables only used in headers, never sent to LLM providers.\r\n\r\n**Usage in Prompts**:\r\n```json\r\n{\r\n  \"agent\": {\r\n    \"prompt\": {\r\n      \"prompt\": \"You are helping {{user_name}}, a {{account_tier}} customer.\"\r\n    },\r\n    \"first_message\": \"Hello {{user_name}}! I see you're calling about order {{order_id}}.\"\r\n  }\r\n}\r\n```\r\n\r\n**Gotcha**: Missing variables cause \"Missing required dynamic variables\" error. Always provide all referenced variables when starting conversation.\r\n\r\n### Authentication Patterns\r\n\r\n**Option 1: Public Agents** (No API Key)\r\n```typescript\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-public-agent-id' // Anyone can use\r\n});\r\n```\r\n\r\n**Option 2: Private Agents with API Key**\r\n```typescript\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-private-agent-id',\r\n  apiKey: process.env.NEXT_PUBLIC_ELEVENLABS_API_KEY\r\n});\r\n```\r\n\r\n**⚠️ Warning**: Never expose API keys in client-side code. Use signed URLs instead.\r\n\r\n**Option 3: Signed URLs (Recommended for Production)**\r\n```typescript\r\n// Server-side (Next.js API route)\r\nimport { ElevenLabsClient } from 'elevenlabs';\r\n\r\nexport async function POST(req: Request) {\r\n  const client = new ElevenLabsClient({\r\n    apiKey: process.env.ELEVENLABS_API_KEY // Server-side only\r\n  });\r\n\r\n  const signedUrl = await client.convai.getSignedUrl({\r\n    agent_id: 'your-agent-id'\r\n  });\r\n\r\n  return Response.json({ signedUrl });\r\n}\r\n\r\n// Client-side\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-agent-id',\r\n  signedUrl: await fetch('/api/elevenlabs/auth').then(r => r.json()).then(d => d.signedUrl)\r\n});\r\n```\r\n\r\n---",
    "11. Advanced Features": "### Events (WebSocket/SSE)\r\n\r\nReal-time event streaming for live transcription, agent responses, and tool calls.\r\n\r\n**Event Types**:\r\n- `audio` - Audio stream chunks\r\n- `transcript` - Real-time transcription\r\n- `agent_response` - Agent's text response\r\n- `tool_call` - Tool execution status\r\n- `conversation_state` - State updates\r\n\r\n**Example**:\r\n```typescript\r\nconst { startConversation } = useConversation({\r\n  onEvent: (event) => {\r\n    switch (event.type) {\r\n      case 'transcript':\r\n        console.log('User said:', event.data.text);\r\n        break;\r\n      case 'agent_response':\r\n        console.log('Agent replied:', event.data.text);\r\n        break;\r\n      case 'tool_call':\r\n        console.log('Tool called:', event.data.tool_name);\r\n        break;\r\n    }\r\n  }\r\n});\r\n```\r\n\r\n### Custom Models (Bring Your Own LLM)\r\n\r\nUse your own OpenAI API key or custom LLM server.\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"llm_config\": {\r\n    \"custom\": {\r\n      \"endpoint\": \"https://api.openai.com/v1/chat/completions\",\r\n      \"api_key\": \"{{secret__openai_api_key}}\",\r\n      \"model\": \"gpt-4\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Custom fine-tuned models\r\n- Private LLM deployments (Ollama, LocalAI)\r\n- Cost control (use your own credits)\r\n- Compliance (on-premise models)\r\n\r\n**Gotchas**:\r\n- Endpoint must be OpenAI-compatible\r\n- No official support for non-OpenAI-compatible models\r\n\r\n### Post-Call Webhooks\r\n\r\nReceive notifications when a call ends and analysis completes.\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"webhooks\": {\r\n    \"post_call\": {\r\n      \"url\": \"https://api.example.com/webhook\",\r\n      \"headers\": {\r\n        \"Authorization\": \"Bearer {{secret__webhook_auth_token}}\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Payload**:\r\n```json\r\n{\r\n  \"conversation_id\": \"conv_123\",\r\n  \"agent_id\": \"agent_456\",\r\n  \"transcript\": \"...\",\r\n  \"duration_seconds\": 120,\r\n  \"analysis\": {\r\n    \"sentiment\": \"positive\",\r\n    \"resolution\": true,\r\n    \"extracted_data\": {\r\n      \"customer_name\": \"John Doe\",\r\n      \"issue_type\": \"billing\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Security (HMAC Verification)**:\r\n```typescript\r\nimport crypto from 'crypto';\r\n\r\nexport async function POST(req: Request) {\r\n  const signature = req.headers.get('elevenlabs-signature');\r\n  const payload = await req.text();\r\n\r\n  const hmac = crypto\r\n    .createHmac('sha256', process.env.WEBHOOK_SECRET!)\r\n    .update(payload)\r\n    .digest('hex');\r\n\r\n  if (signature !== hmac) {\r\n    return new Response('Invalid signature', { status: 401 });\r\n  }\r\n\r\n  // Process webhook\r\n  const data = JSON.parse(payload);\r\n  console.log('Conversation ended:', data.conversation_id);\r\n\r\n  // MUST return 200\r\n  return new Response('OK', { status: 200 });\r\n}\r\n```\r\n\r\n**Gotchas**:\r\n- Must return 200 status code\r\n- Auto-disabled after 10 consecutive failures (7+ days since last success)\r\n- Retry logic: 3 attempts with exponential backoff\r\n\r\n### Chat Mode (Text-Only)\r\n\r\nDisable voice, use text-only conversations.\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"conversation_config\": {\r\n    \"chat_mode\": true  // Disables audio input/output\r\n  }\r\n}\r\n```\r\n\r\n**Benefits**:\r\n- Faster response times (~200ms saved)\r\n- Lower costs (no ASR/TTS charges)\r\n- Easier testing (no microphone required)\r\n\r\n**Use Cases**:\r\n- Testing agents without audio\r\n- Building text chat interfaces\r\n- Accessibility (text-only users)\r\n\r\n### Telephony Integration\r\n\r\n**SIP Trunking**:\r\n```\r\nSIP Endpoint: sip-static.rtc.elevenlabs.io\r\nTLS Transport: Recommended for production\r\nSRTP Encryption: Supported\r\n```\r\n\r\n**Supported Providers**: Twilio, Vonage, RingCentral, Sinch, Infobip, Telnyx, Exotel, Plivo, Bandwidth\r\n\r\n**Native Twilio Integration**:\r\n```json\r\n{\r\n  \"telephony\": {\r\n    \"provider\": \"twilio\",\r\n    \"phone_number\": \"+1234567890\",\r\n    \"account_sid\": \"{{secret__twilio_account_sid}}\",\r\n    \"auth_token\": \"{{secret__twilio_auth_token}}\"\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Customer support hotlines\r\n- Appointment scheduling\r\n- Order status inquiries\r\n- IVR systems\r\n\r\n---",
    "6. SDK Integration": "### React SDK (`@elevenlabs/react`)\r\n\r\n**Installation**:\r\n```bash\r\nnpm install @elevenlabs/react zod\r\n```\r\n\r\n**Complete Example**:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\nimport { z } from 'zod';\r\nimport { useState } from 'react';\r\n\r\nexport default function VoiceAgent() {\r\n  const [transcript, setTranscript] = useState<string[]>([]);\r\n\r\n  const {\r\n    startConversation,\r\n    stopConversation,\r\n    status,\r\n    isSpeaking\r\n  } = useConversation({\r\n    agentId: 'your-agent-id',\r\n\r\n    // Authentication (choose one)\r\n    apiKey: process.env.NEXT_PUBLIC_ELEVENLABS_API_KEY,\r\n\r\n    // Client tools\r\n    clientTools: {\r\n      updateCart: {\r\n        description: \"Update shopping cart\",\r\n        parameters: z.object({\r\n          item: z.string(),\r\n          quantity: z.number()\r\n        }),\r\n        handler: async ({ item, quantity }) => {\r\n          console.log('Cart updated:', item, quantity);\r\n          return { success: true };\r\n        }\r\n      }\r\n    },\r\n\r\n    // Events\r\n    onConnect: () => {\r\n      console.log('Connected to agent');\r\n      setTranscript([]);\r\n    },\r\n    onDisconnect: () => console.log('Disconnected'),\r\n    onEvent: (event) => {\r\n      if (event.type === 'transcript') {\r\n        setTranscript(prev => [...prev, `User: ${event.data.text}`]);\r\n      } else if (event.type === 'agent_response') {\r\n        setTranscript(prev => [...prev, `Agent: ${event.data.text}`]);\r\n      }\r\n    },\r\n    onError: (error) => console.error('Error:', error),\r\n\r\n    // Regional compliance\r\n    serverLocation: 'us'\r\n  });\r\n\r\n  return (\r\n    <div>\r\n      <div>\r\n        <button onClick={startConversation} disabled={status === 'connected'}>\r\n          Start Conversation\r\n        </button>\r\n        <button onClick={stopConversation} disabled={status !== 'connected'}>\r\n          Stop\r\n        </button>\r\n      </div>\r\n\r\n      <div>Status: {status}</div>\r\n      <div>{isSpeaking && 'Agent is speaking...'}</div>\r\n\r\n      <div>\r\n        <h3>Transcript</h3>\r\n        {transcript.map((line, i) => (\r\n          <p key={i}>{line}</p>\r\n        ))}\r\n      </div>\r\n    </div>\r\n  );\r\n}\r\n```\r\n\r\n### JavaScript SDK (`@elevenlabs/client`)\r\n\r\nFor vanilla JavaScript projects (no React).\r\n\r\n**Installation**:\r\n```bash\r\nnpm install @elevenlabs/client\r\n```\r\n\r\n**Example**:\r\n```javascript\r\nimport { Conversation } from '@elevenlabs/client';\r\n\r\nconst conversation = new Conversation({\r\n  agentId: 'your-agent-id',\r\n  apiKey: process.env.ELEVENLABS_API_KEY,\r\n\r\n  onConnect: () => console.log('Connected'),\r\n  onDisconnect: () => console.log('Disconnected'),\r\n\r\n  onEvent: (event) => {\r\n    switch (event.type) {\r\n      case 'transcript':\r\n        document.getElementById('user-text').textContent = event.data.text;\r\n        break;\r\n      case 'agent_response':\r\n        document.getElementById('agent-text').textContent = event.data.text;\r\n        break;\r\n    }\r\n  }\r\n});\r\n\r\n// Start conversation\r\ndocument.getElementById('start-btn').addEventListener('click', async () => {\r\n  await conversation.start();\r\n});\r\n\r\n// Stop conversation\r\ndocument.getElementById('stop-btn').addEventListener('click', async () => {\r\n  await conversation.stop();\r\n});\r\n```\r\n\r\n### Connection Types: WebRTC vs WebSocket\r\n\r\nElevenLabs SDKs support two connection types with different characteristics.\r\n\r\n**Comparison Table**:\r\n\r\n| Feature | WebSocket | WebRTC |\r\n|---------|-----------|--------|\r\n| **Authentication** | `signedUrl` | `conversationToken` |\r\n| **Audio Format** | Configurable | PCM_48000 (hardcoded) |\r\n| **Sample Rate** | Configurable (16k, 24k, 48k) | 48000 (hardcoded) |\r\n| **Latency** | Standard | Lower |\r\n| **Device Switching** | Flexible | Limited (format locked) |\r\n| **Best For** | General use, flexibility | Low-latency requirements |\r\n\r\n**WebSocket Configuration** (default):\r\n\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\n\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-agent-id',\r\n\r\n  // WebSocket uses signed URL\r\n  signedUrl: async () => {\r\n    const response = await fetch('/api/elevenlabs/auth');\r\n    const { signedUrl } = await response.json();\r\n    return signedUrl;\r\n  },\r\n\r\n  // Connection type (optional, defaults to 'websocket')\r\n  connectionType: 'websocket',\r\n\r\n  // Audio config (flexible)\r\n  audioConfig: {\r\n    sampleRate: 24000, // 16000, 24000, or 48000\r\n    format: 'PCM_24000'\r\n  }\r\n});\r\n```\r\n\r\n**WebRTC Configuration**:\r\n\r\n```typescript\r\nconst { startConversation } = useConversation({\r\n  agentId: 'your-agent-id',\r\n\r\n  // WebRTC uses conversation token (different auth flow)\r\n  conversationToken: async () => {\r\n    const response = await fetch('/api/elevenlabs/token');\r\n    const { token } = await response.json();\r\n    return token;\r\n  },\r\n\r\n  // Connection type\r\n  connectionType: 'webrtc',\r\n\r\n  // Audio format is HARDCODED to PCM_48000 (not configurable)\r\n  // audioConfig ignored for WebRTC\r\n});\r\n```\r\n\r\n**Backend Token Endpoints**:\r\n\r\n```typescript\r\n// WebSocket signed URL (GET /v1/convai/conversation/get-signed-url)\r\napp.get('/api/elevenlabs/auth', async (req, res) => {\r\n  const response = await fetch(\r\n    `https://api.elevenlabs.io/v1/convai/conversation/get-signed-url?agent_id=${AGENT_ID}`,\r\n    { headers: { 'xi-api-key': ELEVENLABS_API_KEY } }\r\n  );\r\n  const { signed_url } = await response.json();\r\n  res.json({ signedUrl: signed_url });\r\n});\r\n\r\n// WebRTC conversation token (GET /v1/convai/conversation/token)\r\napp.get('/api/elevenlabs/token', async (req, res) => {\r\n  const response = await fetch(\r\n    `https://api.elevenlabs.io/v1/convai/conversation/token?agent_id=${AGENT_ID}`,\r\n    { headers: { 'xi-api-key': ELEVENLABS_API_KEY } }\r\n  );\r\n  const { conversation_token } = await response.json();\r\n  res.json({ token: conversation_token });\r\n});\r\n```\r\n\r\n**When to Use Each**:\r\n\r\n| Use WebSocket When | Use WebRTC When |\r\n|--------------------|-----------------|\r\n| Need flexible audio formats | Need lowest possible latency |\r\n| Switching between audio devices frequently | Audio format can be locked to 48kHz |\r\n| Standard latency is acceptable | Building real-time applications |\r\n| Need maximum configuration control | Performance is critical |\r\n\r\n**Gotchas**:\r\n- WebRTC hardcodes PCM_48000 - no way to change format\r\n- Device switching in WebRTC limited by fixed format\r\n- Different authentication methods (signedUrl vs conversationToken)\r\n- WebRTC may have better performance but less flexibility\r\n\r\n### React Native SDK (Expo)\r\n\r\n**Installation**:\r\n```bash\r\nnpx expo install @elevenlabs/react-native @livekit/react-native @livekit/react-native-webrtc livekit-client\r\n```\r\n\r\n**Requirements**:\r\n- Expo SDK 47+\r\n- iOS 14.0+ / macOS 11.0+\r\n- **Custom dev build required** (Expo Go not supported)\r\n\r\n**Example**:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react-native';\r\nimport { View, Button, Text } from 'react-native';\r\nimport { z } from 'zod';\r\n\r\nexport default function App() {\r\n  const { startConversation, stopConversation, status } = useConversation({\r\n    agentId: 'your-agent-id',\r\n    signedUrl: 'https://api.elevenlabs.io/v1/convai/auth/...',\r\n\r\n    clientTools: {\r\n      updateProfile: {\r\n        description: \"Update user profile\",\r\n        parameters: z.object({\r\n          name: z.string()\r\n        }),\r\n        handler: async ({ name }) => {\r\n          console.log('Updating profile:', name);\r\n          return { success: true };\r\n        }\r\n      }\r\n    }\r\n  });\r\n\r\n  return (\r\n    <View style={{ padding: 20 }}>\r\n      <Button title=\"Start\" onPress={startConversation} />\r\n      <Button title=\"Stop\" onPress={stopConversation} />\r\n      <Text>Status: {status}</Text>\r\n    </View>\r\n  );\r\n}\r\n```\r\n\r\n**Gotchas**:\r\n- Requires custom dev build (not Expo Go)\r\n- iOS/macOS only (Android support via Kotlin SDK, not yet officially released)\r\n\r\n### Swift SDK (iOS/macOS)\r\n\r\n**Installation** (Swift Package Manager):\r\n```swift\r\ndependencies: [\r\n  .package(url: \"https://github.com/elevenlabs/elevenlabs-swift-sdk\", from: \"1.0.0\")\r\n]\r\n```\r\n\r\n**Requirements**:\r\n- iOS 14.0+ / macOS 11.0+\r\n- Swift 5.9+\r\n\r\n**Use Cases**:\r\n- Native iOS apps\r\n- macOS applications\r\n- watchOS (with limitations)\r\n\r\n### Widget (Embeddable Web Component)\r\n\r\n**Installation**:\r\nCopy-paste embed code from dashboard or use this template:\r\n\r\n```html\r\n<script src=\"https://elevenlabs.io/convai-widget/index.js\"></script>\r\n<script>\r\n  ElevenLabsWidget.init({\r\n    agentId: 'your-agent-id',\r\n\r\n    // Theming\r\n    theme: {\r\n      primaryColor: '#3B82F6',\r\n      backgroundColor: '#1F2937',\r\n      textColor: '#F9FAFB'\r\n    },\r\n\r\n    // Position\r\n    position: 'bottom-right', // 'bottom-left' | 'bottom-right'\r\n\r\n    // Custom branding\r\n    branding: {\r\n      logo: 'https://example.com/logo.png',\r\n      name: 'Support Agent'\r\n    }\r\n  });\r\n</script>\r\n```\r\n\r\n**Use Cases**:\r\n- Customer support chat bubbles\r\n- Website assistants\r\n- Lead capture forms\r\n\r\n### Scribe (Real-Time Speech-to-Text)\r\n\r\n**Status**: Closed Beta (requires sales contact)\r\n**Release**: 2025\r\n\r\nScribe is ElevenLabs' real-time speech-to-text service for low-latency transcription.\r\n\r\n**Capabilities**:\r\n- Microphone streaming (real-time transcription)\r\n- Pre-recorded audio file transcription\r\n- Partial (interim) and final transcripts\r\n- Word-level timestamps\r\n- Voice Activity Detection (VAD)\r\n- Manual and automatic commit strategies\r\n- Language detection\r\n- PCM_16000 and PCM_24000 audio formats\r\n\r\n**Authentication**:\r\nUses single-use tokens (not API keys):\r\n\r\n```typescript\r\n// Fetch token from backend\r\nconst response = await fetch('/api/scribe/token');\r\nconst { token } = await response.json();\r\n\r\n// Backend endpoint\r\nconst token = await client.scribe.getToken();\r\nreturn { token };\r\n```\r\n\r\n**React Hook (`useScribe`)**:\r\n\r\n```typescript\r\nimport { useScribe } from '@elevenlabs/react';\r\n\r\nexport default function Transcription() {\r\n  const {\r\n    connect,\r\n    disconnect,\r\n    startRecording,\r\n    stopRecording,\r\n    status,\r\n    transcript,\r\n    partialTranscript\r\n  } = useScribe({\r\n    token: async () => {\r\n      const response = await fetch('/api/scribe/token');\r\n      const { token } = await response.json();\r\n      return token;\r\n    },\r\n\r\n    // Commit strategy\r\n    commitStrategy: 'vad', // 'vad' (automatic) or 'manual'\r\n\r\n    // Audio format\r\n    sampleRate: 16000, // 16000 or 24000\r\n\r\n    // Events\r\n    onConnect: () => console.log('Connected to Scribe'),\r\n    onDisconnect: () => console.log('Disconnected'),\r\n\r\n    onPartialTranscript: (text) => {\r\n      console.log('Interim:', text);\r\n    },\r\n\r\n    onFinalTranscript: (text, timestamps) => {\r\n      console.log('Final:', text);\r\n      console.log('Timestamps:', timestamps); // Word-level timing\r\n    },\r\n\r\n    onError: (error) => console.error('Error:', error)\r\n  });\r\n\r\n  return (\r\n    <div>\r\n      <button onClick={connect}>Connect</button>\r\n      <button onClick={startRecording}>Start Recording</button>\r\n      <button onClick={stopRecording}>Stop Recording</button>\r\n      <button onClick={disconnect}>Disconnect</button>\r\n\r\n      <p>Status: {status}</p>\r\n      <p>Partial: {partialTranscript}</p>\r\n      <p>Final: {transcript}</p>\r\n    </div>\r\n  );\r\n}\r\n```\r\n\r\n**JavaScript SDK (`Scribe.connect`)**:\r\n\r\n```javascript\r\nimport { Scribe } from '@elevenlabs/client';\r\n\r\nconst connection = await Scribe.connect({\r\n  token: 'your-single-use-token',\r\n\r\n  sampleRate: 16000,\r\n  commitStrategy: 'vad',\r\n\r\n  onPartialTranscript: (text) => {\r\n    document.getElementById('interim').textContent = text;\r\n  },\r\n\r\n  onFinalTranscript: (text, timestamps) => {\r\n    const finalDiv = document.getElementById('final');\r\n    finalDiv.textContent += text + ' ';\r\n\r\n    // timestamps: [{ word: 'hello', start: 0.5, end: 0.8 }, ...]\r\n  },\r\n\r\n  onError: (error) => {\r\n    console.error('Scribe error:', error);\r\n  }\r\n});\r\n\r\n// Start recording from microphone\r\nawait connection.startRecording();\r\n\r\n// Stop recording\r\nawait connection.stopRecording();\r\n\r\n// Manual commit (if commitStrategy: 'manual')\r\nawait connection.commit();\r\n\r\n// Disconnect\r\nawait connection.disconnect();\r\n```\r\n\r\n**Transcribing Pre-Recorded Files**:\r\n\r\n```typescript\r\nimport { Scribe } from '@elevenlabs/client';\r\n\r\nconst connection = await Scribe.connect({ token });\r\n\r\n// Send audio buffer\r\nconst audioBuffer = fs.readFileSync('recording.pcm');\r\nawait connection.sendAudioData(audioBuffer);\r\n\r\n// Manually commit to get final transcript\r\nawait connection.commit();\r\n\r\n// Wait for final transcript event\r\n```\r\n\r\n**Event Types**:\r\n- `SESSION_STARTED`: Connection established\r\n- `PARTIAL_TRANSCRIPT`: Interim transcription (unbuffered)\r\n- `FINAL_TRANSCRIPT`: Complete sentence/phrase\r\n- `FINAL_TRANSCRIPT_WITH_TIMESTAMPS`: Final + word timing\r\n- `ERROR`: Transcription error\r\n- `AUTH_ERROR`: Authentication failed\r\n- `OPEN`: WebSocket opened\r\n- `CLOSE`: WebSocket closed\r\n\r\n**Commit Strategies**:\r\n\r\n| Strategy | Description | Use When |\r\n|----------|-------------|----------|\r\n| `vad` (automatic) | Voice Activity Detection auto-commits on silence | Real-time transcription |\r\n| `manual` | Call `connection.commit()` explicitly | Pre-recorded files, controlled commits |\r\n\r\n**Audio Formats**:\r\n- `PCM_16000` (16kHz, 16-bit PCM)\r\n- `PCM_24000` (24kHz, 16-bit PCM)\r\n\r\n**Gotchas**:\r\n- Token is **single-use** (expires after one connection)\r\n- Closed beta - requires sales contact\r\n- Language detection automatic (no manual override)\r\n- No speaker diarization yet\r\n\r\n**When to Use Scribe**:\r\n- Building custom transcription UI\r\n- Real-time captions/subtitles\r\n- Voice note apps\r\n- Meeting transcription\r\n- Accessibility features\r\n\r\n**When NOT to Use**:\r\nUse **Agents Platform** instead if you need:\r\n- Conversational AI (LLM + TTS)\r\n- Two-way voice interaction\r\n- Agent responses\r\n\r\n---",
    "13. Common Errors & Solutions": "add_header Content-Security-Policy \"\r\n  default-src 'self';\r\n  script-src 'self' https://elevenlabs.io;\r\n  connect-src 'self' https://api.elevenlabs.io wss://api.elevenlabs.io;\r\n  worker-src 'self';\r\n\" always;\r\n```\r\n\r\n**Worklet Files Location**:\r\n```\r\nnode_modules/@elevenlabs/client/dist/worklets/\r\n├── rawAudioProcessor.worklet.js\r\n└── audioConcatProcessor.worklet.js\r\n```\r\n\r\n**Gotchas**:\r\n- Worklet files must be served from same origin (CORS restriction)\r\n- Update worklet files when upgrading `@elevenlabs/client`\r\n- Paths must match exactly (case-sensitive)\r\n\r\n**When You Need This**:\r\n- Enterprise applications with strict CSP\r\n- Government/financial apps\r\n- Apps with security audits\r\n- Any app blocking `blob:` URLs\r\n\r\n---",
    "8. Analytics & Monitoring": "### Conversation Analysis\r\n\r\nExtract structured data from conversation transcripts.\r\n\r\n**Features**:\r\n\r\n#### Success Evaluation (LLM-Based)\r\n```json\r\n{\r\n  \"evaluation_criteria\": {\r\n    \"resolution\": \"Was the customer's issue resolved?\",\r\n    \"sentiment\": \"Was the conversation tone positive?\",\r\n    \"compliance\": \"Did the agent follow company policies?\"\r\n  }\r\n}\r\n```\r\n\r\n#### Data Collection\r\n```json\r\n{\r\n  \"data_collection\": {\r\n    \"fields\": [\r\n      { \"name\": \"customer_name\", \"type\": \"string\" },\r\n      { \"name\": \"issue_type\", \"type\": \"enum\", \"values\": [\"billing\", \"technical\", \"other\"] },\r\n      { \"name\": \"satisfaction\", \"type\": \"number\", \"range\": [1, 5] }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n**Access**:\r\n- Via Post-call Webhooks (real-time)\r\n- Via Analytics Dashboard (batch)\r\n- Via API (on-demand)\r\n\r\n### Analytics Dashboard\r\n\r\n**Metrics**:\r\n- **Resolution Rates**: % of issues resolved\r\n- **CX Metrics**: Sentiment, satisfaction, CSAT\r\n- **Compliance**: Policy adherence, guardrail violations\r\n- **Performance**: Response time, call duration, concurrency\r\n- **Tool Usage**: Tool call frequency, success rates\r\n- **LLM Costs**: Track costs per agent/conversation\r\n\r\n**Access**: Dashboard → Analytics tab\r\n\r\n---",
    "9. Privacy & Compliance": "### Data Retention\r\n\r\n**Default**: 2 years (GDPR-compliant)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"privacy\": {\r\n    \"transcripts\": {\r\n      \"retention_days\": 730  // 2 years (GDPR)\r\n    },\r\n    \"audio\": {\r\n      \"retention_days\": 2190  // 6 years (HIPAA)\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Compliance Recommendations**:\r\n- **GDPR**: Align with data processing purposes (typically 1-2 years)\r\n- **HIPAA**: Minimum 6 years for medical records\r\n- **SOC 2**: Encryption in transit and at rest (automatic)\r\n\r\n### Encryption\r\n\r\n- **In Transit**: TLS 1.3\r\n- **At Rest**: AES-256\r\n- **Regional Compliance**: Data residency (US, EU, India)\r\n\r\n**Regional Configuration**:\r\n```typescript\r\nconst { startConversation } = useConversation({\r\n  serverLocation: 'eu-residency' // 'us' | 'global' | 'eu-residency' | 'in-residency'\r\n});\r\n```\r\n\r\n### Zero Retention Mode\r\n\r\nFor maximum privacy, enable zero retention to immediately delete all conversation data.\r\n\r\n**Limitations**:\r\n- No conversation history\r\n- No analytics\r\n- No post-call webhooks\r\n- No MCP tool integrations\r\n\r\n---",
    "7. Testing & Evaluation": "elevenlabs test load \\\r\n  --users 100 \\\r\n  --spawn-rate 1 \\\r\n  --duration 600\r\n```\r\n\r\n**Gotchas**:\r\n- Load testing consumes real API credits\r\n- Use burst pricing for expected traffic spikes\r\n- Requires careful planning to avoid hitting rate limits\r\n\r\n### Simulation API (Programmatic Testing)\r\n\r\n**API Endpoint**:\r\n```bash\r\nPOST /v1/convai/agents/:agent_id/simulate\r\n```\r\n\r\n**Example**:\r\n```typescript\r\nconst simulation = await client.agents.simulate({\r\n  agent_id: 'agent_123',\r\n  scenario: 'Customer requests refund',\r\n  user_messages: [\r\n    \"I want a refund for order #12345\",\r\n    \"I ordered it last week\",\r\n    \"Yes, please process it\"\r\n  ],\r\n  success_criteria: [\r\n    \"Agent acknowledges request\",\r\n    \"Agent asks for order details\",\r\n    \"Agent provides refund timeline\"\r\n  ]\r\n});\r\n\r\nconsole.log('Test passed:', simulation.passed);\r\nconsole.log('Criteria met:', simulation.evaluation.criteria_met);\r\n```\r\n\r\n**Use Cases**:\r\n- CI/CD integration (test before deploy)\r\n- Regression testing\r\n- Load testing preparation\r\n\r\n---",
    "1. Quick Start (3 Integration Paths)": "elevenlabs agents push --env prod\r\n```\r\n\r\n**Project Structure Created**:\r\n```\r\nyour_project/\r\n├── agents.json              # Agent registry\r\n├── tools.json               # Tool configurations\r\n├── tests.json               # Test configurations\r\n├── agent_configs/           # Individual agent files\r\n├── tool_configs/            # Tool configuration files\r\n└── test_configs/            # Test configuration files\r\n```\r\n\r\n### Path C: API (Programmatic Agent Management)\r\n\r\nFor creating agents dynamically (multi-tenant, SaaS platforms).\r\n\r\n**Installation**:\r\n```bash\r\nnpm install elevenlabs\r\n```\r\n\r\n**Example**:\r\n```typescript\r\nimport { ElevenLabsClient } from 'elevenlabs';\r\n\r\nconst client = new ElevenLabsClient({\r\n  apiKey: process.env.ELEVENLABS_API_KEY\r\n});\r\n\r\n// Create agent\r\nconst agent = await client.agents.create({\r\n  name: 'Support Bot',\r\n  conversation_config: {\r\n    agent: {\r\n      prompt: {\r\n        prompt: \"You are a helpful customer support agent.\",\r\n        llm: \"gpt-4o\",\r\n        temperature: 0.7\r\n      },\r\n      first_message: \"Hello! How can I help you today?\",\r\n      language: \"en\"\r\n    },\r\n    tts: {\r\n      model_id: \"eleven_turbo_v2_5\",\r\n      voice_id: \"your-voice-id\"\r\n    }\r\n  }\r\n});\r\n\r\nconsole.log('Agent created:', agent.agent_id);\r\n```\r\n\r\n---",
    "10. Cost Optimization": "### LLM Caching\r\n\r\nReduce costs by caching repeated inputs.\r\n\r\n**How It Works**:\r\n- **First request**: Full cost (`input_cache_write`)\r\n- **Subsequent requests**: Reduced cost (`input_cache_read`)\r\n- **Automatic cache invalidation** after TTL\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"llm_config\": {\r\n    \"caching\": {\r\n      \"enabled\": true,\r\n      \"ttl_seconds\": 3600  // 1 hour\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Repeated system prompts\r\n- Large knowledge bases\r\n- Frequent tool definitions\r\n\r\n**Savings**: Up to 90% on cached inputs\r\n\r\n### Model Swapping\r\n\r\nSwitch between models based on cost/performance needs.\r\n\r\n**Available Models**:\r\n- **GPT-4o** (high cost, high quality)\r\n- **GPT-4o-mini** (medium cost, good quality)\r\n- **Claude Sonnet 4.5** (high cost, best reasoning)\r\n- **Gemini 2.5 Flash** (low cost, fast)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"llm_config\": {\r\n    \"model\": \"gpt-4o-mini\"  // Swap anytime via dashboard or API\r\n  }\r\n}\r\n```\r\n\r\n### Burst Pricing\r\n\r\nTemporarily exceed concurrency limits during high-demand periods.\r\n\r\n**How It Works**:\r\n- **Normal**: Your subscription concurrency limit (e.g., 10 simultaneous calls)\r\n- **Burst**: Up to 3x your limit (e.g., 30 simultaneous calls)\r\n- **Cost**: 2x the standard rate for burst calls\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"call_limits\": {\r\n    \"burst_pricing_enabled\": true\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Black Friday traffic spikes\r\n- Product launches\r\n- Seasonal demand (holidays)\r\n\r\n**Gotchas**:\r\n- Burst calls cost 2x (plan accordingly)\r\n- Not unlimited (3x cap)\r\n\r\n---",
    "5. Tools (4 Types)": "ElevenLabs supports 4 distinct tool types, each with different execution patterns.\r\n\r\n### A. Client Tools\r\n\r\nExecute operations on the client side (browser or mobile app).\r\n\r\n**Use Cases**:\r\n- Update UI elements (shopping cart, notifications)\r\n- Trigger navigation (redirect user to page)\r\n- Access local storage\r\n- Control media playback\r\n\r\n**React Example**:\r\n```typescript\r\nimport { useConversation } from '@elevenlabs/react';\r\nimport { z } from 'zod';\r\n\r\nconst { startConversation } = useConversation({\r\n  clientTools: {\r\n    updateCart: {\r\n      description: \"Update the shopping cart with new items\",\r\n      parameters: z.object({\r\n        item: z.string().describe(\"The item name\"),\r\n        quantity: z.number().describe(\"Quantity to add\")\r\n      }),\r\n      handler: async ({ item, quantity }) => {\r\n        // Client-side logic\r\n        const cart = getCart();\r\n        cart.add(item, quantity);\r\n        updateUI(cart);\r\n        return { success: true, total: cart.total };\r\n      }\r\n    },\r\n    navigate: {\r\n      description: \"Navigate to a different page\",\r\n      parameters: z.object({\r\n        url: z.string().describe(\"The URL to navigate to\")\r\n      }),\r\n      handler: async ({ url }) => {\r\n        window.location.href = url;\r\n        return { success: true };\r\n      }\r\n    }\r\n  }\r\n});\r\n```\r\n\r\n**Gotchas**:\r\n- Tool names are **case-sensitive**\r\n- Must return a value (agent reads the return value)\r\n- Handler can be async\r\n\r\n### B. Server Tools (Webhooks)\r\n\r\nMake HTTP requests to external APIs from ElevenLabs servers.\r\n\r\n**Use Cases**:\r\n- Fetch real-time data (weather, stock prices)\r\n- Update CRM systems (Salesforce, HubSpot)\r\n- Process payments (Stripe, PayPal)\r\n- Send emails/SMS (SendGrid, Twilio)\r\n\r\n**Configuration via CLI**:\r\n```bash\r\nelevenlabs tools add-webhook \"Get Weather\" --config-path tool_configs/get-weather.json\r\n```\r\n\r\n**tool_configs/get-weather.json**:\r\n```json\r\n{\r\n  \"name\": \"get_weather\",\r\n  \"description\": \"Fetch current weather for a city\",\r\n  \"url\": \"https://api.weather.com/v1/current\",\r\n  \"method\": \"GET\",\r\n  \"parameters\": {\r\n    \"type\": \"object\",\r\n    \"properties\": {\r\n      \"city\": {\r\n        \"type\": \"string\",\r\n        \"description\": \"The city name (e.g., 'London', 'New York')\"\r\n      }\r\n    },\r\n    \"required\": [\"city\"]\r\n  },\r\n  \"headers\": {\r\n    \"Authorization\": \"Bearer {{secret__weather_api_key}}\"\r\n  }\r\n}\r\n```\r\n\r\n**Dynamic Variables in Tools**:\r\n```json\r\n{\r\n  \"url\": \"https://api.crm.com/customers/{{user_id}}\",\r\n  \"headers\": {\r\n    \"X-API-Key\": \"{{secret__crm_api_key}}\"\r\n  }\r\n}\r\n```\r\n\r\n**Gotchas**:\r\n- Secret variables only work in headers (not URL or body)\r\n- Schema description guides LLM on when to use tool\r\n\r\n### C. MCP Tools (Model Context Protocol)\r\n\r\nConnect to external MCP servers for standardized tool access.\r\n\r\n**Use Cases**:\r\n- Access databases (PostgreSQL, MongoDB)\r\n- Query knowledge bases (Pinecone, Weaviate)\r\n- Integrate with IDEs (VS Code, Cursor)\r\n- Connect to data sources (Google Drive, Notion)\r\n\r\n**Configuration**:\r\n1. Navigate to MCP server integrations in dashboard\r\n2. Click \"Add Custom MCP Server\"\r\n3. Configure:\r\n   - **Name**: Server identifier\r\n   - **Server URL**: SSE or HTTP endpoint\r\n   - **Secret Token**: Optional auth header\r\n4. Test connectivity and discover tools\r\n5. Add to agents (public or private)\r\n\r\n**Approval Modes**:\r\n- **Always Ask**: Maximum security, requires permission per tool call\r\n- **Fine-Grained**: Per-tool approval settings\r\n- **No Approval**: Auto-execute all tools\r\n\r\n**Gotchas**:\r\n- Only SSE and HTTP streamable transport supported\r\n- MCP servers must be publicly accessible or behind auth\r\n- Not available for Zero Retention Mode\r\n- Not compatible with HIPAA compliance\r\n\r\n**Example: Using ElevenLabs MCP Server in Claude Desktop**:\r\n```json\r\n{\r\n  \"mcpServers\": {\r\n    \"ElevenLabs\": {\r\n      \"command\": \"uvx\",\r\n      \"args\": [\"elevenlabs-mcp\"],\r\n      \"env\": {\r\n        \"ELEVENLABS_API_KEY\": \"<your-key>\",\r\n        \"ELEVENLABS_MCP_OUTPUT_MODE\": \"files\"\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### D. System Tools\r\n\r\nModify the internal state of the conversation without external calls.\r\n\r\n**Use Cases**:\r\n- Update conversation context\r\n- Switch between workflow nodes\r\n- Modify agent behavior mid-conversation\r\n- Track conversation state\r\n\r\n**Built-in System Tools**:\r\n- `end_call` - End the conversation\r\n- `detect_language` - Detect user's language\r\n- `transfer_agent` - Switch to different agent/workflow node\r\n- `transfer_to_number` - Transfer to external phone number (telephony only)\r\n- `dtmf_playpad` - Display DTMF keypad (telephony only)\r\n- `voicemail_detection` - Detect voicemail (telephony only)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"system_tools\": [\r\n    {\r\n      \"name\": \"update_conversation_state\",\r\n      \"description\": \"Update the conversation context with new information\",\r\n      \"parameters\": {\r\n        \"key\": { \"type\": \"string\" },\r\n        \"value\": { \"type\": \"string\" }\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n**Gotchas**:\r\n- System tools don't trigger external APIs\r\n- Changes are ephemeral (lost after conversation ends)\r\n- Useful for workflows and state management\r\n\r\n---",
    "12. CLI & DevOps (\"Agents as Code\")": ".env\r\n.elevenlabs/\r\n*.secret.json\r\n```\r\n\r\n---",
    "4. Knowledge Base & RAG": "### RAG (Retrieval-Augmented Generation)\r\n\r\nEnable agents to access large knowledge bases without loading entire documents into context.\r\n\r\n**How It Works**:\r\n1. Upload documents (PDF, TXT, DOCX) to knowledge base\r\n2. ElevenLabs automatically computes vector embeddings\r\n3. During conversation, relevant chunks retrieved based on semantic similarity\r\n4. LLM uses retrieved context to generate responses\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"agent\": {\r\n    \"prompt\": {\r\n      \"knowledge_base\": [\"doc_id_1\", \"doc_id_2\"]\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Upload Documents via API**:\r\n```typescript\r\nimport { ElevenLabsClient } from 'elevenlabs';\r\n\r\nconst client = new ElevenLabsClient({ apiKey: process.env.ELEVENLABS_API_KEY });\r\n\r\n// Upload document\r\nconst doc = await client.knowledgeBase.upload({\r\n  file: fs.createReadStream('support_docs.pdf'),\r\n  name: 'Support Documentation'\r\n});\r\n\r\n// Compute RAG index\r\nawait client.knowledgeBase.computeRagIndex({\r\n  document_id: doc.id,\r\n  embedding_model: 'e5_mistral_7b' // or 'multilingual_e5_large'\r\n});\r\n```\r\n\r\n**Retrieval Configuration**:\r\n```json\r\n{\r\n  \"knowledge_base_config\": {\r\n    \"max_chunks\": 5,              // Number of chunks to retrieve\r\n    \"vector_distance_threshold\": 0.8  // Similarity threshold\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Product documentation agents\r\n- Customer support (FAQ, help center)\r\n- Educational tutors (textbooks, lecture notes)\r\n- Healthcare assistants (medical guidelines)\r\n\r\n**Gotchas**:\r\n- RAG adds ~500ms latency per query\r\n- More chunks = higher cost but better context\r\n- Higher vector distance = more context but potentially less relevant\r\n- Documents must be indexed before use (can take minutes for large docs)\r\n\r\n---",
    "3. Voice & Language Features": "### Multi-Voice Support\r\n\r\nDynamically switch between different voices during a single conversation.\r\n\r\n**Use Cases**:\r\n- Multi-character storytelling (different voice per character)\r\n- Language tutoring (native speaker voices for each language)\r\n- Role-playing scenarios (customer vs agent)\r\n- Emotional agents (different voices for different moods)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"agent\": {\r\n    \"prompt\": {\r\n      \"prompt\": \"When speaking as the customer, use voice_id 'customer_voice_abc123'. When speaking as the agent, use voice_id 'agent_voice_def456'.\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n**Gotchas**:\r\n- Voice switching adds ~200ms latency per switch\r\n- Requires careful prompt engineering to trigger switches correctly\r\n- Not all voices work equally well for all characters\r\n\r\n### Pronunciation Dictionary\r\n\r\nCustomize how the agent pronounces specific words or phrases.\r\n\r\n**Supported Formats**:\r\n- **IPA** (International Phonetic Alphabet)\r\n- **CMU** (Carnegie Mellon University Pronouncing Dictionary)\r\n- **Word Substitutions** (replace words before TTS)\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"pronunciation_dictionary\": [\r\n    {\r\n      \"word\": \"ElevenLabs\",\r\n      \"pronunciation\": \"ɪˈlɛvənlæbz\",\r\n      \"format\": \"ipa\"\r\n    },\r\n    {\r\n      \"word\": \"API\",\r\n      \"pronunciation\": \"ey-pee-ay\",\r\n      \"format\": \"cmu\"\r\n    },\r\n    {\r\n      \"word\": \"AI\",\r\n      \"substitution\": \"artificial intelligence\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- Brand names (e.g., \"IKEA\" → \"ee-KAY-uh\")\r\n- Acronyms (e.g., \"API\" → \"A-P-I\" or \"ay-pee-eye\")\r\n- Technical terms\r\n- Character names in storytelling\r\n\r\n**Gotcha**: Only Turbo v2/v2.5 models support phoneme-based pronunciation. Other models silently skip phoneme entries but still process word substitutions.\r\n\r\n### Speed Control\r\n\r\nAdjust speaking speed dynamically (0.7x - 1.2x).\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"voice_settings\": {\r\n    \"speed\": 1.0 // 0.7 = slow, 1.0 = normal, 1.2 = fast\r\n  }\r\n}\r\n```\r\n\r\n**Use Cases**:\r\n- **Slow (0.7x-0.9x)**: Accessibility, children, non-native speakers\r\n- **Normal (1.0x)**: Default for most use cases\r\n- **Fast (1.1x-1.2x)**: Urgent notifications, power users\r\n\r\n**Best Practices**:\r\n- Use 0.9x-1.1x for natural-sounding adjustments\r\n- Extreme values (below 0.7 or above 1.2) degrade quality\r\n- Speed can be adjusted per agent, not per utterance\r\n\r\n### Voice Design\r\n\r\nCreate custom voices using ElevenLabs Voice Design tool.\r\n\r\n**Workflow**:\r\n1. Navigate to Voice Library → Create Voice\r\n2. Use Voice Design (text-to-voice) or Voice Cloning (sample audio)\r\n3. Test voice with sample text\r\n4. Save voice to library\r\n5. Use `voice_id` in agent configuration\r\n\r\n**Voice Cloning Best Practices**:\r\n- Use clean audio samples (no background noise, music, or pops)\r\n- Maintain consistent microphone distance\r\n- Avoid extreme volumes (whispering or shouting)\r\n- 1-2 minutes of audio recommended\r\n\r\n**Gotcha**: Using English-trained voices for non-English languages causes pronunciation issues. Always use language-matched voices.\r\n\r\n### Language Configuration\r\n\r\nSupport for 32+ languages with automatic detection and in-conversation switching.\r\n\r\n**Configuration**:\r\n```json\r\n{\r\n  \"agent\": {\r\n    \"language\": \"en\" // ISO 639-1 code\r\n  }\r\n}\r\n```\r\n\r\n**Multi-Language Presets** (Different Voice Per Language):\r\n```json\r\n{\r\n  \"conversation_config\": {\r\n    \"language_presets\": [\r\n      {\r\n        \"language\": \"en\",\r\n        \"voice_id\": \"en_voice_id\",\r\n        \"first_message\": \"Hello! How can I help you today?\"\r\n      },\r\n      {\r\n        \"language\": \"es\",\r\n        \"voice_id\": \"es_voice_id\",\r\n        \"first_message\": \"¡Hola! ¿Cómo puedo ayudarte hoy?\"\r\n      },\r\n      {\r\n        \"language\": \"fr\",\r\n        \"voice_id\": \"fr_voice_id\",\r\n        \"first_message\": \"Bonjour! Comment puis-je vous aider aujourd'hui?\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n**Automatic Language Detection**: Agent detects user's language and switches automatically.\r\n\r\n**Supported Languages**: English, Spanish, French, German, Italian, Portuguese, Dutch, Polish, Arabic, Chinese, Japanese, Korean, Hindi, and 18+ more.\r\n\r\n---",
    "Integration with Existing Skills": "This skill composes well with:\r\n\r\n- **cloudflare-worker-base** → Deploy agents on Cloudflare Workers edge network\r\n- **cloudflare-workers-ai** → Use Cloudflare LLMs as custom models in agents\r\n- **cloudflare-durable-objects** → Persistent conversation state and session management\r\n- **cloudflare-kv** → Cache agent configurations and user preferences\r\n- **nextjs** → React SDK integration in Next.js applications\r\n- **ai-sdk-core** → Vercel AI SDK provider for unified AI interface\r\n- **clerk-auth** → Authenticated voice sessions with user identity\r\n- **hono-routing** → API routes for webhooks and server tools\r\n\r\n---",
    "Additional Resources": "**Official Documentation**:\r\n- Platform Overview: https://elevenlabs.io/docs/agents-platform/overview\r\n- API Reference: https://elevenlabs.io/docs/api-reference\r\n- CLI GitHub: https://github.com/elevenlabs/cli\r\n\r\n**Examples**:\r\n- Official Examples: https://github.com/elevenlabs/elevenlabs-examples\r\n- MCP Server: https://github.com/elevenlabs/elevenlabs-mcp\r\n\r\n**Community**:\r\n- Discord: https://discord.com/invite/elevenlabs\r\n- Twitter: @elevenlabsio\r\n\r\n---\r\n\r\n**Production Tested**: WordPress Auditor, Customer Support Agents\r\n**Last Updated**: 2025-11-03\r\n**Package Versions**: elevenlabs@1.59.0, @elevenlabs/cli@0.2.0",
    "Overview": "ElevenLabs Agents Platform is a comprehensive solution for building production-ready conversational AI voice agents. The platform coordinates four core components:\r\n\r\n1. **ASR (Automatic Speech Recognition)** - Converts speech to text (32+ languages, sub-second latency)\r\n2. **LLM (Large Language Model)** - Reasoning and response generation (GPT, Claude, Gemini, custom models)\r\n3. **TTS (Text-to-Speech)** - Converts text to speech (5000+ voices, 31 languages, low latency)\r\n4. **Turn-Taking Model** - Proprietary model that handles conversation timing and interruptions\r\n\r\n### 🚨 Package Updates (November 2025)\r\n\r\nElevenLabs migrated to new scoped packages in August 2025:\r\n\r\n**DEPRECATED (Do not use):**\r\n- `@11labs/react` → **DEPRECATED**\r\n- `@11labs/client` → **DEPRECATED**\r\n\r\n**Current packages:**\r\n```bash\r\nnpm install @elevenlabs/react@0.9.1        # React SDK\r\nnpm install @elevenlabs/client@0.9.1       # JavaScript SDK\r\nnpm install @elevenlabs/react-native@0.5.2 # React Native SDK\r\nnpm install @elevenlabs/elevenlabs-js@2.21.0 # Base SDK\r\nnpm install -g @elevenlabs/agents-cli@0.2.0  # CLI\r\n```\r\n\r\nIf you have old packages installed, uninstall them first:\r\n```bash\r\nnpm uninstall @11labs/react @11labs/client\r\n```\r\n\r\n### When to Use This Skill\r\n\r\nUse this skill when:\r\n- Building voice-enabled customer support agents\r\n- Creating interactive voice response (IVR) systems\r\n- Developing conversational AI applications\r\n- Integrating telephony (Twilio, SIP trunking)\r\n- Implementing voice chat in web/mobile apps\r\n- Configuring agents via CLI (\"agents as code\")\r\n- Setting up RAG/knowledge bases for agents\r\n- Integrating MCP (Model Context Protocol) servers\r\n- Building HIPAA/GDPR-compliant voice systems\r\n- Optimizing LLM costs with caching strategies\r\n\r\n### Platform Capabilities\r\n\r\n**Design & Configure**:\r\n- Multi-step workflows with visual builder\r\n- System prompt engineering (6-component framework)\r\n- 5000+ voices across 31 languages\r\n- Pronunciation dictionaries (IPA/CMU formats)\r\n- Speed control (0.7x-1.2x)\r\n- RAG-powered knowledge bases\r\n- Dynamic variables and personalization\r\n\r\n**Connect & Deploy**:\r\n- React SDK (`@elevenlabs/react`)\r\n- JavaScript SDK (`@elevenlabs/client`)\r\n- React Native SDK (`@elevenlabs/react-native`)\r\n- Swift SDK (iOS/macOS)\r\n- Embeddable widget\r\n- Telephony integration (Twilio, SIP)\r\n- Scribe (Real-Time Speech-to-Text) - Beta\r\n\r\n**Operate & Optimize**:\r\n- Automated testing (scenario, tool call, load)\r\n- Conversation analysis and evaluation\r\n- Analytics dashboard (resolution rates, sentiment, compliance)\r\n- Privacy controls (GDPR, HIPAA, SOC 2)\r\n- Cost optimization (LLM caching, model swapping, burst pricing)\r\n- CLI for \"agents as code\" workflow\r\n\r\n---"
  }
}