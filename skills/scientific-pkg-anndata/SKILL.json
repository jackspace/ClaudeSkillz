{
  "description": "This skill should be used when working with annotated data matrices in Python, particularly for single-cell genomics analysis, managing experimental measurements with metadata, or handling large-scale biological datasets. Use when tasks involve AnnData objects, h5ad files, single-cell RNA-seq data, or integration with scanpy/scverse tools.",
  "references": {
    "files": [
      "references/best_practices.md",
      "references/concatenation.md",
      "references/data_structure.md",
      "references/io_operations.md",
      "references/manipulation.md"
    ]
  },
  "content": "```bash\r\npip install anndata\r\n\r\n\r\n### Creating an AnnData object\r\n```python\r\nimport anndata as ad\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nX = np.random.rand(100, 2000)  # 100 cells × 2000 genes\r\nadata = ad.AnnData(X)\r\n\r\nobs = pd.DataFrame({\r\n    'cell_type': ['T cell', 'B cell'] * 50,\r\n    'sample': ['A', 'B'] * 50\r\n}, index=[f'cell_{i}' for i in range(100)])\r\n\r\nvar = pd.DataFrame({\r\n    'gene_name': [f'Gene_{i}' for i in range(2000)]\r\n}, index=[f'ENSG{i:05d}' for i in range(2000)])\r\n\r\nadata = ad.AnnData(X=X, obs=obs, var=var)\r\n```\r\n\r\n### Reading data\r\n```python\r\nadata = ad.read_h5ad('data.h5ad')\r\n\r\nadata = ad.read_h5ad('large_data.h5ad', backed='r')\r\n\r\nadata = ad.read_csv('data.csv')\r\nadata = ad.read_loom('data.loom')\r\nadata = ad.read_10x_h5('filtered_feature_bc_matrix.h5')\r\n```\r\n\r\n### Writing data\r\n```python\r\nadata.write_h5ad('output.h5ad')\r\n\r\nadata.write_h5ad('output.h5ad', compression='gzip')\r\n\r\nadata.write_zarr('output.zarr')\r\nadata.write_csvs('output_dir/')\r\n```\r\n\r\n### Basic operations\r\n```python\r\nt_cells = adata[adata.obs['cell_type'] == 'T cell']\r\n\r\nsubset = adata[0:50, 0:100]\r\n\r\nadata.obs['quality_score'] = np.random.rand(adata.n_obs)\r\nadata.var['highly_variable'] = np.random.rand(adata.n_vars) > 0.8\r\n\r\n\r\n### 1. Data Structure\r\n\r\nUnderstand the AnnData object structure including X, obs, var, layers, obsm, varm, obsp, varp, uns, and raw components.\r\n\r\n**See**: `references/data_structure.md` for comprehensive information on:\r\n- Core components (X, obs, var, layers, obsm, varm, obsp, varp, uns, raw)\r\n- Creating AnnData objects from various sources\r\n- Accessing and manipulating data components\r\n- Memory-efficient practices\r\n\r\n### 2. Input/Output Operations\r\n\r\nRead and write data in various formats with support for compression, backed mode, and cloud storage.\r\n\r\n**See**: `references/io_operations.md` for details on:\r\n- Native formats (h5ad, zarr)\r\n- Alternative formats (CSV, MTX, Loom, 10X, Excel)\r\n- Backed mode for large datasets\r\n- Remote data access\r\n- Format conversion\r\n- Performance optimization\r\n\r\nCommon commands:\r\n```python\r\nadata = ad.read_h5ad('data.h5ad', backed='r')\r\nadata.write_h5ad('output.h5ad', compression='gzip')\r\n\r\nadata = ad.read_10x_h5('filtered_feature_bc_matrix.h5')\r\n\r\nadata = ad.read_mtx('matrix.mtx').T\r\n```\r\n\r\n### 3. Concatenation\r\n\r\nCombine multiple AnnData objects along observations or variables with flexible join strategies.\r\n\r\n**See**: `references/concatenation.md` for comprehensive coverage of:\r\n- Basic concatenation (axis=0 for observations, axis=1 for variables)\r\n- Join types (inner, outer)\r\n- Merge strategies (same, unique, first, only)\r\n- Tracking data sources with labels\r\n- Lazy concatenation (AnnCollection)\r\n- On-disk concatenation for large datasets\r\n\r\nCommon commands:\r\n```python\r\nadata = ad.concat(\r\n    [adata1, adata2, adata3],\r\n    axis=0,\r\n    join='inner',\r\n    label='batch',\r\n    keys=['batch1', 'batch2', 'batch3']\r\n)\r\n\r\nadata = ad.concat([adata_rna, adata_protein], axis=1)\r\n\r\nfrom anndata.experimental import AnnCollection\r\ncollection = AnnCollection(\r\n    ['data1.h5ad', 'data2.h5ad'],\r\n    join_obs='outer',\r\n    label='dataset'\r\n)\r\n```\r\n\r\n### 4. Data Manipulation\r\n\r\nTransform, subset, filter, and reorganize data efficiently.\r\n\r\n**See**: `references/manipulation.md` for detailed guidance on:\r\n- Subsetting (by indices, names, boolean masks, metadata conditions)\r\n- Transposition\r\n- Copying (full copies vs views)\r\n- Renaming (observations, variables, categories)\r\n- Type conversions (strings to categoricals, sparse/dense)\r\n- Adding/removing data components\r\n- Reordering\r\n- Quality control filtering\r\n\r\nCommon commands:\r\n```python\r\nfiltered = adata[adata.obs['quality_score'] > 0.8]\r\nhv_genes = adata[:, adata.var['highly_variable']]\r\n\r\nadata_T = adata.T\r\n\r\nview = adata[0:100, :]  # View (lightweight reference)\r\ncopy = adata[0:100, :].copy()  # Independent copy\r\n\r\nadata.strings_to_categoricals()\r\n```\r\n\r\n### 5. Best Practices\r\n\r\nFollow recommended patterns for memory efficiency, performance, and reproducibility.\r\n\r\n**See**: `references/best_practices.md` for guidelines on:\r\n- Memory management (sparse matrices, categoricals, backed mode)\r\n- Views vs copies\r\n- Data storage optimization\r\n- Performance optimization\r\n- Working with raw data\r\n- Metadata management\r\n- Reproducibility\r\n- Error handling\r\n- Integration with other tools\r\n- Common pitfalls and solutions\r\n\r\nKey recommendations:\r\n```python\r\nfrom scipy.sparse import csr_matrix\r\nadata.X = csr_matrix(adata.X)\r\n\r\nadata.strings_to_categoricals()\r\n\r\nadata = ad.read_h5ad('large.h5ad', backed='r')\r\n\r\n\r\nAnnData serves as the foundational data structure for the scverse ecosystem:\r\n\r\n### Scanpy (Single-cell analysis)\r\n```python\r\nimport scanpy as sc\r\n\r\nsc.pp.filter_cells(adata, min_genes=200)\r\nsc.pp.normalize_total(adata, target_sum=1e4)\r\nsc.pp.log1p(adata)\r\nsc.pp.highly_variable_genes(adata, n_top_genes=2000)\r\n\r\nsc.pp.pca(adata, n_comps=50)\r\nsc.pp.neighbors(adata, n_neighbors=15)\r\nsc.tl.umap(adata)\r\nsc.tl.leiden(adata)\r\n\r\nsc.pl.umap(adata, color=['cell_type', 'leiden'])\r\n```\r\n\r\n### Muon (Multimodal data)\r\n```python\r\nimport muon as mu\r\n\r\nmdata = mu.MuData({'rna': adata_rna, 'protein': adata_protein})\r\n```\r\n\r\n### PyTorch integration\r\n```python\r\nfrom anndata.experimental import AnnLoader\r\n\r\n\r\n### Single-cell RNA-seq analysis\r\n```python\r\nimport anndata as ad\r\nimport scanpy as sc\r\n\r\nadata = ad.read_10x_h5('filtered_feature_bc_matrix.h5')\r\n\r\nadata.obs['n_genes'] = (adata.X > 0).sum(axis=1)\r\nadata.obs['n_counts'] = adata.X.sum(axis=1)\r\nadata = adata[adata.obs['n_genes'] > 200]\r\nadata = adata[adata.obs['n_counts'] < 50000]\r\n\r\nadata.raw = adata.copy()\r\n\r\nsc.pp.normalize_total(adata, target_sum=1e4)\r\nsc.pp.log1p(adata)\r\nsc.pp.highly_variable_genes(adata, n_top_genes=2000)\r\nadata = adata[:, adata.var['highly_variable']]\r\n\r\nadata.write_h5ad('processed.h5ad')\r\n```\r\n\r\n### Batch integration\r\n```python\r\nadata1 = ad.read_h5ad('batch1.h5ad')\r\nadata2 = ad.read_h5ad('batch2.h5ad')\r\nadata3 = ad.read_h5ad('batch3.h5ad')\r\n\r\nadata = ad.concat(\r\n    [adata1, adata2, adata3],\r\n    label='batch',\r\n    keys=['batch1', 'batch2', 'batch3'],\r\n    join='inner'\r\n)\r\n\r\nimport scanpy as sc\r\nsc.pp.combat(adata, key='batch')\r\n\r\nsc.pp.pca(adata)\r\nsc.pp.neighbors(adata)\r\nsc.tl.umap(adata)\r\n```\r\n\r\n### Working with large datasets\r\n```python\r\nadata = ad.read_h5ad('100GB_dataset.h5ad', backed='r')\r\n\r\nhigh_quality = adata[adata.obs['quality_score'] > 0.8]\r\n\r\nadata_subset = high_quality.to_memory()\r\n\r\nprocess(adata_subset)\r\n\r\n\r\n### Out of memory errors\r\nUse backed mode or convert to sparse matrices:\r\n```python\r\nadata = ad.read_h5ad('file.h5ad', backed='r')\r\n\r\nfrom scipy.sparse import csr_matrix\r\nadata.X = csr_matrix(adata.X)\r\n```\r\n\r\n### Slow file reading\r\nUse compression and appropriate formats:\r\n```python\r\nadata.strings_to_categoricals()\r\nadata.write_h5ad('file.h5ad', compression='gzip')\r\n\r\nadata.write_zarr('file.zarr', chunks=(1000, 1000))\r\n```\r\n\r\n### Index alignment issues\r\nAlways align external data on index:\r\n```python\r\nadata.obs['new_col'] = external_data['values']",
  "name": "anndata",
  "id": "scientific-pkg-anndata",
  "sections": {
    "Quick Start": "print(f\"{adata.n_obs} observations × {adata.n_vars} variables\")\r\n```",
    "Additional Resources": "- **Official documentation**: https://anndata.readthedocs.io/\r\n- **Scanpy tutorials**: https://scanpy.readthedocs.io/\r\n- **Scverse ecosystem**: https://scverse.org/\r\n- **GitHub repository**: https://github.com/scverse/anndata",
    "Installation": "pip install anndata[dev,test,doc]\r\n```",
    "Troubleshooting": "adata.obs['new_col'] = external_data.set_index('cell_id').loc[adata.obs_names, 'values']\r\n```",
    "Overview": "AnnData is a Python package for handling annotated data matrices, storing experimental measurements (X) alongside observation metadata (obs), variable metadata (var), and multi-dimensional annotations (obsm, varm, obsp, varp, uns). Originally designed for single-cell genomics through Scanpy, it now serves as a general-purpose framework for any annotated data requiring efficient storage, manipulation, and analysis.",
    "When to Use This Skill": "Use this skill when:\r\n- Creating, reading, or writing AnnData objects\r\n- Working with h5ad, zarr, or other genomics data formats\r\n- Performing single-cell RNA-seq analysis\r\n- Managing large datasets with sparse matrices or backed mode\r\n- Concatenating multiple datasets or experimental batches\r\n- Subsetting, filtering, or transforming annotated data\r\n- Integrating with scanpy, scvi-tools, or other scverse ecosystem tools",
    "Core Capabilities": "adata.raw = adata.copy()\r\nadata = adata[:, adata.var['highly_variable']]\r\n```",
    "Common Workflows": "chunk_size = 1000\r\nfor i in range(0, adata.n_obs, chunk_size):\r\n    chunk = adata[i:i+chunk_size, :].to_memory()\r\n    process(chunk)\r\n```",
    "Integration with Scverse Ecosystem": "dataloader = AnnLoader(adata, batch_size=128, shuffle=True)\r\n\r\nfor batch in dataloader:\r\n    X = batch.X\r\n    # Train model\r\n```"
  }
}