{
  "description": "|",
  "metadata": {
    "license": "MIT"
  },
  "references": {
    "files": [
      "references/assistants-api-v2.md",
      "references/code-interpreter-guide.md",
      "references/file-search-rag-guide.md",
      "references/migration-from-v1.md",
      "references/thread-lifecycle.md",
      "references/top-errors.md",
      "references/vector-stores.md"
    ]
  },
  "content": "**Status**: Production Ready (Deprecated H1 2026)\r\n**Package**: openai@6.7.0\r\n**Last Updated**: 2025-10-25\r\n**v1 Deprecated**: December 18, 2024\r\n**v2 Sunset**: H1 2026 (migrate to Responses API)\r\n\r\n---",
  "name": "openai-assistants",
  "id": "openai-assistants",
  "sections": {
    "Table of Contents": "1. [Quick Start](#quick-start)\r\n2. [Core Concepts](#core-concepts)\r\n3. [Assistants](#assistants)\r\n4. [Threads](#threads)\r\n5. [Messages](#messages)\r\n6. [Runs](#runs)\r\n7. [Streaming Runs](#streaming-runs)\r\n8. [Tools](#tools)\r\n   - [Code Interpreter](#code-interpreter)\r\n   - [File Search](#file-search)\r\n   - [Function Calling](#function-calling)\r\n9. [Vector Stores](#vector-stores)\r\n10. [File Uploads](#file-uploads)\r\n11. [Thread Lifecycle Management](#thread-lifecycle-management)\r\n12. [Error Handling](#error-handling)\r\n13. [Production Best Practices](#production-best-practices)\r\n14. [Relationship to Other Skills](#relationship-to-other-skills)\r\n\r\n---",
    "File Uploads": "Upload files for use with Code Interpreter or File Search.\r\n\r\n### Upload a File\r\n\r\n```typescript\r\nimport fs from 'fs';\r\n\r\nconst file = await openai.files.create({\r\n  file: fs.createReadStream(\"document.pdf\"),\r\n  purpose: \"assistants\",\r\n});\r\n\r\nconsole.log(file.id); // file_abc123\r\n```\r\n\r\n**Supported Formats:**\r\n- **Code Interpreter**: .c, .cpp, .csv, .docx, .html, .java, .json, .md, .pdf, .php, .pptx, .py, .rb, .tex, .txt, .css, .jpeg, .jpg, .js, .gif, .png, .tar, .ts, .xlsx, .xml, .zip\r\n- **File Search**: .c, .cpp, .docx, .html, .java, .json, .md, .pdf, .php, .pptx, .py, .rb, .tex, .txt, .css, .js, .ts, .go\r\n\r\n**Size Limits:**\r\n- Code Interpreter: 512 MB per file\r\n- File Search: 512 MB per file\r\n- Vector Store: Up to 10,000 files\r\n\r\n### Retrieve File Info\r\n\r\n```typescript\r\nconst file = await openai.files.retrieve(\"file_abc123\");\r\n```\r\n\r\n### Download File Content\r\n\r\n```typescript\r\nconst content = await openai.files.content(\"file_abc123\");\r\n// Returns binary content\r\n```\r\n\r\n### Delete a File\r\n\r\n```typescript\r\nawait openai.files.del(\"file_abc123\");\r\n```\r\n\r\n### List Files\r\n\r\n```typescript\r\nconst files = await openai.files.list({\r\n  purpose: \"assistants\",\r\n});\r\n```\r\n\r\n---",
    "Production Best Practices": "### 1. Use Assistant IDs (Don't Recreate)\r\n\r\n**❌ Bad:**\r\n```typescript\r\n// Creates new assistant on every request!\r\nconst assistant = await openai.beta.assistants.create({ ... });\r\n```\r\n\r\n**✅ Good:**\r\n```typescript\r\n// Create once, store ID, reuse\r\nconst ASSISTANT_ID = process.env.ASSISTANT_ID || await createAssistant();\r\n\r\nasync function createAssistant() {\r\n  const assistant = await openai.beta.assistants.create({ ... });\r\n  console.log('Save this ID:', assistant.id);\r\n  return assistant.id;\r\n}\r\n```\r\n\r\n### 2. Implement Proper Error Handling\r\n\r\n```typescript\r\nasync function createRunWithRetry(threadId: string, assistantId: string, maxRetries = 3) {\r\n  for (let i = 0; i < maxRetries; i++) {\r\n    try {\r\n      return await openai.beta.threads.runs.create(threadId, {\r\n        assistant_id: assistantId,\r\n      });\r\n    } catch (error) {\r\n      if (error.status === 429) {\r\n        // Rate limit - wait and retry\r\n        await new Promise(resolve => setTimeout(resolve, 2000 * (i + 1)));\r\n        continue;\r\n      }\r\n\r\n      if (error.message?.includes('active run')) {\r\n        // Wait for active run to complete\r\n        await new Promise(resolve => setTimeout(resolve, 5000));\r\n        continue;\r\n      }\r\n\r\n      throw error; // Other errors\r\n    }\r\n  }\r\n\r\n  throw new Error('Max retries exceeded');\r\n}\r\n```\r\n\r\n### 3. Monitor Costs\r\n\r\n```typescript\r\n// Track usage\r\nconst run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\nconsole.log('Tokens used:', run.usage);\r\n// { prompt_tokens: 150, completion_tokens: 200, total_tokens: 350 }\r\n\r\n// Set limits\r\nconst run = await openai.beta.threads.runs.create(threadId, {\r\n  assistant_id: assistantId,\r\n  max_prompt_tokens: 1000,\r\n  max_completion_tokens: 500,\r\n});\r\n```\r\n\r\n### 4. Clean Up Resources\r\n\r\n```typescript\r\n// Delete old threads\r\nasync function cleanupUserThread(userId: string) {\r\n  const threadId = await db.getThreadIdForUser(userId);\r\n  if (threadId) {\r\n    await openai.beta.threads.del(threadId);\r\n    await db.deleteThreadIdForUser(userId);\r\n  }\r\n}\r\n\r\n// Delete unused vector stores\r\nasync function cleanupVectorStores(keepDays = 30) {\r\n  const stores = await openai.beta.vectorStores.list({ limit: 100 });\r\n\r\n  for (const store of stores.data) {\r\n    const ageSeconds = Date.now() / 1000 - store.created_at;\r\n    const ageDays = ageSeconds / (60 * 60 * 24);\r\n\r\n    if (ageDays > keepDays) {\r\n      await openai.beta.vectorStores.del(store.id);\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### 5. Use Streaming for Better UX\r\n\r\n```typescript\r\n// Show progress in real-time\r\nasync function streamToUser(threadId: string, assistantId: string) {\r\n  const stream = await openai.beta.threads.runs.stream(threadId, {\r\n    assistant_id: assistantId,\r\n  });\r\n\r\n  for await (const event of stream) {\r\n    if (event.event === 'thread.message.delta') {\r\n      const delta = event.data.delta.content?.[0]?.text?.value;\r\n      if (delta) {\r\n        // Send to user immediately\r\n        sendToClient(delta);\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n---",
    "Tools": "Assistants API supports three types of tools:\r\n\r\n### Code Interpreter\r\n\r\nExecutes Python code in a sandboxed environment.\r\n\r\n**Capabilities:**\r\n- Run Python code\r\n- Generate charts/graphs\r\n- Process files (CSV, JSON, text, images, etc.)\r\n- Return file outputs (images, data files)\r\n- Install packages (limited set available)\r\n\r\n**Example:**\r\n\r\n```typescript\r\nconst assistant = await openai.beta.assistants.create({\r\n  name: \"Data Analyst\",\r\n  instructions: \"You are a data analyst. Use Python to analyze data and create visualizations.\",\r\n  model: \"gpt-4o\",\r\n  tools: [{ type: \"code_interpreter\" }],\r\n});\r\n\r\n// Upload a file\r\nconst file = await openai.files.create({\r\n  file: fs.createReadStream(\"sales_data.csv\"),\r\n  purpose: \"assistants\",\r\n});\r\n\r\n// Create thread with file\r\nconst thread = await openai.beta.threads.create({\r\n  messages: [{\r\n    role: \"user\",\r\n    content: \"Analyze this sales data and create a visualization.\",\r\n    attachments: [{\r\n      file_id: file.id,\r\n      tools: [{ type: \"code_interpreter\" }],\r\n    }],\r\n  }],\r\n});\r\n\r\n// Run\r\nconst run = await openai.beta.threads.runs.create(thread.id, {\r\n  assistant_id: assistant.id,\r\n});\r\n\r\n// Poll for completion and retrieve outputs\r\n```\r\n\r\n**Output Files:**\r\n\r\nCode Interpreter can generate files (images, CSVs, etc.). Access them via:\r\n\r\n```typescript\r\nconst messages = await openai.beta.threads.messages.list(thread.id);\r\nconst message = messages.data[0];\r\n\r\nfor (const content of message.content) {\r\n  if (content.type === 'image_file') {\r\n    const fileId = content.image_file.file_id;\r\n    const fileContent = await openai.files.content(fileId);\r\n    // Save or process file\r\n  }\r\n}\r\n```\r\n\r\n### File Search\r\n\r\nSemantic search over uploaded documents using vector stores.\r\n\r\n**Key Features:**\r\n- Up to 10,000 files per assistant (500x more than v1)\r\n- Automatic chunking and embedding\r\n- Vector + keyword search\r\n- Parallel queries with multi-threading\r\n- Advanced reranking\r\n\r\n**Pricing:**\r\n- $0.10/GB/day for vector storage\r\n- First 1GB free\r\n\r\n**Example:**\r\n\r\n```typescript\r\n// 1. Create vector store\r\nconst vectorStore = await openai.beta.vectorStores.create({\r\n  name: \"Product Documentation\",\r\n  metadata: { category: \"docs\" },\r\n});\r\n\r\n// 2. Upload files to vector store\r\nconst file = await openai.files.create({\r\n  file: fs.createReadStream(\"product_guide.pdf\"),\r\n  purpose: \"assistants\",\r\n});\r\n\r\nawait openai.beta.vectorStores.files.create(vectorStore.id, {\r\n  file_id: file.id,\r\n});\r\n\r\n// 3. Create assistant with file search\r\nconst assistant = await openai.beta.assistants.create({\r\n  name: \"Product Support\",\r\n  instructions: \"Use file search to answer questions about our products.\",\r\n  model: \"gpt-4o\",\r\n  tools: [{ type: \"file_search\" }],\r\n  tool_resources: {\r\n    file_search: {\r\n      vector_store_ids: [vectorStore.id],\r\n    },\r\n  },\r\n});\r\n\r\n// 4. Create thread and run\r\nconst thread = await openai.beta.threads.create({\r\n  messages: [{\r\n    role: \"user\",\r\n    content: \"How do I install the product?\",\r\n  }],\r\n});\r\n\r\nconst run = await openai.beta.threads.runs.create(thread.id, {\r\n  assistant_id: assistant.id,\r\n});\r\n```\r\n\r\n**Best Practices:**\r\n- Wait for vector store status to be `completed` before using\r\n- Use metadata for filtering (coming soon)\r\n- Chunk large documents appropriately\r\n- Monitor storage costs\r\n\r\n### Function Calling\r\n\r\nDefine custom functions for the assistant to call.\r\n\r\n**Example:**\r\n\r\n```typescript\r\nconst assistant = await openai.beta.assistants.create({\r\n  name: \"Weather Assistant\",\r\n  instructions: \"You help users get weather information.\",\r\n  model: \"gpt-4o\",\r\n  tools: [{\r\n    type: \"function\",\r\n    function: {\r\n      name: \"get_weather\",\r\n      description: \"Get the current weather for a location\",\r\n      parameters: {\r\n        type: \"object\",\r\n        properties: {\r\n          location: {\r\n            type: \"string\",\r\n            description: \"City name, e.g., 'San Francisco'\",\r\n          },\r\n          unit: {\r\n            type: \"string\",\r\n            enum: [\"celsius\", \"fahrenheit\"],\r\n            description: \"Temperature unit\",\r\n          },\r\n        },\r\n        required: [\"location\"],\r\n      },\r\n    },\r\n  }],\r\n});\r\n\r\n// Create thread and run\r\nconst thread = await openai.beta.threads.create({\r\n  messages: [{\r\n    role: \"user\",\r\n    content: \"What's the weather in San Francisco?\",\r\n  }],\r\n});\r\n\r\nlet run = await openai.beta.threads.runs.create(thread.id, {\r\n  assistant_id: assistant.id,\r\n});\r\n\r\n// Poll until requires_action\r\nwhile (run.status === 'in_progress' || run.status === 'queued') {\r\n  await new Promise(resolve => setTimeout(resolve, 1000));\r\n  run = await openai.beta.threads.runs.retrieve(thread.id, run.id);\r\n}\r\n\r\nif (run.status === 'requires_action') {\r\n  const toolCalls = run.required_action.submit_tool_outputs.tool_calls;\r\n\r\n  const toolOutputs = [];\r\n  for (const toolCall of toolCalls) {\r\n    if (toolCall.function.name === 'get_weather') {\r\n      const args = JSON.parse(toolCall.function.arguments);\r\n      // Call your actual weather API\r\n      const weather = await getWeatherAPI(args.location, args.unit);\r\n\r\n      toolOutputs.push({\r\n        tool_call_id: toolCall.id,\r\n        output: JSON.stringify(weather),\r\n      });\r\n    }\r\n  }\r\n\r\n  // Submit tool outputs\r\n  run = await openai.beta.threads.runs.submitToolOutputs(thread.id, run.id, {\r\n    tool_outputs: toolOutputs,\r\n  });\r\n\r\n  // Continue polling...\r\n}\r\n```\r\n\r\n---",
    "Migration from v1 to v2": "**v1 deprecated**: December 18, 2024\r\n\r\n**Key Changes:**\r\n1. **Retrieval → File Search**: `retrieval` tool replaced with `file_search`\r\n2. **Vector Stores**: Files now organized in vector stores (10,000 file limit)\r\n3. **Instructions Limit**: Increased from 32k to 256k characters\r\n4. **File Attachments**: Now message-level instead of assistant-level\r\n\r\nSee `references/migration-from-v1.md` for complete guide.\r\n\r\n---",
    "Relationship to Other Skills": "### vs. openai-api Skill\r\n\r\n**openai-api** (Chat Completions):\r\n- Stateless requests\r\n- Manual history management\r\n- Direct responses\r\n- Use for: Simple text generation, function calling\r\n\r\n**openai-assistants**:\r\n- Stateful conversations (threads)\r\n- Automatic history management\r\n- Built-in tools (Code Interpreter, File Search)\r\n- Use for: Chatbots, data analysis, RAG\r\n\r\n### vs. openai-responses Skill\r\n\r\n**openai-responses** (Responses API):\r\n- ✅ **Recommended for new projects**\r\n- Better reasoning preservation\r\n- Modern MCP integration\r\n- Active development\r\n\r\n**openai-assistants**:\r\n- ⚠️ **Deprecated in H1 2026**\r\n- Use for legacy apps\r\n- Migration path available\r\n\r\n**Migration:** See `references/migration-to-responses.md`\r\n\r\n---",
    "Core Concepts": "The Assistants API uses four main objects:\r\n\r\n### 1. **Assistants**\r\nConfigured AI entities with:\r\n- Instructions (system prompt, max 256k characters)\r\n- Model (gpt-4o, gpt-5, etc.)\r\n- Tools (Code Interpreter, File Search, Functions)\r\n- File attachments\r\n- Metadata\r\n\r\n### 2. **Threads**\r\nConversation containers that:\r\n- Store message history\r\n- Persist across runs\r\n- Can have metadata\r\n- Support up to 100,000 messages\r\n\r\n### 3. **Messages**\r\nIndividual messages in a thread:\r\n- User messages (input)\r\n- Assistant messages (output)\r\n- Can include file attachments\r\n- Support text and image content\r\n\r\n### 4. **Runs**\r\nExecution of an assistant on a thread:\r\n- Asynchronous processing\r\n- Multiple states (queued, in_progress, completed, failed, etc.)\r\n- Can stream results\r\n- Handle tool calls automatically\r\n\r\n---",
    "Threads": "Threads store conversation history and persist across runs.\r\n\r\n### Create a Thread\r\n\r\n```typescript\r\n// Empty thread\r\nconst thread = await openai.beta.threads.create();\r\n\r\n// Thread with initial messages\r\nconst thread = await openai.beta.threads.create({\r\n  messages: [\r\n    {\r\n      role: \"user\",\r\n      content: \"Hello! I need help with Python.\",\r\n      metadata: { source: \"web\" },\r\n    },\r\n  ],\r\n  metadata: {\r\n    user_id: \"user_123\",\r\n    session_id: \"session_456\",\r\n  },\r\n});\r\n```\r\n\r\n### Retrieve a Thread\r\n\r\n```typescript\r\nconst thread = await openai.beta.threads.retrieve(\"thread_abc123\");\r\n```\r\n\r\n### Update Thread Metadata\r\n\r\n```typescript\r\nconst thread = await openai.beta.threads.update(\"thread_abc123\", {\r\n  metadata: {\r\n    user_id: \"user_123\",\r\n    last_active: new Date().toISOString(),\r\n  },\r\n});\r\n```\r\n\r\n### Delete a Thread\r\n\r\n```typescript\r\nawait openai.beta.threads.del(\"thread_abc123\");\r\n```\r\n\r\n**⚠️ Warning**: Deleting a thread also deletes all messages and runs. Cannot be undone.\r\n\r\n---",
    "Quick Start": "### Installation\r\n\r\n```bash\r\nnpm install openai@6.7.0\r\n```\r\n\r\n### Environment Setup\r\n\r\n```bash\r\nexport OPENAI_API_KEY=\"sk-...\"\r\n```\r\n\r\n### Basic Assistant (Node.js SDK)\r\n\r\n```typescript\r\nimport OpenAI from 'openai';\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\n// 1. Create an assistant\r\nconst assistant = await openai.beta.assistants.create({\r\n  name: \"Math Tutor\",\r\n  instructions: \"You are a personal math tutor. Write and run code to answer math questions.\",\r\n  tools: [{ type: \"code_interpreter\" }],\r\n  model: \"gpt-4o\",\r\n});\r\n\r\n// 2. Create a thread\r\nconst thread = await openai.beta.threads.create();\r\n\r\n// 3. Add a message to the thread\r\nawait openai.beta.threads.messages.create(thread.id, {\r\n  role: \"user\",\r\n  content: \"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\r\n});\r\n\r\n// 4. Create a run\r\nconst run = await openai.beta.threads.runs.create(thread.id, {\r\n  assistant_id: assistant.id,\r\n});\r\n\r\n// 5. Poll for completion\r\nlet runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);\r\n\r\nwhile (runStatus.status !== 'completed') {\r\n  await new Promise(resolve => setTimeout(resolve, 1000));\r\n  runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);\r\n}\r\n\r\n// 6. Retrieve messages\r\nconst messages = await openai.beta.threads.messages.list(thread.id);\r\nconsole.log(messages.data[0].content[0].text.value);\r\n```\r\n\r\n### Basic Assistant (Fetch - Cloudflare Workers)\r\n\r\n```typescript\r\n// 1. Create assistant\r\nconst assistant = await fetch('https://api.openai.com/v1/assistants', {\r\n  method: 'POST',\r\n  headers: {\r\n    'Authorization': `Bearer ${env.OPENAI_API_KEY}`,\r\n    'Content-Type': 'application/json',\r\n    'OpenAI-Beta': 'assistants=v2',\r\n  },\r\n  body: JSON.stringify({\r\n    name: \"Math Tutor\",\r\n    instructions: \"You are a helpful math tutor.\",\r\n    model: \"gpt-4o\",\r\n  }),\r\n});\r\n\r\nconst assistantData = await assistant.json();\r\n\r\n// 2. Create thread\r\nconst thread = await fetch('https://api.openai.com/v1/threads', {\r\n  method: 'POST',\r\n  headers: {\r\n    'Authorization': `Bearer ${env.OPENAI_API_KEY}`,\r\n    'Content-Type': 'application/json',\r\n    'OpenAI-Beta': 'assistants=v2',\r\n  },\r\n});\r\n\r\nconst threadData = await thread.json();\r\n\r\n// 3. Add message and create run\r\nconst run = await fetch(`https://api.openai.com/v1/threads/${threadData.id}/runs`, {\r\n  method: 'POST',\r\n  headers: {\r\n    'Authorization': `Bearer ${env.OPENAI_API_KEY}`,\r\n    'Content-Type': 'application/json',\r\n    'OpenAI-Beta': 'assistants=v2',\r\n  },\r\n  body: JSON.stringify({\r\n    assistant_id: assistantData.id,\r\n    additional_messages: [{\r\n      role: \"user\",\r\n      content: \"What is 3x + 11 = 14?\",\r\n    }],\r\n  }),\r\n});\r\n\r\n// Poll for completion...\r\n```\r\n\r\n---",
    "Error Handling": "### Common Errors and Solutions\r\n\r\n**1. Thread Already Has Active Run**\r\n\r\n```\r\nError: 400 Can't add messages to thread_xxx while a run run_xxx is active.\r\n```\r\n\r\n**Solution:**\r\n```typescript\r\n// Wait for run to complete or cancel it\r\nconst run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\nif (['queued', 'in_progress'].includes(run.status)) {\r\n  await openai.beta.threads.runs.cancel(threadId, runId);\r\n  // Wait for cancellation\r\n  while (run.status !== 'cancelled') {\r\n    await new Promise(resolve => setTimeout(resolve, 500));\r\n    run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\n  }\r\n}\r\n```\r\n\r\n**2. Run Polling Timeout**\r\n\r\nLong-running tasks may exceed reasonable polling windows.\r\n\r\n**Solution:**\r\n```typescript\r\nasync function pollWithTimeout(threadId: string, runId: string, maxSeconds = 300) {\r\n  const startTime = Date.now();\r\n\r\n  while (true) {\r\n    const run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\n\r\n    if (!['queued', 'in_progress'].includes(run.status)) {\r\n      return run;\r\n    }\r\n\r\n    const elapsed = (Date.now() - startTime) / 1000;\r\n    if (elapsed > maxSeconds) {\r\n      await openai.beta.threads.runs.cancel(threadId, runId);\r\n      throw new Error('Run exceeded timeout');\r\n    }\r\n\r\n    await new Promise(resolve => setTimeout(resolve, 1000));\r\n  }\r\n}\r\n```\r\n\r\n**3. Vector Store Not Ready**\r\n\r\nUsing vector store before indexing completes.\r\n\r\n**Solution:**\r\n```typescript\r\nasync function waitForVectorStore(vectorStoreId: string) {\r\n  let store = await openai.beta.vectorStores.retrieve(vectorStoreId);\r\n\r\n  while (store.status === 'in_progress') {\r\n    await new Promise(resolve => setTimeout(resolve, 2000));\r\n    store = await openai.beta.vectorStores.retrieve(vectorStoreId);\r\n  }\r\n\r\n  if (store.status === 'failed') {\r\n    throw new Error('Vector store indexing failed');\r\n  }\r\n\r\n  return store;\r\n}\r\n```\r\n\r\n**4. File Upload Format Issues**\r\n\r\nUnsupported file formats cause errors.\r\n\r\n**Solution:**\r\n```typescript\r\nconst SUPPORTED_FORMATS = {\r\n  code_interpreter: ['.csv', '.json', '.pdf', '.txt', '.py', '.js', '.xlsx'],\r\n  file_search: ['.pdf', '.docx', '.txt', '.md', '.html'],\r\n};\r\n\r\nfunction validateFile(filename: string, tool: string) {\r\n  const ext = filename.substring(filename.lastIndexOf('.')).toLowerCase();\r\n  if (!SUPPORTED_FORMATS[tool].includes(ext)) {\r\n    throw new Error(`Unsupported file format for ${tool}: ${ext}`);\r\n  }\r\n}\r\n```\r\n\r\nSee `references/top-errors.md` for complete error catalog.\r\n\r\n---",
    "Messages": "### Add a Message to a Thread\r\n\r\n```typescript\r\nconst message = await openai.beta.threads.messages.create(\"thread_abc123\", {\r\n  role: \"user\",\r\n  content: \"Can you analyze this data?\",\r\n  attachments: [\r\n    {\r\n      file_id: \"file_abc123\",\r\n      tools: [{ type: \"code_interpreter\" }],\r\n    },\r\n  ],\r\n  metadata: {\r\n    timestamp: new Date().toISOString(),\r\n  },\r\n});\r\n```\r\n\r\n**Parameters:**\r\n- `role`: \"user\" only (assistant messages created by runs)\r\n- `content`: Text or array of content blocks\r\n- `attachments`: Files with associated tools\r\n- `metadata`: Key-value pairs\r\n\r\n### Retrieve a Message\r\n\r\n```typescript\r\nconst message = await openai.beta.threads.messages.retrieve(\r\n  \"thread_abc123\",\r\n  \"msg_abc123\"\r\n);\r\n```\r\n\r\n### List Messages\r\n\r\n```typescript\r\nconst messages = await openai.beta.threads.messages.list(\"thread_abc123\", {\r\n  limit: 20,\r\n  order: \"desc\", // \"asc\" or \"desc\"\r\n});\r\n\r\n// Iterate through messages\r\nfor (const message of messages.data) {\r\n  console.log(`${message.role}: ${message.content[0].text.value}`);\r\n}\r\n```\r\n\r\n### Update Message Metadata\r\n\r\n```typescript\r\nconst message = await openai.beta.threads.messages.update(\r\n  \"thread_abc123\",\r\n  \"msg_abc123\",\r\n  {\r\n    metadata: {\r\n      edited: \"true\",\r\n      edit_timestamp: new Date().toISOString(),\r\n    },\r\n  }\r\n);\r\n```\r\n\r\n### Delete a Message\r\n\r\n```typescript\r\nawait openai.beta.threads.messages.del(\"thread_abc123\", \"msg_abc123\");\r\n```\r\n\r\n---",
    "Assistants": "### Create an Assistant\r\n\r\n```typescript\r\nconst assistant = await openai.beta.assistants.create({\r\n  name: \"Data Analyst\",\r\n  instructions: \"You are a data analyst. Use code interpreter to analyze data and create visualizations.\",\r\n  model: \"gpt-4o\",\r\n  tools: [\r\n    { type: \"code_interpreter\" },\r\n    { type: \"file_search\" },\r\n  ],\r\n  tool_resources: {\r\n    file_search: {\r\n      vector_store_ids: [\"vs_abc123\"],\r\n    },\r\n  },\r\n  metadata: {\r\n    department: \"analytics\",\r\n    version: \"1.0\",\r\n  },\r\n});\r\n```\r\n\r\n**Parameters:**\r\n- `model` (required): Model ID (gpt-4o, gpt-5, gpt-4-turbo)\r\n- `instructions`: System prompt (max 256k characters in v2, was 32k in v1)\r\n- `name`: Assistant name (max 256 characters)\r\n- `description`: Description (max 512 characters)\r\n- `tools`: Array of tools (max 128 tools)\r\n- `tool_resources`: Resources for tools (vector stores, files)\r\n- `temperature`: 0-2 (default 1)\r\n- `top_p`: 0-1 (default 1)\r\n- `response_format`: \"auto\", \"json_object\", or JSON schema\r\n- `metadata`: Key-value pairs (max 16 pairs)\r\n\r\n### Retrieve an Assistant\r\n\r\n```typescript\r\nconst assistant = await openai.beta.assistants.retrieve(\"asst_abc123\");\r\n```\r\n\r\n### Update an Assistant\r\n\r\n```typescript\r\nconst updatedAssistant = await openai.beta.assistants.update(\"asst_abc123\", {\r\n  instructions: \"Updated instructions\",\r\n  tools: [{ type: \"code_interpreter\" }, { type: \"file_search\" }],\r\n});\r\n```\r\n\r\n### Delete an Assistant\r\n\r\n```typescript\r\nawait openai.beta.assistants.del(\"asst_abc123\");\r\n```\r\n\r\n### List Assistants\r\n\r\n```typescript\r\nconst assistants = await openai.beta.assistants.list({\r\n  limit: 20,\r\n  order: \"desc\",\r\n});\r\n```\r\n\r\n---",
    "Thread Lifecycle Management": "Proper thread lifecycle management prevents common errors.\r\n\r\n### Pattern 1: One Thread Per User\r\n\r\n```typescript\r\nasync function getOrCreateUserThread(userId: string): Promise<string> {\r\n  // Check if thread exists in your database\r\n  let threadId = await db.getThreadIdForUser(userId);\r\n\r\n  if (!threadId) {\r\n    // Create new thread\r\n    const thread = await openai.beta.threads.create({\r\n      metadata: { user_id: userId },\r\n    });\r\n    threadId = thread.id;\r\n    await db.saveThreadIdForUser(userId, threadId);\r\n  }\r\n\r\n  return threadId;\r\n}\r\n```\r\n\r\n### Pattern 2: Active Run Check\r\n\r\n```typescript\r\nasync function ensureNoActiveRun(threadId: string) {\r\n  const runs = await openai.beta.threads.runs.list(threadId, {\r\n    limit: 1,\r\n    order: \"desc\",\r\n  });\r\n\r\n  const latestRun = runs.data[0];\r\n  if (latestRun && ['queued', 'in_progress', 'cancelling'].includes(latestRun.status)) {\r\n    throw new Error('Thread already has an active run. Wait or cancel first.');\r\n  }\r\n}\r\n\r\n// Before creating new run\r\nawait ensureNoActiveRun(threadId);\r\nconst run = await openai.beta.threads.runs.create(threadId, { assistant_id });\r\n```\r\n\r\n### Pattern 3: Thread Cleanup\r\n\r\n```typescript\r\nasync function cleanupOldThreads(maxAgeHours = 24) {\r\n  const threads = await openai.beta.threads.list({ limit: 100 });\r\n\r\n  for (const thread of threads.data) {\r\n    const createdAt = new Date(thread.created_at * 1000);\r\n    const ageHours = (Date.now() - createdAt.getTime()) / (1000 * 60 * 60);\r\n\r\n    if (ageHours > maxAgeHours) {\r\n      await openai.beta.threads.del(thread.id);\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n---",
    "Next Steps": "**Templates:**\r\n- `templates/basic-assistant.ts` - Simple math tutor\r\n- `templates/code-interpreter-assistant.ts` - Data analysis\r\n- `templates/file-search-assistant.ts` - RAG with vector stores\r\n- `templates/function-calling-assistant.ts` - Custom tools\r\n- `templates/streaming-assistant.ts` - Real-time streaming\r\n\r\n**References:**\r\n- `references/top-errors.md` - 12 common errors and solutions\r\n- `references/thread-lifecycle.md` - Thread management patterns\r\n- `references/vector-stores.md` - Vector store deep dive\r\n\r\n**Related Skills:**\r\n- `openai-responses` - Modern replacement (recommended)\r\n- `openai-api` - Chat Completions (stateless)\r\n\r\n---\r\n\r\n**Last Updated**: 2025-10-25\r\n**Package Version**: openai@6.7.0\r\n**Status**: Production Ready (Deprecated H1 2026)",
    "Runs": "Runs execute an assistant on a thread.\r\n\r\n### Create a Run\r\n\r\n```typescript\r\nconst run = await openai.beta.threads.runs.create(\"thread_abc123\", {\r\n  assistant_id: \"asst_abc123\",\r\n  instructions: \"Please address the user as Jane Doe.\",\r\n  additional_messages: [\r\n    {\r\n      role: \"user\",\r\n      content: \"Can you help me with this?\",\r\n    },\r\n  ],\r\n});\r\n```\r\n\r\n**Parameters:**\r\n- `assistant_id` (required): Assistant to use\r\n- `instructions`: Override assistant instructions\r\n- `additional_messages`: Add messages before running\r\n- `tools`: Override assistant tools\r\n- `metadata`: Key-value pairs\r\n- `temperature`: Override temperature\r\n- `top_p`: Override top_p\r\n- `max_prompt_tokens`: Limit input tokens\r\n- `max_completion_tokens`: Limit output tokens\r\n\r\n### Retrieve a Run\r\n\r\n```typescript\r\nconst run = await openai.beta.threads.runs.retrieve(\r\n  \"thread_abc123\",\r\n  \"run_abc123\"\r\n);\r\n\r\nconsole.log(run.status); // queued, in_progress, requires_action, completed, failed, etc.\r\n```\r\n\r\n### Run States\r\n\r\n| State | Description |\r\n|-------|-------------|\r\n| `queued` | Run is waiting to start |\r\n| `in_progress` | Run is executing |\r\n| `requires_action` | Function calling needs your input |\r\n| `cancelling` | Cancellation in progress |\r\n| `cancelled` | Run was cancelled |\r\n| `failed` | Run failed (check `last_error`) |\r\n| `completed` | Run finished successfully |\r\n| `expired` | Run expired (max 10 minutes) |\r\n\r\n### Polling Pattern\r\n\r\n```typescript\r\nasync function pollRunCompletion(threadId: string, runId: string) {\r\n  let run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\n\r\n  while (['queued', 'in_progress', 'cancelling'].includes(run.status)) {\r\n    await new Promise(resolve => setTimeout(resolve, 1000)); // Wait 1 second\r\n    run = await openai.beta.threads.runs.retrieve(threadId, runId);\r\n  }\r\n\r\n  if (run.status === 'failed') {\r\n    throw new Error(`Run failed: ${run.last_error?.message}`);\r\n  }\r\n\r\n  if (run.status === 'requires_action') {\r\n    // Handle function calling (see Function Calling section)\r\n    return run;\r\n  }\r\n\r\n  return run; // completed\r\n}\r\n\r\nconst run = await openai.beta.threads.runs.create(threadId, { assistant_id: assistantId });\r\nconst completedRun = await pollRunCompletion(threadId, run.id);\r\n```\r\n\r\n### Cancel a Run\r\n\r\n```typescript\r\nconst run = await openai.beta.threads.runs.cancel(\"thread_abc123\", \"run_abc123\");\r\n```\r\n\r\n**⚠️ Important**: Cancellation is asynchronous. Check `status` becomes `cancelled`.\r\n\r\n### List Runs\r\n\r\n```typescript\r\nconst runs = await openai.beta.threads.runs.list(\"thread_abc123\", {\r\n  limit: 10,\r\n  order: \"desc\",\r\n});\r\n```\r\n\r\n---",
    "Vector Stores": "Vector stores enable efficient semantic search over large document collections.\r\n\r\n### Create a Vector Store\r\n\r\n```typescript\r\nconst vectorStore = await openai.beta.vectorStores.create({\r\n  name: \"Legal Documents\",\r\n  metadata: {\r\n    department: \"legal\",\r\n    category: \"contracts\",\r\n  },\r\n  expires_after: {\r\n    anchor: \"last_active_at\",\r\n    days: 7, // Auto-delete 7 days after last use\r\n  },\r\n});\r\n```\r\n\r\n### Add Files to Vector Store\r\n\r\n**Single File:**\r\n\r\n```typescript\r\nconst file = await openai.files.create({\r\n  file: fs.createReadStream(\"contract.pdf\"),\r\n  purpose: \"assistants\",\r\n});\r\n\r\nawait openai.beta.vectorStores.files.create(vectorStore.id, {\r\n  file_id: file.id,\r\n});\r\n```\r\n\r\n**Batch Upload:**\r\n\r\n```typescript\r\nconst fileBatch = await openai.beta.vectorStores.fileBatches.create(vectorStore.id, {\r\n  file_ids: [\"file_abc123\", \"file_def456\", \"file_ghi789\"],\r\n});\r\n\r\n// Poll for batch completion\r\nlet batch = await openai.beta.vectorStores.fileBatches.retrieve(vectorStore.id, fileBatch.id);\r\nwhile (batch.status === 'in_progress') {\r\n  await new Promise(resolve => setTimeout(resolve, 1000));\r\n  batch = await openai.beta.vectorStores.fileBatches.retrieve(vectorStore.id, fileBatch.id);\r\n}\r\n```\r\n\r\n### Check Vector Store Status\r\n\r\n```typescript\r\nconst vectorStore = await openai.beta.vectorStores.retrieve(\"vs_abc123\");\r\n\r\nconsole.log(vectorStore.status); // \"in_progress\", \"completed\", \"failed\"\r\nconsole.log(vectorStore.file_counts); // { in_progress: 0, completed: 50, failed: 0 }\r\n```\r\n\r\n**⚠️ Important**: Wait for `status: \"completed\"` before using with file search.\r\n\r\n### List Vector Stores\r\n\r\n```typescript\r\nconst stores = await openai.beta.vectorStores.list({\r\n  limit: 20,\r\n  order: \"desc\",\r\n});\r\n```\r\n\r\n### Update Vector Store\r\n\r\n```typescript\r\nconst vectorStore = await openai.beta.vectorStores.update(\"vs_abc123\", {\r\n  name: \"Updated Name\",\r\n  metadata: { updated: \"true\" },\r\n});\r\n```\r\n\r\n### Delete Vector Store\r\n\r\n```typescript\r\nawait openai.beta.vectorStores.del(\"vs_abc123\");\r\n```\r\n\r\n---",
    "⚠️ Important: Deprecation Notice": "**OpenAI announced that the Assistants API will be deprecated in favor of the [Responses API](../openai-responses/SKILL.md).**\r\n\r\n**Timeline:**\r\n- ✅ **Dec 18, 2024**: Assistants API v1 deprecated\r\n- ⏳ **H1 2026**: Planned sunset of Assistants API v2\r\n- ✅ **Now**: Responses API available (recommended for new projects)\r\n\r\n**Should you still use this skill?**\r\n- ✅ **Yes, if**: You have existing Assistants API code (12-18 month migration window)\r\n- ✅ **Yes, if**: You need to maintain legacy applications\r\n- ✅ **Yes, if**: Planning migration from Assistants → Responses\r\n- ❌ **No, if**: Starting a new project (use openai-responses skill instead)\r\n\r\n**Migration Path:**\r\nSee `references/migration-to-responses.md` for complete migration guide.\r\n\r\n---",
    "Streaming Runs": "Stream run events in real-time using Server-Sent Events (SSE).\r\n\r\n### Basic Streaming\r\n\r\n```typescript\r\nconst stream = await openai.beta.threads.runs.stream(\"thread_abc123\", {\r\n  assistant_id: \"asst_abc123\",\r\n});\r\n\r\nfor await (const event of stream) {\r\n  if (event.event === 'thread.message.delta') {\r\n    const delta = event.data.delta.content?.[0]?.text?.value;\r\n    if (delta) {\r\n      process.stdout.write(delta);\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Stream Event Types\r\n\r\n| Event | Description |\r\n|-------|-------------|\r\n| `thread.run.created` | Run was created |\r\n| `thread.run.in_progress` | Run started |\r\n| `thread.run.step.created` | Step created (tool call, message creation) |\r\n| `thread.run.step.delta` | Step progress update |\r\n| `thread.message.created` | Message created |\r\n| `thread.message.delta` | Message content streaming |\r\n| `thread.message.completed` | Message finished |\r\n| `thread.run.completed` | Run finished |\r\n| `thread.run.failed` | Run failed |\r\n| `thread.run.requires_action` | Function calling needed |\r\n\r\n### Complete Streaming Example\r\n\r\n```typescript\r\nasync function streamAssistantResponse(threadId: string, assistantId: string) {\r\n  const stream = await openai.beta.threads.runs.stream(threadId, {\r\n    assistant_id: assistantId,\r\n  });\r\n\r\n  for await (const event of stream) {\r\n    switch (event.event) {\r\n      case 'thread.run.created':\r\n        console.log('\\\\nRun started...');\r\n        break;\r\n\r\n      case 'thread.message.delta':\r\n        const delta = event.data.delta.content?.[0];\r\n        if (delta?.type === 'text' && delta.text?.value) {\r\n          process.stdout.write(delta.text.value);\r\n        }\r\n        break;\r\n\r\n      case 'thread.run.step.delta':\r\n        const toolCall = event.data.delta.step_details;\r\n        if (toolCall?.type === 'tool_calls') {\r\n          const codeInterpreter = toolCall.tool_calls?.[0]?.code_interpreter;\r\n          if (codeInterpreter?.input) {\r\n            console.log('\\\\nExecuting code:', codeInterpreter.input);\r\n          }\r\n        }\r\n        break;\r\n\r\n      case 'thread.run.completed':\r\n        console.log('\\\\n\\\\nRun completed!');\r\n        break;\r\n\r\n      case 'thread.run.failed':\r\n        console.error('\\\\nRun failed:', event.data.last_error);\r\n        break;\r\n\r\n      case 'thread.run.requires_action':\r\n        // Handle function calling\r\n        console.log('\\\\nFunction calling required');\r\n        break;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n---"
  }
}