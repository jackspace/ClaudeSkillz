{
  "description": "|",
  "metadata": {
    "license": "MIT"
  },
  "references": {
    "files": [
      "references/best-practices.md",
      "references/workers-api.md"
    ]
  },
  "content": "**Status**: Production Ready ✅\r\n**Last Updated**: 2025-10-21\r\n**Dependencies**: cloudflare-worker-base (for Worker setup)\r\n**Latest Versions**: wrangler@4.43.0, @cloudflare/workers-types@4.20251014.0\r\n\r\n---\r\n\r\n\r\n### 1. Create KV Namespace\r\n\r\n```bash\r\nnpx wrangler kv namespace create MY_NAMESPACE\r\n\r\n#\r\n```\r\n\r\n**For development (preview) namespace:**\r\n\r\n```bash\r\nnpx wrangler kv namespace create MY_NAMESPACE --preview\r\n\r\n```\r\n\r\n### 2. Configure Bindings\r\n\r\nAdd to your `wrangler.jsonc`:\r\n\r\n```jsonc\r\n{\r\n  \"name\": \"my-worker\",\r\n  \"main\": \"src/index.ts\",\r\n  \"compatibility_date\": \"2025-10-11\",\r\n  \"kv_namespaces\": [\r\n    {\r\n      \"binding\": \"MY_NAMESPACE\",          // Available as env.MY_NAMESPACE\r\n      \"id\": \"<production-uuid>\",           // Production namespace ID\r\n      \"preview_id\": \"<preview-uuid>\"       // Local dev namespace ID (optional)\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n**Or use `wrangler.toml`:**\r\n\r\n```toml\r\nname = \"my-worker\"\r\nmain = \"src/index.ts\"\r\ncompatibility_date = \"2025-10-11\"\r\n\r\n[[kv_namespaces]]\r\nbinding = \"MY_NAMESPACE\"\r\nid = \"<production-uuid>\"\r\npreview_id = \"<preview-uuid>\"  # optional\r\n```\r\n\r\n**CRITICAL:**\r\n- `binding` is how you access the namespace in code (`env.MY_NAMESPACE`)\r\n- `id` is the production namespace UUID\r\n- `preview_id` is for local dev (optional, separate namespace)\r\n- **Never commit real namespace IDs to public repos** - use environment variables or secrets\r\n\r\n### 3. Write Your First Key-Value Pair\r\n\r\n```typescript\r\nimport { Hono } from 'hono';\r\n\r\ntype Bindings = {\r\n  MY_NAMESPACE: KVNamespace;\r\n};\r\n\r\nconst app = new Hono<{ Bindings: Bindings }>();\r\n\r\napp.post('/set/:key', async (c) => {\r\n  const key = c.req.param('key');\r\n  const value = await c.req.text();\r\n\r\n  // Simple write\r\n  await c.env.MY_NAMESPACE.put(key, value);\r\n\r\n  return c.json({ success: true, key });\r\n});\r\n\r\napp.get('/get/:key', async (c) => {\r\n  const key = c.req.param('key');\r\n  const value = await c.env.MY_NAMESPACE.get(key);\r\n\r\n  if (!value) {\r\n    return c.json({ error: 'Not found' }, 404);\r\n  }\r\n\r\n  return c.json({ value });\r\n});\r\n\r\nexport default app;\r\n```\r\n\r\n### 4. Test Locally\r\n\r\n```bash\r\nnpm run dev\r\n\r\ncurl -X POST http://localhost:8787/set/test -d \"Hello KV\"\r\n\r\ncurl http://localhost:8787/get/test\r\n\r\n### 1. Read Operations\r\n\r\n#### `get()` - Read Single Key\r\n\r\n```typescript\r\n// Get as string (default)\r\nconst value: string | null = await env.MY_KV.get('my-key');\r\n\r\n// Get as JSON\r\nconst data: MyType | null = await env.MY_KV.get('my-key', { type: 'json' });\r\n\r\n// Get as ArrayBuffer\r\nconst buffer: ArrayBuffer | null = await env.MY_KV.get('my-key', { type: 'arrayBuffer' });\r\n\r\n// Get as ReadableStream\r\nconst stream: ReadableStream | null = await env.MY_KV.get('my-key', { type: 'stream' });\r\n\r\n// Get with cache optimization\r\nconst value = await env.MY_KV.get('my-key', {\r\n  type: 'text',\r\n  cacheTtl: 300, // Cache at edge for 5 minutes (minimum 60 seconds)\r\n});\r\n```\r\n\r\n#### `get()` - Read Multiple Keys (Bulk)\r\n\r\n```typescript\r\n// Read multiple keys at once (counts as 1 operation)\r\nconst keys = ['key1', 'key2', 'key3'];\r\nconst values: Map<string, string | null> = await env.MY_KV.get(keys);\r\n\r\n// Access values\r\nconst value1 = values.get('key1'); // string | null\r\nconst value2 = values.get('key2'); // string | null\r\n\r\n// Convert to object\r\nconst obj = Object.fromEntries(values);\r\n```\r\n\r\n#### `getWithMetadata()` - Read with Metadata\r\n\r\n```typescript\r\n// Get single key with metadata\r\nconst { value, metadata } = await env.MY_KV.getWithMetadata('my-key');\r\n\r\n// value: string | null\r\n// metadata: any | null\r\n\r\n// Get as JSON with metadata\r\nconst { value, metadata } = await env.MY_KV.getWithMetadata<MyType>('my-key', {\r\n  type: 'json',\r\n  cacheTtl: 300,\r\n});\r\n\r\n// Get multiple keys with metadata\r\nconst keys = ['key1', 'key2'];\r\nconst result: Map<string, { value: string | null, metadata: any | null }> =\r\n  await env.MY_KV.getWithMetadata(keys);\r\n\r\nfor (const [key, data] of result) {\r\n  console.log(key, data.value, data.metadata);\r\n}\r\n```\r\n\r\n**Type Options:**\r\n- `text` (default) - Returns `string`\r\n- `json` - Parses JSON, returns `object`\r\n- `arrayBuffer` - Returns `ArrayBuffer`\r\n- `stream` - Returns `ReadableStream`\r\n\r\n**Note:** Bulk read with `get(keys[])` only supports `text` and `json` types. For `arrayBuffer` or `stream`, use individual `get()` calls with `Promise.all()`.\r\n\r\n---\r\n\r\n### 2. Write Operations\r\n\r\n#### `put()` - Write Key-Value Pair\r\n\r\n```typescript\r\n// Simple write\r\nawait env.MY_KV.put('key', 'value');\r\n\r\n// Write JSON\r\nawait env.MY_KV.put('user:123', JSON.stringify({ name: 'John', age: 30 }));\r\n\r\n// Write with expiration (TTL)\r\nawait env.MY_KV.put('session:abc', sessionData, {\r\n  expirationTtl: 3600, // Expire in 1 hour (minimum 60 seconds)\r\n});\r\n\r\n// Write with absolute expiration\r\nconst expirationTime = Math.floor(Date.now() / 1000) + 86400; // 24 hours from now\r\nawait env.MY_KV.put('token', tokenValue, {\r\n  expiration: expirationTime, // Seconds since epoch\r\n});\r\n\r\n// Write with metadata\r\nawait env.MY_KV.put('config:theme', 'dark', {\r\n  metadata: {\r\n    updatedAt: Date.now(),\r\n    updatedBy: 'admin',\r\n    version: 2\r\n  },\r\n});\r\n\r\n// Write with everything\r\nawait env.MY_KV.put('feature:flags', JSON.stringify(flags), {\r\n  expirationTtl: 600,\r\n  metadata: { source: 'api', timestamp: Date.now() },\r\n});\r\n```\r\n\r\n**CRITICAL Limits:**\r\n- **Key size**: Maximum 512 bytes\r\n- **Value size**: Maximum 25 MiB\r\n- **Metadata size**: Maximum 1024 bytes (JSON serialized)\r\n- **Write rate**: Maximum 1 write per second **per key**\r\n- **Expiration minimum**: 60 seconds (both TTL and absolute)\r\n\r\n**Rate Limit Handling:**\r\n\r\n```typescript\r\nasync function putWithRetry(\r\n  kv: KVNamespace,\r\n  key: string,\r\n  value: string,\r\n  options?: KVPutOptions\r\n) {\r\n  let attempts = 0;\r\n  const maxAttempts = 5;\r\n  let delay = 1000; // Start with 1 second\r\n\r\n  while (attempts < maxAttempts) {\r\n    try {\r\n      await kv.put(key, value, options);\r\n      return; // Success\r\n    } catch (error) {\r\n      const message = (error as Error).message;\r\n\r\n      if (message.includes('429') || message.includes('Too Many Requests')) {\r\n        attempts++;\r\n        if (attempts >= maxAttempts) {\r\n          throw new Error('Max retry attempts reached');\r\n        }\r\n\r\n        console.warn(`Attempt ${attempts} failed. Retrying in ${delay}ms...`);\r\n        await new Promise(resolve => setTimeout(resolve, delay));\r\n\r\n        // Exponential backoff\r\n        delay *= 2;\r\n      } else {\r\n        throw error; // Different error, rethrow\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n---\r\n\r\n### 3. List Operations\r\n\r\n#### `list()` - List Keys\r\n\r\n```typescript\r\n// List all keys (up to 1000)\r\nconst result = await env.MY_KV.list();\r\n\r\nconsole.log(result.keys);         // Array of key objects\r\nconsole.log(result.list_complete); // boolean - false if more keys exist\r\nconsole.log(result.cursor);        // string - for pagination\r\n\r\n// List with prefix filter\r\nconst result = await env.MY_KV.list({\r\n  prefix: 'user:', // Only keys starting with 'user:'\r\n});\r\n\r\n// List with limit\r\nconst result = await env.MY_KV.list({\r\n  limit: 100, // Maximum 1000 (default 1000)\r\n});\r\n\r\n// Pagination with cursor\r\nlet cursor: string | undefined;\r\nlet allKeys: any[] = [];\r\n\r\ndo {\r\n  const result = await env.MY_KV.list({ cursor });\r\n  allKeys = allKeys.concat(result.keys);\r\n  cursor = result.list_complete ? undefined : result.cursor;\r\n} while (cursor);\r\n\r\n// Combined: prefix + pagination\r\nlet cursor: string | undefined;\r\nconst userKeys: any[] = [];\r\n\r\ndo {\r\n  const result = await env.MY_KV.list({\r\n    prefix: 'user:',\r\n    cursor,\r\n  });\r\n\r\n  userKeys.push(...result.keys);\r\n  cursor = result.list_complete ? undefined : result.cursor;\r\n} while (cursor);\r\n```\r\n\r\n**List Response Format:**\r\n\r\n```typescript\r\n{\r\n  keys: [\r\n    {\r\n      name: \"user:123\",\r\n      expiration: 1234567890,  // Optional: seconds since epoch\r\n      metadata: { ... }         // Optional: metadata object\r\n    },\r\n    // ... more keys\r\n  ],\r\n  list_complete: false,  // true if no more keys\r\n  cursor: \"6Ck1la0VxJ0djhidm1MdX2FyD\"  // Use for next page\r\n}\r\n```\r\n\r\n**IMPORTANT:**\r\n- Keys are **always** returned in lexicographically sorted order (UTF-8)\r\n- **Always check `list_complete`**, not `keys.length === 0`\r\n- Empty `keys` array doesn't mean no more data (expired/deleted keys create \"tombstones\")\r\n- When paginating with `prefix`, you **must** pass the same `prefix` with each `cursor` request\r\n\r\n---\r\n\r\n### 4. Delete Operations\r\n\r\n#### `delete()` - Delete Key\r\n\r\n```typescript\r\n// Delete single key\r\nawait env.MY_KV.delete('my-key');\r\n\r\n// Delete always succeeds, even if key doesn't exist\r\nawait env.MY_KV.delete('non-existent-key'); // No error\r\n\r\n// Bulk delete pattern (in Worker)\r\nconst keysToDelete = ['key1', 'key2', 'key3', ...];\r\n\r\n// Delete in parallel (careful of Worker subrequest limits)\r\nawait Promise.all(\r\n  keysToDelete.map(key => env.MY_KV.delete(key))\r\n);\r\n\r\n// For more than 1000 keys, use REST API bulk delete (via wrangler or API)\r\n```\r\n\r\n**Bulk Delete via REST API:**\r\n\r\nThe Workers binding doesn't support bulk delete, but you can use the REST API (via `wrangler` or direct API calls):\r\n\r\n```bash\r\nnpx wrangler kv bulk delete --namespace-id=<UUID> keys.json\r\n\r\n\r\n### Create Namespace\r\n\r\n```bash\r\nnpx wrangler kv namespace create MY_NAMESPACE\r\n\r\nnpx wrangler kv namespace create MY_NAMESPACE --preview\r\n```\r\n\r\n### List Namespaces\r\n\r\n```bash\r\nnpx wrangler kv namespace list\r\n```\r\n\r\n### Write Key-Value Pairs\r\n\r\n```bash\r\nnpx wrangler kv key put --binding=MY_NAMESPACE \"my-key\" \"my-value\"\r\n\r\nnpx wrangler kv key put --binding=MY_NAMESPACE \"config\" --path=config.json\r\n\r\nnpx wrangler kv key put --binding=MY_NAMESPACE \"key\" \"value\" --metadata='{\"version\":1}'\r\n\r\nnpx wrangler kv key put --binding=MY_NAMESPACE \"session\" \"data\" --ttl=3600\r\n```\r\n\r\n### Read Key-Value Pairs\r\n\r\n```bash\r\nnpx wrangler kv key get --binding=MY_NAMESPACE \"my-key\"\r\n\r\nnpx wrangler kv key get --binding=MY_NAMESPACE \"image\" --path=image.png\r\n```\r\n\r\n### List Keys\r\n\r\n```bash\r\nnpx wrangler kv key list --binding=MY_NAMESPACE\r\n\r\nnpx wrangler kv key list --binding=MY_NAMESPACE --prefix=\"user:\"\r\n\r\nnpx wrangler kv key list --binding=MY_NAMESPACE | jq \".\"\r\n```\r\n\r\n### Delete Keys\r\n\r\n```bash\r\nnpx wrangler kv key delete --binding=MY_NAMESPACE \"my-key\"\r\n```\r\n\r\n### Bulk Operations\r\n\r\n```bash\r\nnpx wrangler kv bulk put --binding=MY_NAMESPACE data.json\r\n\r\n\r\nnpx wrangler kv bulk delete --binding=MY_NAMESPACE keys.json",
  "name": "cloudflare-kv",
  "id": "cloudflare-kv",
  "sections": {
    "Never Do ❌": "1. **Never write to same key >1/second** - Causes 429 rate limit errors\r\n2. **Never assume immediate global consistency** - Takes ~60 seconds to propagate\r\n3. **Never use KV for atomic operations** - Use Durable Objects instead\r\n4. **Never set cacheTtl <60 seconds** - Will fail\r\n5. **Never commit namespace IDs to public repos** - Use environment variables\r\n6. **Never exceed 1000 operations per invocation** - Use bulk operations\r\n7. **Never rely on write order** - Eventual consistency means no guarantees\r\n8. **Never store sensitive data without encryption** - KV is not encrypted at rest by default\r\n9. **Never use KV for high-frequency writes** - Not designed for write-heavy workloads\r\n10. **Never forget to handle null values** - `get()` returns `null` if key doesn't exist\r\n\r\n---",
    "Limits & Quotas": "| Feature | Free Plan | Paid Plan |\r\n|---------|-----------|-----------|\r\n| **Reads per day** | 100,000 | Unlimited |\r\n| **Writes per day** (different keys) | 1,000 | Unlimited |\r\n| **Writes per key per second** | 1 | 1 |\r\n| **Operations per Worker invocation** | 1,000 | 1,000 |\r\n| **Namespaces per account** | 1,000 | 1,000 |\r\n| **Storage per account** | 1 GB | Unlimited |\r\n| **Storage per namespace** | 1 GB | Unlimited |\r\n| **Keys per namespace** | Unlimited | Unlimited |\r\n| **Key size** | 512 bytes | 512 bytes |\r\n| **Metadata size** | 1024 bytes | 1024 bytes |\r\n| **Value size** | 25 MiB | 25 MiB |\r\n| **Minimum cacheTtl** | 60 seconds | 60 seconds |\r\n| **Maximum cacheTtl** | Number.MAX_SAFE_INTEGER | Number.MAX_SAFE_INTEGER |\r\n\r\n**Important Notes:**\r\n- **1 write/second per key**: Concurrent writes to the same key cause 429 errors\r\n- **1000 operations per invocation**: Bulk operations count as **1 operation**\r\n- **Bulk reads** (reading multiple keys) count as a single operation\r\n- **REST API** is subject to [Cloudflare API rate limits](https://developers.cloudflare.com/fundamentals/api/reference/limits/)\r\n\r\n---",
    "Always Do ✅": "1. **Use bulk operations** when reading multiple keys (counts as 1 operation)\r\n2. **Set cacheTtl** for frequently-read, infrequently-updated data\r\n3. **Store small values in metadata** when using `list()` frequently\r\n4. **Check `list_complete`** when paginating, not `keys.length === 0`\r\n5. **Use retry logic with exponential backoff** for write operations\r\n6. **Validate sizes** before writing (key 512 bytes, value 25 MiB, metadata 1 KB)\r\n7. **Use preview namespaces** for local development\r\n8. **Set appropriate TTLs** for cache invalidation (minimum 60 seconds)\r\n9. **Coalesce related keys** for better caching performance\r\n10. **Use KV for read-heavy workloads** (100:1 read/write ratio ideal)\r\n\r\n---",
    "Related Documentation": "- [Cloudflare KV Docs](https://developers.cloudflare.com/kv/)\r\n- [KV API Reference](https://developers.cloudflare.com/kv/api/)\r\n- [KV Limits](https://developers.cloudflare.com/kv/platform/limits/)\r\n- [How KV Works](https://developers.cloudflare.com/kv/concepts/how-kv-works/)\r\n- [Wrangler KV Commands](https://developers.cloudflare.com/workers/wrangler/commands/#kv)\r\n\r\n---\r\n\r\n**Last Updated**: 2025-10-21\r\n**Version**: 1.0.0\r\n**Maintainer**: Jeremy Dawes | jeremy@jezweb.net",
    "Understanding Eventual Consistency": "KV is **eventually consistent** across Cloudflare's global network:\r\n\r\n### How It Works:\r\n\r\n1. **Writes** are immediately visible in the **same location**\r\n2. **Other locations** see the update within **~60 seconds** (or your `cacheTtl` value)\r\n3. **Cached reads** may return stale data during propagation\r\n\r\n### Implications:\r\n\r\n```typescript\r\n// In Tokyo data center:\r\nawait env.MY_KV.put('counter', '1');\r\nconst value1 = await env.MY_KV.get('counter'); // \"1\" ✅\r\n\r\n// In London data center (within 60 seconds):\r\nconst value2 = await env.MY_KV.get('counter'); // Might still be old value ⚠️\r\n\r\n// After 60+ seconds:\r\nconst value3 = await env.MY_KV.get('counter'); // \"1\" ✅\r\n```\r\n\r\n### Best Practices:\r\n\r\n✅ **Use KV for:**\r\n- Read-heavy workloads (100:1 read/write ratio)\r\n- Data that doesn't require immediate global consistency\r\n- Configuration, feature flags, caching\r\n- User preferences, session data\r\n\r\n❌ **Don't use KV for:**\r\n- Financial transactions requiring atomic operations\r\n- Data requiring strong consistency\r\n- High-frequency writes to same key (>1/second)\r\n- Critical data where stale reads are unacceptable\r\n\r\n**If you need strong consistency, use [Durable Objects](https://developers.cloudflare.com/durable-objects/).**\r\n\r\n---",
    "TypeScript Types": "```typescript\r\n// KVNamespace type is provided by @cloudflare/workers-types\r\ninterface KVNamespace {\r\n  get(key: string, options?: Partial<KVGetOptions<undefined>>): Promise<string | null>;\r\n  get(key: string, type: \"text\"): Promise<string | null>;\r\n  get<ExpectedValue = unknown>(key: string, type: \"json\"): Promise<ExpectedValue | null>;\r\n  get(key: string, type: \"arrayBuffer\"): Promise<ArrayBuffer | null>;\r\n  get(key: string, type: \"stream\"): Promise<ReadableStream | null>;\r\n  get(key: string, options?: KVGetOptions<\"text\">): Promise<string | null>;\r\n  get<ExpectedValue = unknown>(key: string, options?: KVGetOptions<\"json\">): Promise<ExpectedValue | null>;\r\n  get(key: string, options?: KVGetOptions<\"arrayBuffer\">): Promise<ArrayBuffer | null>;\r\n  get(key: string, options?: KVGetOptions<\"stream\">): Promise<ReadableStream | null>;\r\n  get(keys: string[]): Promise<Map<string, string | null>>;\r\n  get(keys: string[], type: \"text\"): Promise<Map<string, string | null>>;\r\n  get<ExpectedValue = unknown>(keys: string[], type: \"json\"): Promise<Map<string, ExpectedValue | null>>;\r\n\r\n  getWithMetadata<Metadata = unknown>(key: string, options?: Partial<KVGetOptions<undefined>>): Promise<KVGetWithMetadataResult<string, Metadata>>;\r\n  getWithMetadata<Metadata = unknown>(key: string, type: \"text\"): Promise<KVGetWithMetadataResult<string, Metadata>>;\r\n  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(key: string, type: \"json\"): Promise<KVGetWithMetadataResult<ExpectedValue, Metadata>>;\r\n  getWithMetadata<Metadata = unknown>(key: string, options?: KVGetOptions<\"text\">): Promise<KVGetWithMetadataResult<string, Metadata>>;\r\n  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(key: string, options?: KVGetOptions<\"json\">): Promise<KVGetWithMetadataResult<ExpectedValue, Metadata>>;\r\n  getWithMetadata<Metadata = unknown>(keys: string[]): Promise<Map<string, KVGetWithMetadataResult<string, Metadata>>>;\r\n  getWithMetadata<Metadata = unknown>(keys: string[], type: \"text\"): Promise<Map<string, KVGetWithMetadataResult<string, Metadata>>>;\r\n  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(keys: string[], type: \"json\"): Promise<Map<string, KVGetWithMetadataResult<ExpectedValue, Metadata>>>;\r\n\r\n  put(key: string, value: string | ArrayBuffer | ArrayBufferView | ReadableStream, options?: KVPutOptions): Promise<void>;\r\n\r\n  delete(key: string): Promise<void>;\r\n\r\n  list<Metadata = unknown>(options?: KVListOptions): Promise<KVListResult<Metadata>>;\r\n}\r\n\r\ninterface KVGetOptions<Type> {\r\n  type: Type;\r\n  cacheTtl?: number;\r\n}\r\n\r\ninterface KVGetWithMetadataResult<Value, Metadata> {\r\n  value: Value | null;\r\n  metadata: Metadata | null;\r\n}\r\n\r\ninterface KVPutOptions {\r\n  expiration?: number;        // Seconds since epoch\r\n  expirationTtl?: number;     // Seconds from now (minimum 60)\r\n  metadata?: any;             // Serializable to JSON, max 1024 bytes\r\n}\r\n\r\ninterface KVListOptions {\r\n  prefix?: string;\r\n  limit?: number;   // Default 1000, max 1000\r\n  cursor?: string;\r\n}\r\n\r\ninterface KVListResult<Metadata = unknown> {\r\n  keys: {\r\n    name: string;\r\n    expiration?: number;\r\n    metadata?: Metadata;\r\n  }[];\r\n  list_complete: boolean;\r\n  cursor?: string;\r\n}\r\n```\r\n\r\n---",
    "Error Handling": "### Common Errors\r\n\r\n#### 1. Rate Limit (429 Too Many Requests)\r\n\r\n```typescript\r\ntry {\r\n  await env.MY_KV.put('counter', '1');\r\n  await env.MY_KV.put('counter', '2'); // Too fast! < 1 second\r\n} catch (error) {\r\n  // Error: KV PUT failed: 429 Too Many Requests\r\n  console.error(error);\r\n}\r\n\r\n// Solution: Use retry with backoff (see putWithRetry example above)\r\n```\r\n\r\n#### 2. Value Too Large\r\n\r\n```typescript\r\nconst largeValue = 'x'.repeat(26 * 1024 * 1024); // > 25 MiB\r\n\r\ntry {\r\n  await env.MY_KV.put('large', largeValue);\r\n} catch (error) {\r\n  // Error: Value too large\r\n  console.error(error);\r\n}\r\n\r\n// Solution: Check size before writing\r\nif (value.length > 25 * 1024 * 1024) {\r\n  throw new Error('Value exceeds 25 MiB limit');\r\n}\r\n```\r\n\r\n#### 3. Metadata Too Large\r\n\r\n```typescript\r\nconst metadata = { data: 'x'.repeat(2000) }; // > 1024 bytes serialized\r\n\r\ntry {\r\n  await env.MY_KV.put('key', 'value', { metadata });\r\n} catch (error) {\r\n  // Error: Metadata too large\r\n  console.error(error);\r\n}\r\n\r\n// Solution: Validate metadata size\r\nconst serialized = JSON.stringify(metadata);\r\nif (serialized.length > 1024) {\r\n  throw new Error('Metadata exceeds 1024 byte limit');\r\n}\r\n```\r\n\r\n#### 4. Invalid CacheTtl\r\n\r\n```typescript\r\n// ❌ Too low\r\nawait env.MY_KV.get('key', { cacheTtl: 30 }); // Error: minimum is 60\r\n\r\n// ✅ Correct\r\nawait env.MY_KV.get('key', { cacheTtl: 60 });\r\n```\r\n\r\n---",
    "Advanced Patterns & Best Practices": "### 1. Caching Pattern with CacheTtl\r\n\r\n```typescript\r\nasync function getCachedData(\r\n  kv: KVNamespace,\r\n  cacheKey: string,\r\n  fetchFn: () => Promise<any>,\r\n  cacheTtl: number = 300\r\n) {\r\n  // Try to get from KV cache\r\n  const cached = await kv.get(cacheKey, {\r\n    type: 'json',\r\n    cacheTtl, // Cache at edge for faster subsequent reads\r\n  });\r\n\r\n  if (cached) {\r\n    return cached;\r\n  }\r\n\r\n  // Cache miss - fetch fresh data\r\n  const data = await fetchFn();\r\n\r\n  // Store in KV with expiration\r\n  await kv.put(cacheKey, JSON.stringify(data), {\r\n    expirationTtl: cacheTtl * 2, // Store longer than cache\r\n  });\r\n\r\n  return data;\r\n}\r\n\r\n// Usage\r\napp.get('/api/data/:id', async (c) => {\r\n  const id = c.req.param('id');\r\n\r\n  const data = await getCachedData(\r\n    c.env.CACHE,\r\n    `data:${id}`,\r\n    () => fetchFromDatabase(id),\r\n    300 // 5 minutes\r\n  );\r\n\r\n  return c.json(data);\r\n});\r\n```\r\n\r\n**CacheTtl Guidelines:**\r\n- **Minimum:** 60 seconds\r\n- **Default:** 60 seconds\r\n- **Maximum:** `Number.MAX_SAFE_INTEGER`\r\n- **Use case:** Frequently read, infrequently updated data\r\n- **Trade-off:** Higher cacheTtl = faster reads but slower update propagation\r\n\r\n---\r\n\r\n### 2. Metadata Optimization Pattern\r\n\r\nStore small values in metadata to avoid separate `get()` calls:\r\n\r\n```typescript\r\n// ❌ Bad: Two operations\r\nawait env.MY_KV.put('user:123', 'active');\r\nconst status = await env.MY_KV.get('user:123');\r\n\r\n// ✅ Good: Store in metadata with empty value\r\nawait env.MY_KV.put('user:123', '', {\r\n  metadata: {\r\n    status: 'active',\r\n    lastSeen: Date.now(),\r\n    plan: 'pro'\r\n  },\r\n});\r\n\r\n// List returns metadata automatically\r\nconst users = await env.MY_KV.list({ prefix: 'user:' });\r\n\r\nusers.keys.forEach(({ name, metadata }) => {\r\n  console.log(name, metadata.status, metadata.plan);\r\n  // No additional get() calls needed!\r\n});\r\n```\r\n\r\n**When to Use:**\r\n- ✅ Values fit in 1024 bytes\r\n- ✅ You frequently use `list()` operations\r\n- ✅ You need to filter/process many keys\r\n- ❌ Don't use for large values (use regular value storage)\r\n\r\n---\r\n\r\n### 3. Key Coalescing for Performance\r\n\r\nCombine related cold keys with hot keys:\r\n\r\n```typescript\r\n// ❌ Bad: Many individual keys (some hot, some cold)\r\nawait kv.put('user:123:name', 'John');\r\nawait kv.put('user:123:email', 'john@example.com');\r\nawait kv.put('user:123:age', '30');\r\n\r\n// ✅ Good: Coalesce into single hot key\r\nawait kv.put('user:123', JSON.stringify({\r\n  name: 'John',\r\n  email: 'john@example.com',\r\n  age: 30,\r\n}));\r\n\r\n// Single read gets everything\r\nconst user = await kv.get<User>('user:123', { type: 'json' });\r\n```\r\n\r\n**Advantages:**\r\n- Cold keys benefit from hot key caching\r\n- Fewer operations = better performance\r\n- Single cache entry instead of multiple\r\n\r\n**Disadvantages:**\r\n- Can't update individual fields easily (requires read-modify-write)\r\n- Large coalesced values may hit memory limits\r\n- Concurrent updates need locking mechanism\r\n\r\n---\r\n\r\n### 4. Pagination Helper\r\n\r\n```typescript\r\nasync function* paginateKV(\r\n  kv: KVNamespace,\r\n  options: { prefix?: string; limit?: number } = {}\r\n) {\r\n  let cursor: string | undefined;\r\n\r\n  do {\r\n    const result = await kv.list({\r\n      prefix: options.prefix,\r\n      limit: options.limit || 1000,\r\n      cursor,\r\n    });\r\n\r\n    yield result.keys;\r\n\r\n    cursor = result.list_complete ? undefined : result.cursor;\r\n  } while (cursor);\r\n}\r\n\r\n// Usage\r\napp.get('/all-users', async (c) => {\r\n  const allUsers = [];\r\n\r\n  for await (const keys of paginateKV(c.env.MY_KV, { prefix: 'user:' })) {\r\n    // Process batch\r\n    allUsers.push(...keys.map(k => k.name));\r\n  }\r\n\r\n  return c.json({ users: allUsers, count: allUsers.length });\r\n});\r\n```\r\n\r\n---\r\n\r\n### 5. Feature Flags Pattern\r\n\r\n```typescript\r\ninterface FeatureFlags {\r\n  darkMode: boolean;\r\n  newDashboard: boolean;\r\n  betaFeatures: boolean;\r\n}\r\n\r\nasync function getFeatureFlags(\r\n  kv: KVNamespace,\r\n  userId?: string\r\n): Promise<FeatureFlags> {\r\n  // Try user-specific flags first\r\n  if (userId) {\r\n    const userFlags = await kv.get<FeatureFlags>(`flags:user:${userId}`, {\r\n      type: 'json',\r\n      cacheTtl: 300,\r\n    });\r\n    if (userFlags) return userFlags;\r\n  }\r\n\r\n  // Fallback to global flags\r\n  const globalFlags = await kv.get<FeatureFlags>('flags:global', {\r\n    type: 'json',\r\n    cacheTtl: 300,\r\n  });\r\n\r\n  return globalFlags || {\r\n    darkMode: false,\r\n    newDashboard: false,\r\n    betaFeatures: false,\r\n  };\r\n}\r\n\r\n// Update global flags\r\napp.post('/admin/flags', async (c) => {\r\n  const flags = await c.req.json<FeatureFlags>();\r\n\r\n  await c.env.CONFIG.put('flags:global', JSON.stringify(flags), {\r\n    metadata: { updatedAt: Date.now() },\r\n  });\r\n\r\n  return c.json({ success: true });\r\n});\r\n```\r\n\r\n---",
    "Quick Start (5 Minutes)": "```\r\n\r\n---",
    "Troubleshooting": "### Issue: \"429 Too Many Requests\" on writes\r\n\r\n**Cause:** Writing to same key more than once per second\r\n\r\n**Solution:**\r\n```typescript\r\n// ❌ Bad\r\nfor (let i = 0; i < 10; i++) {\r\n  await kv.put('counter', String(i)); // Rate limit!\r\n}\r\n\r\n// ✅ Good - consolidate writes\r\nconst finalValue = '9';\r\nawait kv.put('counter', finalValue);\r\n\r\n// ✅ Good - use retry with backoff\r\nawait putWithRetry(kv, 'counter', String(i));\r\n```\r\n\r\n---\r\n\r\n### Issue: Stale reads after write\r\n\r\n**Cause:** Eventual consistency - writes take up to 60 seconds to propagate globally\r\n\r\n**Solution:**\r\n```typescript\r\n// Accept that reads may be stale for up to 60 seconds\r\n// OR use Durable Objects for strong consistency\r\n// OR implement application-level cache invalidation\r\n```\r\n\r\n---\r\n\r\n### Issue: \"Operations limit exceeded\"\r\n\r\n**Cause:** More than 1000 KV operations in single Worker invocation\r\n\r\n**Solution:**\r\n```typescript\r\n// ❌ Bad - 5000 operations\r\nconst keys = Array.from({ length: 5000 }, (_, i) => `key${i}`);\r\nfor (const key of keys) {\r\n  await kv.get(key); // Exceeds 1000 limit\r\n}\r\n\r\n// ✅ Good - 1 operation (bulk read)\r\nconst values = await kv.get(keys);\r\n```\r\n\r\n---\r\n\r\n### Issue: List returns empty but cursor exists\r\n\r\n**Cause:** Recently deleted/expired keys create \"tombstones\" in the list\r\n\r\n**Solution:**\r\n```typescript\r\n// Always check list_complete, not keys.length\r\nlet cursor: string | undefined;\r\n\r\ndo {\r\n  const result = await kv.list({ cursor });\r\n\r\n  // Process keys even if empty\r\n  processKeys(result.keys);\r\n\r\n  // CORRECT: Check list_complete\r\n  cursor = result.list_complete ? undefined : result.cursor;\r\n} while (cursor);\r\n```\r\n\r\n---",
    "Complete Workers KV API": "```\r\n\r\n**REST API Limit:** Up to 10,000 keys per bulk delete request.\r\n\r\n---",
    "Production Checklist": "Before deploying to production:\r\n\r\n- [ ] Environment-specific namespaces configured (`id` vs `preview_id`)\r\n- [ ] Namespace IDs stored in environment variables (not hardcoded)\r\n- [ ] Rate limit retry logic implemented for writes\r\n- [ ] Appropriate `cacheTtl` values set for reads\r\n- [ ] Metadata sizes validated (<1024 bytes)\r\n- [ ] Value sizes validated (<25 MiB)\r\n- [ ] Key sizes validated (<512 bytes)\r\n- [ ] Bulk operations used where possible\r\n- [ ] Pagination implemented correctly for `list()`\r\n- [ ] Error handling for null values\r\n- [ ] Monitoring/alerting for rate limits\r\n- [ ] Documentation for eventual consistency behavior\r\n\r\n---",
    "Wrangler CLI Operations": "```\r\n\r\n---"
  }
}