{
  "description": "\"Statistical analysis toolkit. Hypothesis tests (t-test, ANOVA, chi-square), regression, correlation, Bayesian stats, power analysis, assumption checks, APA reporting, for academic research.\"",
  "references": {
    "files": [
      "references/assumptions_and_diagnostics.md",
      "references/bayesian_statistics.md",
      "references/effect_sizes_and_power.md",
      "references/reporting_standards.md",
      "references/test_selection_guide.md"
    ]
  },
  "content": "### Systematic Assumption Verification\r\n\r\n**ALWAYS check assumptions before interpreting test results.**\r\n\r\nUse the provided `scripts/assumption_checks.py` module for automated checking:\r\n\r\n```python\r\nfrom scripts.assumption_checks import comprehensive_assumption_check\r\n\r\nresults = comprehensive_assumption_check(\r\n    data=df,\r\n    value_col='score',\r\n    group_col='group',  # Optional: for group comparisons\r\n    alpha=0.05\r\n)\r\n```\r\n\r\nThis performs:\r\n1. **Outlier detection** (IQR and z-score methods)\r\n2. **Normality testing** (Shapiro-Wilk test + Q-Q plots)\r\n3. **Homogeneity of variance** (Levene's test + box plots)\r\n4. **Interpretation and recommendations**\r\n\r\n### Individual Assumption Checks\r\n\r\nFor targeted checks, use individual functions:\r\n\r\n```python\r\nfrom scripts.assumption_checks import (\r\n    check_normality,\r\n    check_normality_per_group,\r\n    check_homogeneity_of_variance,\r\n    check_linearity,\r\n    detect_outliers\r\n)\r\n\r\n\r\n### Python Libraries\r\n\r\nPrimary libraries for statistical analysis:\r\n- **scipy.stats**: Core statistical tests\r\n- **statsmodels**: Advanced regression and diagnostics\r\n- **pingouin**: User-friendly statistical testing with effect sizes\r\n- **pymc**: Bayesian statistical modeling\r\n- **arviz**: Bayesian visualization and diagnostics\r\n\r\n### Example Analyses\r\n\r\n#### T-Test with Complete Reporting\r\n\r\n```python\r\nimport pingouin as pg\r\nimport numpy as np\r\n\r\nresult = pg.ttest(group_a, group_b, correction='auto')\r\n\r\nt_stat = result['T'].values[0]\r\ndf = result['dof'].values[0]\r\np_value = result['p-val'].values[0]\r\ncohens_d = result['cohen-d'].values[0]\r\nci_lower = result['CI95%'].values[0][0]\r\nci_upper = result['CI95%'].values[0][1]\r\n\r\nprint(f\"t({df:.0f}) = {t_stat:.2f}, p = {p_value:.3f}\")\r\nprint(f\"Cohen's d = {cohens_d:.2f}, 95% CI [{ci_lower:.2f}, {ci_upper:.2f}]\")\r\n```\r\n\r\n#### ANOVA with Post-Hoc Tests\r\n\r\n```python\r\nimport pingouin as pg\r\n\r\naov = pg.anova(dv='score', between='group', data=df, detailed=True)\r\nprint(aov)\r\n\r\nif aov['p-unc'].values[0] < 0.05:\r\n    posthoc = pg.pairwise_tukey(dv='score', between='group', data=df)\r\n    print(posthoc)\r\n\r\neta_squared = aov['np2'].values[0]  # Partial eta-squared\r\nprint(f\"Partial η² = {eta_squared:.3f}\")\r\n```\r\n\r\n#### Linear Regression with Diagnostics\r\n\r\n```python\r\nimport statsmodels.api as sm\r\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\r\n\r\nX = sm.add_constant(X_predictors)  # Add intercept\r\nmodel = sm.OLS(y, X).fit()\r\n\r\nprint(model.summary())\r\n\r\nvif_data = pd.DataFrame()\r\nvif_data[\"Variable\"] = X.columns\r\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\r\nprint(vif_data)\r\n\r\nresiduals = model.resid\r\nfitted = model.fittedvalues\r\n\r\nimport matplotlib.pyplot as plt\r\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\r\n\r\naxes[0, 0].scatter(fitted, residuals, alpha=0.6)\r\naxes[0, 0].axhline(y=0, color='r', linestyle='--')\r\naxes[0, 0].set_xlabel('Fitted values')\r\naxes[0, 0].set_ylabel('Residuals')\r\naxes[0, 0].set_title('Residuals vs Fitted')\r\n\r\nfrom scipy import stats\r\nstats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\r\naxes[0, 1].set_title('Normal Q-Q')\r\n\r\naxes[1, 0].scatter(fitted, np.sqrt(np.abs(residuals / residuals.std())), alpha=0.6)\r\naxes[1, 0].set_xlabel('Fitted values')\r\naxes[1, 0].set_ylabel('√|Standardized residuals|')\r\naxes[1, 0].set_title('Scale-Location')\r\n\r\naxes[1, 1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\r\naxes[1, 1].set_xlabel('Residuals')\r\naxes[1, 1].set_ylabel('Frequency')\r\naxes[1, 1].set_title('Histogram of Residuals')\r\n\r\nplt.tight_layout()\r\nplt.show()\r\n```\r\n\r\n#### Bayesian T-Test\r\n\r\n```python\r\nimport pymc as pm\r\nimport arviz as az\r\nimport numpy as np\r\n\r\nwith pm.Model() as model:\r\n    # Priors\r\n    mu1 = pm.Normal('mu_group1', mu=0, sigma=10)\r\n    mu2 = pm.Normal('mu_group2', mu=0, sigma=10)\r\n    sigma = pm.HalfNormal('sigma', sigma=10)\r\n\r\n    # Likelihood\r\n    y1 = pm.Normal('y1', mu=mu1, sigma=sigma, observed=group_a)\r\n    y2 = pm.Normal('y2', mu=mu2, sigma=sigma, observed=group_b)\r\n\r\n    # Derived quantity\r\n    diff = pm.Deterministic('difference', mu1 - mu2)\r\n\r\n    # Sample\r\n    trace = pm.sample(2000, tune=1000, return_inferencedata=True)\r\n\r\nprint(az.summary(trace, var_names=['difference']))\r\n\r\nprob_greater = np.mean(trace.posterior['difference'].values > 0)\r\nprint(f\"P(μ₁ > μ₂ | data) = {prob_greater:.3f}\")\r\n\r\n\r\n### Always Calculate Effect Sizes\r\n\r\n**Effect sizes quantify magnitude, while p-values only indicate existence of an effect.**\r\n\r\nSee `references/effect_sizes_and_power.md` for comprehensive guidance.\r\n\r\n### Quick Reference: Common Effect Sizes\r\n\r\n| Test | Effect Size | Small | Medium | Large |\r\n|------|-------------|-------|--------|-------|\r\n| T-test | Cohen's d | 0.20 | 0.50 | 0.80 |\r\n| ANOVA | η²_p | 0.01 | 0.06 | 0.14 |\r\n| Correlation | r | 0.10 | 0.30 | 0.50 |\r\n| Regression | R² | 0.02 | 0.13 | 0.26 |\r\n| Chi-square | Cramér's V | 0.07 | 0.21 | 0.35 |\r\n\r\n**Important**: Benchmarks are guidelines. Context matters!\r\n\r\n### Calculating Effect Sizes\r\n\r\nMost effect sizes are automatically calculated by pingouin:\r\n\r\n```python\r\nresult = pg.ttest(x, y)\r\nd = result['cohen-d'].values[0]\r\n\r\naov = pg.anova(dv='score', between='group', data=df)\r\neta_p2 = aov['np2'].values[0]\r\n\r\ncorr = pg.corr(x, y)\r\nr = corr['r'].values[0]\r\n```\r\n\r\n### Confidence Intervals for Effect Sizes\r\n\r\nAlways report CIs to show precision:\r\n\r\n```python\r\nfrom pingouin import compute_effsize_from_t\r\n\r\n\r\n### A Priori Power Analysis (Study Planning)\r\n\r\nDetermine required sample size before data collection:\r\n\r\n```python\r\nfrom statsmodels.stats.power import (\r\n    tt_ind_solve_power,\r\n    FTestAnovaPower\r\n)\r\n\r\nn_required = tt_ind_solve_power(\r\n    effect_size=0.5,\r\n    alpha=0.05,\r\n    power=0.80,\r\n    ratio=1.0,\r\n    alternative='two-sided'\r\n)\r\nprint(f\"Required n per group: {n_required:.0f}\")\r\n\r\nanova_power = FTestAnovaPower()\r\nn_per_group = anova_power.solve_power(\r\n    effect_size=0.25,\r\n    ngroups=3,\r\n    alpha=0.05,\r\n    power=0.80\r\n)\r\nprint(f\"Required n per group: {n_per_group:.0f}\")\r\n```\r\n\r\n### Sensitivity Analysis (Post-Study)\r\n\r\nDetermine what effect size you could detect:\r\n\r\n```python",
  "name": "statistical-analysis",
  "id": "scientific-thinking-statistical-analysis",
  "sections": {
    "Bayesian Statistics": "### When to Use Bayesian Methods\r\n\r\nConsider Bayesian approaches when:\r\n- You have prior information to incorporate\r\n- You want direct probability statements about hypotheses\r\n- Sample size is small or planning sequential data collection\r\n- You need to quantify evidence for the null hypothesis\r\n- The model is complex (hierarchical, missing data)\r\n\r\nSee `references/bayesian_statistics.md` for comprehensive guidance on:\r\n- Bayes' theorem and interpretation\r\n- Prior specification (informative, weakly informative, non-informative)\r\n- Bayesian hypothesis testing with Bayes Factors\r\n- Credible intervals vs. confidence intervals\r\n- Bayesian t-tests, ANOVA, regression, and hierarchical models\r\n- Model convergence checking and posterior predictive checks\r\n\r\n### Key Advantages\r\n\r\n1. **Intuitive interpretation**: \"Given the data, there is a 95% probability the parameter is in this interval\"\r\n2. **Evidence for null**: Can quantify support for no effect\r\n3. **Flexible**: No p-hacking concerns; can analyze data as it arrives\r\n4. **Uncertainty quantification**: Full posterior distribution\r\n\r\n---",
    "Workflow Decision Tree": "Use this decision tree to determine your analysis path:\r\n\r\n```\r\nSTART\r\n│\r\n├─ Need to SELECT a statistical test?\r\n│  └─ YES → See \"Test Selection Guide\"\r\n│  └─ NO → Continue\r\n│\r\n├─ Ready to check ASSUMPTIONS?\r\n│  └─ YES → See \"Assumption Checking\"\r\n│  └─ NO → Continue\r\n│\r\n├─ Ready to run ANALYSIS?\r\n│  └─ YES → See \"Running Statistical Tests\"\r\n│  └─ NO → Continue\r\n│\r\n└─ Need to REPORT results?\r\n   └─ YES → See \"Reporting Results\"\r\n```\r\n\r\n---",
    "Effect Sizes": "d, ci = compute_effsize_from_t(\r\n    t_statistic,\r\n    nx=len(group1),\r\n    ny=len(group2),\r\n    eftype='cohen'\r\n)\r\nprint(f\"d = {d:.2f}, 95% CI [{ci[0]:.2f}, {ci[1]:.2f}]\")\r\n```\r\n\r\n---",
    "Overview": "Statistical analysis is a systematic process for testing hypotheses and quantifying relationships. Conduct hypothesis tests (t-test, ANOVA, chi-square), regression, correlation, and Bayesian analyses with assumption checks and APA reporting. Apply this skill for academic research.",
    "Support and Further Reading": "For questions about:\r\n- **Test selection**: See references/test_selection_guide.md\r\n- **Assumptions**: See references/assumptions_and_diagnostics.md\r\n- **Effect sizes**: See references/effect_sizes_and_power.md\r\n- **Bayesian methods**: See references/bayesian_statistics.md\r\n- **Reporting**: See references/reporting_standards.md\r\n\r\n**Key textbooks**:\r\n- Cohen, J. (1988). *Statistical Power Analysis for the Behavioral Sciences*\r\n- Field, A. (2013). *Discovering Statistics Using IBM SPSS Statistics*\r\n- Gelman, A., & Hill, J. (2006). *Data Analysis Using Regression and Multilevel/Hierarchical Models*\r\n- Kruschke, J. K. (2014). *Doing Bayesian Data Analysis*\r\n\r\n**Online resources**:\r\n- APA Style Guide: https://apastyle.apa.org/\r\n- Statistical Consulting: Cross Validated (stats.stackexchange.com)",
    "Best Practices": "1. **Pre-register analyses** when possible to distinguish confirmatory from exploratory\r\n2. **Always check assumptions** before interpreting results\r\n3. **Report effect sizes** with confidence intervals\r\n4. **Report all planned analyses** including non-significant results\r\n5. **Distinguish statistical from practical significance**\r\n6. **Visualize data** before and after analysis\r\n7. **Check diagnostics** for regression/ANOVA (residual plots, VIF, etc.)\r\n8. **Conduct sensitivity analyses** to assess robustness\r\n9. **Share data and code** for reproducibility\r\n10. **Be transparent** about violations, transformations, and decisions\r\n\r\n---",
    "Reporting Results": "### APA Style Statistical Reporting\r\n\r\nFollow guidelines in `references/reporting_standards.md`.\r\n\r\n### Essential Reporting Elements\r\n\r\n1. **Descriptive statistics**: M, SD, n for all groups/variables\r\n2. **Test statistics**: Test name, statistic, df, exact p-value\r\n3. **Effect sizes**: With confidence intervals\r\n4. **Assumption checks**: Which tests were done, results, actions taken\r\n5. **All planned analyses**: Including non-significant findings\r\n\r\n### Example Report Templates\r\n\r\n#### Independent T-Test\r\n\r\n```\r\nGroup A (n = 48, M = 75.2, SD = 8.5) scored significantly higher than\r\nGroup B (n = 52, M = 68.3, SD = 9.2), t(98) = 3.82, p < .001, d = 0.77,\r\n95% CI [0.36, 1.18], two-tailed. Assumptions of normality (Shapiro-Wilk:\r\nGroup A W = 0.97, p = .18; Group B W = 0.96, p = .12) and homogeneity\r\nof variance (Levene's F(1, 98) = 1.23, p = .27) were satisfied.\r\n```\r\n\r\n#### One-Way ANOVA\r\n\r\n```\r\nA one-way ANOVA revealed a significant main effect of treatment condition\r\non test scores, F(2, 147) = 8.45, p < .001, η²_p = .10. Post hoc\r\ncomparisons using Tukey's HSD indicated that Condition A (M = 78.2,\r\nSD = 7.3) scored significantly higher than Condition B (M = 71.5,\r\nSD = 8.1, p = .002, d = 0.87) and Condition C (M = 70.1, SD = 7.9,\r\np < .001, d = 1.07). Conditions B and C did not differ significantly\r\n(p = .52, d = 0.18).\r\n```\r\n\r\n#### Multiple Regression\r\n\r\n```\r\nMultiple linear regression was conducted to predict exam scores from\r\nstudy hours, prior GPA, and attendance. The overall model was significant,\r\nF(3, 146) = 45.2, p < .001, R² = .48, adjusted R² = .47. Study hours\r\n(B = 1.80, SE = 0.31, β = .35, t = 5.78, p < .001, 95% CI [1.18, 2.42])\r\nand prior GPA (B = 8.52, SE = 1.95, β = .28, t = 4.37, p < .001,\r\n95% CI [4.66, 12.38]) were significant predictors, while attendance was\r\nnot (B = 0.15, SE = 0.12, β = .08, t = 1.25, p = .21, 95% CI [-0.09, 0.39]).\r\nMulticollinearity was not a concern (all VIF < 1.5).\r\n```\r\n\r\n#### Bayesian Analysis\r\n\r\n```\r\nA Bayesian independent samples t-test was conducted using weakly\r\ninformative priors (Normal(0, 1) for mean difference). The posterior\r\ndistribution indicated that Group A scored higher than Group B\r\n(M_diff = 6.8, 95% credible interval [3.2, 10.4]). The Bayes Factor\r\nBF₁₀ = 45.3 provided very strong evidence for a difference between\r\ngroups, with a 99.8% posterior probability that Group A's mean exceeded\r\nGroup B's mean. Convergence diagnostics were satisfactory (all R̂ < 1.01,\r\nESS > 1000).\r\n```\r\n\r\n---",
    "When to Use This Skill": "This skill should be used when:\r\n- Conducting statistical hypothesis tests (t-tests, ANOVA, chi-square)\r\n- Performing regression or correlation analyses\r\n- Running Bayesian statistical analyses\r\n- Checking statistical assumptions and diagnostics\r\n- Calculating effect sizes and conducting power analyses\r\n- Reporting statistical results in APA format\r\n- Analyzing experimental or observational data for research\r\n\r\n---",
    "Running Statistical Tests": "az.plot_posterior(trace, var_names=['difference'], ref_val=0)\r\n```\r\n\r\n---",
    "Assumption Checking": "result = check_normality(\r\n    data=df['score'],\r\n    name='Test Score',\r\n    alpha=0.05,\r\n    plot=True\r\n)\r\nprint(result['interpretation'])\r\nprint(result['recommendation'])\r\n```\r\n\r\n### What to Do When Assumptions Are Violated\r\n\r\n**Normality violated:**\r\n- Mild violation + n > 30 per group → Proceed with parametric test (robust)\r\n- Moderate violation → Use non-parametric alternative\r\n- Severe violation → Transform data or use non-parametric test\r\n\r\n**Homogeneity of variance violated:**\r\n- For t-test → Use Welch's t-test\r\n- For ANOVA → Use Welch's ANOVA or Brown-Forsythe ANOVA\r\n- For regression → Use robust standard errors or weighted least squares\r\n\r\n**Linearity violated (regression):**\r\n- Add polynomial terms\r\n- Transform variables\r\n- Use non-linear models or GAM\r\n\r\nSee `references/assumptions_and_diagnostics.md` for comprehensive guidance.\r\n\r\n---",
    "Resources": "This skill includes comprehensive reference materials:\r\n\r\n### References Directory\r\n\r\n- **test_selection_guide.md**: Decision tree for choosing appropriate statistical tests\r\n- **assumptions_and_diagnostics.md**: Detailed guidance on checking and handling assumption violations\r\n- **effect_sizes_and_power.md**: Calculating, interpreting, and reporting effect sizes; conducting power analyses\r\n- **bayesian_statistics.md**: Complete guide to Bayesian analysis methods\r\n- **reporting_standards.md**: APA-style reporting guidelines with examples\r\n\r\n### Scripts Directory\r\n\r\n- **assumption_checks.py**: Automated assumption checking with visualizations\r\n  - `comprehensive_assumption_check()`: Complete workflow\r\n  - `check_normality()`: Normality testing with Q-Q plots\r\n  - `check_homogeneity_of_variance()`: Levene's test with box plots\r\n  - `check_linearity()`: Regression linearity checks\r\n  - `detect_outliers()`: IQR and z-score outlier detection\r\n\r\n---",
    "Test Selection Guide": "### Quick Reference: Choosing the Right Test\r\n\r\nUse `references/test_selection_guide.md` for comprehensive guidance. Quick reference:\r\n\r\n**Comparing Two Groups:**\r\n- Independent, continuous, normal → Independent t-test\r\n- Independent, continuous, non-normal → Mann-Whitney U test\r\n- Paired, continuous, normal → Paired t-test\r\n- Paired, continuous, non-normal → Wilcoxon signed-rank test\r\n- Binary outcome → Chi-square or Fisher's exact test\r\n\r\n**Comparing 3+ Groups:**\r\n- Independent, continuous, normal → One-way ANOVA\r\n- Independent, continuous, non-normal → Kruskal-Wallis test\r\n- Paired, continuous, normal → Repeated measures ANOVA\r\n- Paired, continuous, non-normal → Friedman test\r\n\r\n**Relationships:**\r\n- Two continuous variables → Pearson (normal) or Spearman correlation (non-normal)\r\n- Continuous outcome with predictor(s) → Linear regression\r\n- Binary outcome with predictor(s) → Logistic regression\r\n\r\n**Bayesian Alternatives:**\r\nAll tests have Bayesian versions that provide:\r\n- Direct probability statements about hypotheses\r\n- Bayes Factors quantifying evidence\r\n- Ability to support null hypothesis\r\n- See `references/bayesian_statistics.md`\r\n\r\n---",
    "Getting Started Checklist": "When beginning a statistical analysis:\r\n\r\n- [ ] Define research question and hypotheses\r\n- [ ] Determine appropriate statistical test (use test_selection_guide.md)\r\n- [ ] Conduct power analysis to determine sample size\r\n- [ ] Load and inspect data\r\n- [ ] Check for missing data and outliers\r\n- [ ] Verify assumptions using assumption_checks.py\r\n- [ ] Run primary analysis\r\n- [ ] Calculate effect sizes with confidence intervals\r\n- [ ] Conduct post-hoc tests if needed (with corrections)\r\n- [ ] Create visualizations\r\n- [ ] Write results following reporting_standards.md\r\n- [ ] Conduct sensitivity analyses\r\n- [ ] Share data and code\r\n\r\n---",
    "Common Pitfalls to Avoid": "1. **P-hacking**: Don't test multiple ways until something is significant\r\n2. **HARKing**: Don't present exploratory findings as confirmatory\r\n3. **Ignoring assumptions**: Check them and report violations\r\n4. **Confusing significance with importance**: p < .05 ≠ meaningful effect\r\n5. **Not reporting effect sizes**: Essential for interpretation\r\n6. **Cherry-picking results**: Report all planned analyses\r\n7. **Misinterpreting p-values**: They're NOT probability that hypothesis is true\r\n8. **Multiple comparisons**: Correct for family-wise error when appropriate\r\n9. **Ignoring missing data**: Understand mechanism (MCAR, MAR, MNAR)\r\n10. **Overinterpreting non-significant results**: Absence of evidence ≠ evidence of absence\r\n\r\n---",
    "Core Capabilities": "### 1. Test Selection and Planning\r\n- Choose appropriate statistical tests based on research questions and data characteristics\r\n- Conduct a priori power analyses to determine required sample sizes\r\n- Plan analysis strategies including multiple comparison corrections\r\n\r\n### 2. Assumption Checking\r\n- Automatically verify all relevant assumptions before running tests\r\n- Provide diagnostic visualizations (Q-Q plots, residual plots, box plots)\r\n- Recommend remedial actions when assumptions are violated\r\n\r\n### 3. Statistical Testing\r\n- Hypothesis testing: t-tests, ANOVA, chi-square, non-parametric alternatives\r\n- Regression: linear, multiple, logistic, with diagnostics\r\n- Correlations: Pearson, Spearman, with confidence intervals\r\n- Bayesian alternatives: Bayesian t-tests, ANOVA, regression with Bayes Factors\r\n\r\n### 4. Effect Sizes and Interpretation\r\n- Calculate and interpret appropriate effect sizes for all analyses\r\n- Provide confidence intervals for effect estimates\r\n- Distinguish statistical from practical significance\r\n\r\n### 5. Professional Reporting\r\n- Generate APA-style statistical reports\r\n- Create publication-ready figures and tables\r\n- Provide complete interpretation with all required statistics\r\n\r\n---",
    "Power Analysis": "detectable_d = tt_ind_solve_power(\r\n    effect_size=None,  # Solve for this\r\n    nobs1=50,\r\n    alpha=0.05,\r\n    power=0.80,\r\n    ratio=1.0,\r\n    alternative='two-sided'\r\n)\r\nprint(f\"Study could detect d ≥ {detectable_d:.2f}\")\r\n```\r\n\r\n**Note**: Post-hoc power analysis (calculating power after study) is generally not recommended. Use sensitivity analysis instead.\r\n\r\nSee `references/effect_sizes_and_power.md` for detailed guidance.\r\n\r\n---"
  }
}