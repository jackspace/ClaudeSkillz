{
  "description": "\"Parse FCS (Flow Cytometry Standard) files v2.0-3.1. Extract events as NumPy arrays, read metadata/channels, convert to CSV/DataFrame, for flow cytometry data preprocessing.\"",
  "references": {
    "files": [
      "references/api_reference.md"
    ]
  },
  "content": "### Basic File Reading\r\n\r\n```python\r\nfrom flowio import FlowData\r\n\r\nflow_data = FlowData('experiment.fcs')\r\n\r\nprint(f\"FCS Version: {flow_data.version}\")\r\nprint(f\"Events: {flow_data.event_count}\")\r\nprint(f\"Channels: {flow_data.pnn_labels}\")\r\n\r\nevents = flow_data.as_array()  # Shape: (events, channels)\r\n```\r\n\r\n### Creating FCS Files\r\n\r\n```python\r\nimport numpy as np\r\nfrom flowio import create_fcs\r\n\r\ndata = np.array([[100, 200, 50], [150, 180, 60]])  # 2 events, 3 channels\r\nchannels = ['FSC-A', 'SSC-A', 'FL1-A']\r\n\r\n\r\n### Reading and Parsing FCS Files\r\n\r\nThe FlowData class provides the primary interface for reading FCS files.\r\n\r\n**Standard Reading:**\r\n\r\n```python\r\nfrom flowio import FlowData\r\n\r\nflow = FlowData('sample.fcs')\r\n\r\nversion = flow.version              # '3.0', '3.1', etc.\r\nevent_count = flow.event_count      # Number of events\r\nchannel_count = flow.channel_count  # Number of channels\r\npnn_labels = flow.pnn_labels        # Short channel names\r\npns_labels = flow.pns_labels        # Descriptive stain names\r\n\r\nevents = flow.as_array()            # Preprocessed (gain, log scaling applied)\r\nraw_events = flow.as_array(preprocess=False)  # Raw data\r\n```\r\n\r\n**Memory-Efficient Metadata Reading:**\r\n\r\nWhen only metadata is needed (no event data):\r\n\r\n```python\r\nflow = FlowData('sample.fcs', only_text=True)\r\n\r\nmetadata = flow.text  # Dictionary of TEXT segment keywords\r\nprint(metadata.get('$DATE'))  # Acquisition date\r\nprint(metadata.get('$CYT'))   # Instrument name\r\n```\r\n\r\n**Handling Problematic Files:**\r\n\r\nSome FCS files have offset discrepancies or errors:\r\n\r\n```python\r\nflow = FlowData('problematic.fcs', ignore_offset_discrepancy=True)\r\n\r\nflow = FlowData('problematic.fcs', use_header_offsets=True)\r\n\r\nflow = FlowData('problematic.fcs', ignore_offset_error=True)\r\n```\r\n\r\n**Excluding Null Channels:**\r\n\r\n```python\r\nflow = FlowData('sample.fcs', null_channel_list=['Time', 'Null'])\r\n```\r\n\r\n### Extracting Metadata and Channel Information\r\n\r\nFCS files contain rich metadata in the TEXT segment.\r\n\r\n**Common Metadata Keywords:**\r\n\r\n```python\r\nflow = FlowData('sample.fcs')\r\n\r\ntext_dict = flow.text\r\nacquisition_date = text_dict.get('$DATE', 'Unknown')\r\ninstrument = text_dict.get('$CYT', 'Unknown')\r\ndata_type = flow.data_type  # 'I', 'F', 'D', 'A'\r\n\r\nfor i in range(flow.channel_count):\r\n    pnn = flow.pnn_labels[i]      # Short name (e.g., 'FSC-A')\r\n    pns = flow.pns_labels[i]      # Descriptive name (e.g., 'Forward Scatter')\r\n    pnr = flow.pnr_values[i]      # Range/max value\r\n    print(f\"Channel {i}: {pnn} ({pns}), Range: {pnr}\")\r\n```\r\n\r\n**Channel Type Identification:**\r\n\r\nFlowIO automatically categorizes channels:\r\n\r\n```python\r\nscatter_idx = flow.scatter_indices    # [0, 1] for FSC, SSC\r\nfluoro_idx = flow.fluoro_indices      # [2, 3, 4] for FL channels\r\ntime_idx = flow.time_index            # Index of time channel (or None)\r\n\r\nevents = flow.as_array()\r\nscatter_data = events[:, scatter_idx]\r\nfluorescence_data = events[:, fluoro_idx]\r\n```\r\n\r\n**ANALYSIS Segment:**\r\n\r\nIf present, access processed results:\r\n\r\n```python\r\nif flow.analysis:\r\n    analysis_keywords = flow.analysis  # Dictionary of ANALYSIS keywords\r\n    print(analysis_keywords)\r\n```\r\n\r\n### Creating New FCS Files\r\n\r\nGenerate FCS files from NumPy arrays or other data sources.\r\n\r\n**Basic Creation:**\r\n\r\n```python\r\nimport numpy as np\r\nfrom flowio import create_fcs\r\n\r\nevents = np.random.rand(10000, 5) * 1000\r\n\r\nchannel_names = ['FSC-A', 'SSC-A', 'FL1-A', 'FL2-A', 'Time']\r\n\r\ncreate_fcs('output.fcs', events, channel_names)\r\n```\r\n\r\n**With Descriptive Channel Names:**\r\n\r\n```python\r\nchannel_names = ['FSC-A', 'SSC-A', 'FL1-A', 'FL2-A', 'Time']\r\ndescriptive_names = ['Forward Scatter', 'Side Scatter', 'FITC', 'PE', 'Time']\r\n\r\ncreate_fcs('output.fcs',\r\n           events,\r\n           channel_names,\r\n           opt_channel_names=descriptive_names)\r\n```\r\n\r\n**With Custom Metadata:**\r\n\r\n```python\r\nmetadata = {\r\n    '$SRC': 'Python script',\r\n    '$DATE': '19-OCT-2025',\r\n    '$CYT': 'Synthetic Instrument',\r\n    '$INST': 'Laboratory A'\r\n}\r\n\r\ncreate_fcs('output.fcs',\r\n           events,\r\n           channel_names,\r\n           opt_channel_names=descriptive_names,\r\n           metadata=metadata)\r\n```\r\n\r\n**Note:** FlowIO exports as FCS 3.1 with single-precision floating-point data.\r\n\r\n### Exporting Modified Data\r\n\r\nModify existing FCS files and re-export them.\r\n\r\n**Approach 1: Using write_fcs() Method:**\r\n\r\n```python\r\nfrom flowio import FlowData\r\n\r\nflow = FlowData('original.fcs')\r\n\r\nflow.write_fcs('modified.fcs', metadata={'$SRC': 'Modified data'})\r\n```\r\n\r\n**Approach 2: Extract, Modify, and Recreate:**\r\n\r\nFor modifying event data:\r\n\r\n```python\r\nfrom flowio import FlowData, create_fcs\r\n\r\nflow = FlowData('original.fcs')\r\nevents = flow.as_array(preprocess=False)\r\n\r\nevents[:, 0] = events[:, 0] * 1.5  # Scale first channel\r\n\r\ncreate_fcs('modified.fcs',\r\n           events,\r\n           flow.pnn_labels,\r\n           opt_channel_names=flow.pns_labels,\r\n           metadata=flow.text)\r\n```\r\n\r\n### Handling Multi-Dataset FCS Files\r\n\r\nSome FCS files contain multiple datasets in a single file.\r\n\r\n**Detecting Multi-Dataset Files:**\r\n\r\n```python\r\nfrom flowio import FlowData, MultipleDataSetsError\r\n\r\ntry:\r\n    flow = FlowData('sample.fcs')\r\nexcept MultipleDataSetsError:\r\n    print(\"File contains multiple datasets\")\r\n    # Use read_multiple_data_sets() instead\r\n```\r\n\r\n**Reading All Datasets:**\r\n\r\n```python\r\nfrom flowio import read_multiple_data_sets\r\n\r\ndatasets = read_multiple_data_sets('multi_dataset.fcs')\r\n\r\nprint(f\"Found {len(datasets)} datasets\")\r\n\r\nfor i, dataset in enumerate(datasets):\r\n    print(f\"\\nDataset {i}:\")\r\n    print(f\"  Events: {dataset.event_count}\")\r\n    print(f\"  Channels: {dataset.pnn_labels}\")\r\n\r\n    # Get event data for this dataset\r\n    events = dataset.as_array()\r\n    print(f\"  Shape: {events.shape}\")\r\n    print(f\"  Mean values: {events.mean(axis=0)}\")\r\n```\r\n\r\n**Reading Specific Dataset:**\r\n\r\n```python\r\nfrom flowio import FlowData\r\n\r\nfirst_dataset = FlowData('multi.fcs', nextdata_offset=0)\r\n\r\n\r\nFlowIO applies standard FCS preprocessing transformations when `preprocess=True`.\r\n\r\n**Preprocessing Steps:**\r\n\r\n1. **Gain Scaling:** Multiply values by PnG (gain) keyword\r\n2. **Logarithmic Transformation:** Apply PnE exponential transformation if present\r\n   - Formula: `value = a * 10^(b * raw_value)` where PnE = \"a,b\"\r\n3. **Time Scaling:** Convert time values to appropriate units\r\n\r\n**Controlling Preprocessing:**\r\n\r\n```python\r\npreprocessed = flow.as_array(preprocess=True)\r\n\r\n\r\n### Inspecting FCS File Contents\r\n\r\nQuick exploration of FCS file structure:\r\n\r\n```python\r\nfrom flowio import FlowData\r\n\r\nflow = FlowData('unknown.fcs')\r\n\r\nprint(\"=\" * 50)\r\nprint(f\"File: {flow.name}\")\r\nprint(f\"Version: {flow.version}\")\r\nprint(f\"Size: {flow.file_size:,} bytes\")\r\nprint(\"=\" * 50)\r\n\r\nprint(f\"\\nEvents: {flow.event_count:,}\")\r\nprint(f\"Channels: {flow.channel_count}\")\r\n\r\nprint(\"\\nChannel Information:\")\r\nfor i, (pnn, pns) in enumerate(zip(flow.pnn_labels, flow.pns_labels)):\r\n    ch_type = \"scatter\" if i in flow.scatter_indices else \\\r\n              \"fluoro\" if i in flow.fluoro_indices else \\\r\n              \"time\" if i == flow.time_index else \"other\"\r\n    print(f\"  [{i}] {pnn:10s} | {pns:30s} | {ch_type}\")\r\n\r\nprint(\"\\nKey Metadata:\")\r\nfor key in ['$DATE', '$BTIM', '$ETIM', '$CYT', '$INST', '$SRC']:\r\n    value = flow.text.get(key, 'N/A')\r\n    print(f\"  {key:15s}: {value}\")\r\n```\r\n\r\n### Batch Processing Multiple Files\r\n\r\nProcess a directory of FCS files:\r\n\r\n```python\r\nfrom pathlib import Path\r\nfrom flowio import FlowData\r\nimport pandas as pd\r\n\r\nfcs_files = list(Path('data/').glob('*.fcs'))\r\n\r\nsummaries = []\r\nfor fcs_path in fcs_files:\r\n    try:\r\n        flow = FlowData(str(fcs_path), only_text=True)\r\n        summaries.append({\r\n            'filename': fcs_path.name,\r\n            'version': flow.version,\r\n            'events': flow.event_count,\r\n            'channels': flow.channel_count,\r\n            'date': flow.text.get('$DATE', 'N/A')\r\n        })\r\n    except Exception as e:\r\n        print(f\"Error processing {fcs_path.name}: {e}\")\r\n\r\ndf = pd.DataFrame(summaries)\r\nprint(df)\r\n```\r\n\r\n### Converting FCS to CSV\r\n\r\nExport event data to CSV format:\r\n\r\n```python\r\nfrom flowio import FlowData\r\nimport pandas as pd\r\n\r\nflow = FlowData('sample.fcs')\r\n\r\ndf = pd.DataFrame(\r\n    flow.as_array(),\r\n    columns=flow.pnn_labels\r\n)\r\n\r\ndf.attrs['fcs_version'] = flow.version\r\ndf.attrs['instrument'] = flow.text.get('$CYT', 'Unknown')\r\n\r\ndf.to_csv('output.csv', index=False)\r\nprint(f\"Exported {len(df)} events to CSV\")\r\n```\r\n\r\n### Filtering Events and Re-exporting\r\n\r\nApply filters and save filtered data:\r\n\r\n```python\r\nfrom flowio import FlowData, create_fcs\r\nimport numpy as np\r\n\r\nflow = FlowData('sample.fcs')\r\nevents = flow.as_array(preprocess=False)\r\n\r\nfsc_idx = 0\r\nthreshold = 500\r\nmask = events[:, fsc_idx] > threshold\r\nfiltered_events = events[mask]\r\n\r\nprint(f\"Original events: {len(events)}\")\r\nprint(f\"Filtered events: {len(filtered_events)}\")\r\n\r\ncreate_fcs('filtered.fcs',\r\n           filtered_events,\r\n           flow.pnn_labels,\r\n           opt_channel_names=flow.pns_labels,\r\n           metadata={**flow.text, '$SRC': 'Filtered data'})\r\n```\r\n\r\n### Extracting Specific Channels\r\n\r\nExtract and process specific channels:\r\n\r\n```python\r\nfrom flowio import FlowData\r\nimport numpy as np\r\n\r\nflow = FlowData('sample.fcs')\r\nevents = flow.as_array()\r\n\r\nfluoro_indices = flow.fluoro_indices\r\nfluoro_data = events[:, fluoro_indices]\r\nfluoro_names = [flow.pnn_labels[i] for i in fluoro_indices]\r\n\r\nprint(f\"Fluorescence channels: {fluoro_names}\")\r\nprint(f\"Shape: {fluoro_data.shape}\")",
  "name": "flowio",
  "id": "scientific-pkg-flowio",
  "sections": {
    "Overview": "FlowIO is a lightweight Python library for reading and writing Flow Cytometry Standard (FCS) files. Parse FCS metadata, extract event data, and create new FCS files with minimal dependencies. The library supports FCS versions 2.0, 3.0, and 3.1, making it ideal for backend services, data pipelines, and basic cytometry file operations.",
    "Installation": "```bash\r\npip install flowio\r\n```\r\n\r\nRequires Python 3.9 or later.",
    "Data Preprocessing": "raw = flow.as_array(preprocess=False)\r\n```",
    "Best Practices": "1. **Memory Efficiency:** Use `only_text=True` when event data is not needed\r\n2. **Error Handling:** Wrap file operations in try-except blocks for robust code\r\n3. **Multi-Dataset Detection:** Check for MultipleDataSetsError and use appropriate function\r\n4. **Preprocessing Control:** Explicitly set `preprocess` parameter based on analysis needs\r\n5. **Offset Issues:** If parsing fails, try `ignore_offset_discrepancy=True` parameter\r\n6. **Channel Validation:** Verify channel counts and names match expectations before processing\r\n7. **Metadata Preservation:** When modifying files, preserve original TEXT segment keywords",
    "Error Handling": "Handle common FlowIO exceptions appropriately.\r\n\r\n```python\r\nfrom flowio import (\r\n    FlowData,\r\n    FCSParsingError,\r\n    DataOffsetDiscrepancyError,\r\n    MultipleDataSetsError\r\n)\r\n\r\ntry:\r\n    flow = FlowData('sample.fcs')\r\n    events = flow.as_array()\r\n\r\nexcept FCSParsingError as e:\r\n    print(f\"Failed to parse FCS file: {e}\")\r\n    # Try with relaxed parsing\r\n    flow = FlowData('sample.fcs', ignore_offset_error=True)\r\n\r\nexcept DataOffsetDiscrepancyError as e:\r\n    print(f\"Offset discrepancy detected: {e}\")\r\n    # Use ignore_offset_discrepancy parameter\r\n    flow = FlowData('sample.fcs', ignore_offset_discrepancy=True)\r\n\r\nexcept MultipleDataSetsError as e:\r\n    print(f\"Multiple datasets detected: {e}\")\r\n    # Use read_multiple_data_sets instead\r\n    from flowio import read_multiple_data_sets\r\n    datasets = read_multiple_data_sets('sample.fcs')\r\n\r\nexcept Exception as e:\r\n    print(f\"Unexpected error: {e}\")\r\n```",
    "When to Use This Skill": "This skill should be used when:\r\n\r\n- FCS files requiring parsing or metadata extraction\r\n- Flow cytometry data needing conversion to NumPy arrays\r\n- Event data requiring export to FCS format\r\n- Multi-dataset FCS files needing separation\r\n- Channel information extraction (scatter, fluorescence, time)\r\n- Cytometry file validation or inspection\r\n- Pre-processing workflows before advanced analysis\r\n\r\n**Related Tools:** For advanced flow cytometry analysis including compensation, gating, and FlowJo/GatingML support, recommend FlowKit library as a companion to FlowIO.",
    "Common Use Cases": "for i, name in enumerate(fluoro_names):\r\n    channel_data = fluoro_data[:, i]\r\n    print(f\"\\n{name}:\")\r\n    print(f\"  Mean: {channel_data.mean():.2f}\")\r\n    print(f\"  Median: {np.median(channel_data):.2f}\")\r\n    print(f\"  Std Dev: {channel_data.std():.2f}\")\r\n```",
    "Advanced Topics": "### Understanding FCS File Structure\r\n\r\nFCS files consist of four segments:\r\n\r\n1. **HEADER:** FCS version and byte offsets for other segments\r\n2. **TEXT:** Key-value metadata pairs (delimiter-separated)\r\n3. **DATA:** Raw event data (binary/float/ASCII format)\r\n4. **ANALYSIS** (optional): Results from data processing\r\n\r\nAccess these segments via FlowData attributes:\r\n- `flow.header` - HEADER segment\r\n- `flow.text` - TEXT segment keywords\r\n- `flow.events` - DATA segment (as bytes)\r\n- `flow.analysis` - ANALYSIS segment keywords (if present)\r\n\r\n### Detailed API Reference\r\n\r\nFor comprehensive API documentation including all parameters, methods, exceptions, and FCS keyword reference, consult the detailed reference file:\r\n\r\n**Read:** `references/api_reference.md`\r\n\r\nThe reference includes:\r\n- Complete FlowData class documentation\r\n- All utility functions (read_multiple_data_sets, create_fcs)\r\n- Exception classes and handling\r\n- FCS file structure details\r\n- Common TEXT segment keywords\r\n- Extended example workflows\r\n\r\nWhen working with complex FCS operations or encountering unusual file formats, load this reference for detailed guidance.",
    "Core Workflows": "next_offset = int(first_dataset.text['$NEXTDATA'])\r\nif next_offset > 0:\r\n    second_dataset = FlowData('multi.fcs', nextdata_offset=next_offset)\r\n```",
    "Troubleshooting": "**Problem:** \"Offset discrepancy error\"\r\n**Solution:** Use `ignore_offset_discrepancy=True` parameter\r\n\r\n**Problem:** \"Multiple datasets error\"\r\n**Solution:** Use `read_multiple_data_sets()` function instead of FlowData constructor\r\n\r\n**Problem:** Out of memory with large files\r\n**Solution:** Use `only_text=True` for metadata-only operations, or process events in chunks\r\n\r\n**Problem:** Unexpected channel counts\r\n**Solution:** Check for null channels; use `null_channel_list` parameter to exclude them\r\n\r\n**Problem:** Cannot modify event data in place\r\n**Solution:** FlowIO doesn't support direct modification; extract data, modify, then use `create_fcs()` to save",
    "Integration Notes": "**NumPy Arrays:** All event data is returned as NumPy ndarrays with shape (events, channels)\r\n\r\n**Pandas DataFrames:** Easily convert to DataFrames for analysis:\r\n```python\r\nimport pandas as pd\r\ndf = pd.DataFrame(flow.as_array(), columns=flow.pnn_labels)\r\n```\r\n\r\n**FlowKit Integration:** For advanced analysis (compensation, gating, FlowJo support), use FlowKit library which builds on FlowIO's parsing capabilities\r\n\r\n**Web Applications:** FlowIO's minimal dependencies make it ideal for web backend services processing FCS uploads",
    "Quick Start": "create_fcs('output.fcs', data, channels)\r\n```",
    "Summary": "FlowIO provides essential FCS file handling capabilities for flow cytometry workflows. Use it for parsing, metadata extraction, and file creation. For simple file operations and data extraction, FlowIO is sufficient. For complex analysis including compensation and gating, integrate with FlowKit or other specialized tools."
  }
}